2025-05-15 21:29:52,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 21:29:52,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 21:29:52,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-15 21:29:52,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:58:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:58:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:58:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:58:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:58:08,390:INFO:PyCaret ClassificationExperiment
2025-05-24 18:58:08,390:INFO:Logging name: clf-default-name
2025-05-24 18:58:08,390:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 18:58:08,390:INFO:version 3.3.2
2025-05-24 18:58:08,390:INFO:Initializing setup()
2025-05-24 18:58:08,390:INFO:self.USI: 967a
2025-05-24 18:58:08,390:INFO:self._variable_keys: {'USI', 'n_jobs_param', 'target_param', 'y_train', 'fold_groups_param', 'X_test', '_ml_usecase', 'log_plots_param', 'fix_imbalance', 'pipeline', '_available_plots', 'memory', 'y', 'idx', 'is_multiclass', 'html_param', 'exp_name_log', 'exp_id', 'fold_generator', 'X_train', 'logging_param', 'X', 'gpu_n_jobs_param', 'fold_shuffle_param', 'y_test', 'gpu_param', 'seed', 'data'}
2025-05-24 18:58:08,390:INFO:Checking environment
2025-05-24 18:58:08,390:INFO:python_version: 3.10.17
2025-05-24 18:58:08,391:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 18:58:08,391:INFO:machine: x86_64
2025-05-24 18:58:08,392:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 18:58:08,393:INFO:Memory: svmem(total=16407515136, available=9213636608, percent=43.8, used=5927624704, free=3219009536, active=1945980928, inactive=9596342272, buffers=228024320, cached=7032856576, shared=916336640, slab=610738176)
2025-05-24 18:58:08,394:INFO:Physical Core: 4
2025-05-24 18:58:08,394:INFO:Logical Core: 8
2025-05-24 18:58:08,394:INFO:Checking libraries
2025-05-24 18:58:08,394:INFO:System:
2025-05-24 18:58:08,394:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 18:58:08,394:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python
2025-05-24 18:58:08,394:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 18:58:08,394:INFO:PyCaret required dependencies:
2025-05-24 18:58:08,422:INFO:                 pip: 25.1.1
2025-05-24 18:58:08,422:INFO:          setuptools: 65.5.0
2025-05-24 18:58:08,422:INFO:             pycaret: 3.3.2
2025-05-24 18:58:08,422:INFO:             IPython: 8.36.0
2025-05-24 18:58:08,422:INFO:          ipywidgets: 8.1.7
2025-05-24 18:58:08,422:INFO:                tqdm: 4.67.1
2025-05-24 18:58:08,422:INFO:               numpy: 1.26.4
2025-05-24 18:58:08,422:INFO:              pandas: 2.1.4
2025-05-24 18:58:08,422:INFO:              jinja2: 3.1.6
2025-05-24 18:58:08,422:INFO:               scipy: 1.11.4
2025-05-24 18:58:08,422:INFO:              joblib: 1.3.2
2025-05-24 18:58:08,422:INFO:             sklearn: 1.4.2
2025-05-24 18:58:08,422:INFO:                pyod: 2.0.5
2025-05-24 18:58:08,422:INFO:            imblearn: 0.13.0
2025-05-24 18:58:08,422:INFO:   category_encoders: 2.7.0
2025-05-24 18:58:08,422:INFO:            lightgbm: 4.6.0
2025-05-24 18:58:08,423:INFO:               numba: 0.61.2
2025-05-24 18:58:08,423:INFO:            requests: 2.32.3
2025-05-24 18:58:08,423:INFO:          matplotlib: 3.7.5
2025-05-24 18:58:08,423:INFO:          scikitplot: 0.3.7
2025-05-24 18:58:08,423:INFO:         yellowbrick: 1.5
2025-05-24 18:58:08,423:INFO:              plotly: 5.24.1
2025-05-24 18:58:08,423:INFO:    plotly-resampler: Not installed
2025-05-24 18:58:08,423:INFO:             kaleido: 0.2.1
2025-05-24 18:58:08,423:INFO:           schemdraw: 0.15
2025-05-24 18:58:08,423:INFO:         statsmodels: 0.14.4
2025-05-24 18:58:08,423:INFO:              sktime: 0.26.0
2025-05-24 18:58:08,423:INFO:               tbats: 1.1.3
2025-05-24 18:58:08,423:INFO:            pmdarima: 2.0.4
2025-05-24 18:58:08,423:INFO:              psutil: 7.0.0
2025-05-24 18:58:08,423:INFO:          markupsafe: 3.0.2
2025-05-24 18:58:08,423:INFO:             pickle5: Not installed
2025-05-24 18:58:08,424:INFO:         cloudpickle: 3.1.1
2025-05-24 18:58:08,424:INFO:         deprecation: 2.1.0
2025-05-24 18:58:08,424:INFO:              xxhash: 3.5.0
2025-05-24 18:58:08,424:INFO:           wurlitzer: 3.1.1
2025-05-24 18:58:08,424:INFO:PyCaret optional dependencies:
2025-05-24 18:58:08,868:INFO:                shap: Not installed
2025-05-24 18:58:08,868:INFO:           interpret: Not installed
2025-05-24 18:58:08,868:INFO:                umap: Not installed
2025-05-24 18:58:08,868:INFO:     ydata_profiling: Not installed
2025-05-24 18:58:08,868:INFO:  explainerdashboard: Not installed
2025-05-24 18:58:08,868:INFO:             autoviz: Not installed
2025-05-24 18:58:08,868:INFO:           fairlearn: Not installed
2025-05-24 18:58:08,868:INFO:          deepchecks: Not installed
2025-05-24 18:58:08,868:INFO:             xgboost: Not installed
2025-05-24 18:58:08,868:INFO:            catboost: Not installed
2025-05-24 18:58:08,868:INFO:              kmodes: Not installed
2025-05-24 18:58:08,868:INFO:             mlxtend: Not installed
2025-05-24 18:58:08,868:INFO:       statsforecast: Not installed
2025-05-24 18:58:08,868:INFO:        tune_sklearn: Not installed
2025-05-24 18:58:08,868:INFO:                 ray: Not installed
2025-05-24 18:58:08,868:INFO:            hyperopt: Not installed
2025-05-24 18:58:08,868:INFO:              optuna: Not installed
2025-05-24 18:58:08,868:INFO:               skopt: Not installed
2025-05-24 18:58:08,868:INFO:              mlflow: Not installed
2025-05-24 18:58:08,868:INFO:              gradio: Not installed
2025-05-24 18:58:08,868:INFO:             fastapi: 0.115.12
2025-05-24 18:58:08,868:INFO:             uvicorn: 0.34.2
2025-05-24 18:58:08,868:INFO:              m2cgen: Not installed
2025-05-24 18:58:08,869:INFO:           evidently: Not installed
2025-05-24 18:58:08,869:INFO:               fugue: Not installed
2025-05-24 18:58:08,869:INFO:           streamlit: Not installed
2025-05-24 18:58:08,869:INFO:             prophet: Not installed
2025-05-24 18:58:08,869:INFO:None
2025-05-24 18:58:08,869:INFO:Set up data.
2025-05-24 18:58:08,880:INFO:Set up folding strategy.
2025-05-24 18:58:08,880:INFO:Set up train/test split.
2025-05-24 18:58:08,888:INFO:Set up index.
2025-05-24 18:58:08,889:INFO:Assigning column types.
2025-05-24 18:58:08,893:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 18:58:08,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 18:58:08,944:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:58:08,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:08,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 18:58:09,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:58:09,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,056:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 18:58:09,103:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:58:09,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,179:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:58:09,207:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,208:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,208:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 18:58:09,284:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,284:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:58:09,365:INFO:Preparing preprocessing pipeline...
2025-05-24 18:58:09,367:INFO:Set up simple imputation.
2025-05-24 18:58:09,372:INFO:Set up encoding of ordinal features.
2025-05-24 18:58:09,382:INFO:Set up encoding of categorical features.
2025-05-24 18:59:57,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:59:57,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:59:57,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:59:57,717:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 18:59:58,331:INFO:PyCaret ClassificationExperiment
2025-05-24 18:59:58,331:INFO:Logging name: clf-default-name
2025-05-24 18:59:58,331:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 18:59:58,331:INFO:version 3.3.2
2025-05-24 18:59:58,331:INFO:Initializing setup()
2025-05-24 18:59:58,331:INFO:self.USI: 20ab
2025-05-24 18:59:58,331:INFO:self._variable_keys: {'_ml_usecase', 'seed', 'fold_generator', 'USI', 'X', 'X_train', 'pipeline', 'data', 'logging_param', 'memory', 'fold_shuffle_param', 'idx', 'html_param', 'gpu_param', 'is_multiclass', 'n_jobs_param', 'fix_imbalance', 'y_train', 'exp_name_log', 'y', 'X_test', 'target_param', 'fold_groups_param', 'exp_id', 'gpu_n_jobs_param', 'log_plots_param', '_available_plots', 'y_test'}
2025-05-24 18:59:58,331:INFO:Checking environment
2025-05-24 18:59:58,331:INFO:python_version: 3.10.17
2025-05-24 18:59:58,331:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 18:59:58,331:INFO:machine: x86_64
2025-05-24 18:59:58,333:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 18:59:58,334:INFO:Memory: svmem(total=16407515136, available=9210003456, percent=43.9, used=5921271808, free=3193585664, active=1999724544, inactive=9543884800, buffers=228855808, cached=7063801856, shared=926597120, slab=612278272)
2025-05-24 18:59:58,334:INFO:Physical Core: 4
2025-05-24 18:59:58,334:INFO:Logical Core: 8
2025-05-24 18:59:58,335:INFO:Checking libraries
2025-05-24 18:59:58,335:INFO:System:
2025-05-24 18:59:58,335:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 18:59:58,335:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python
2025-05-24 18:59:58,335:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 18:59:58,335:INFO:PyCaret required dependencies:
2025-05-24 18:59:58,355:INFO:                 pip: 25.1.1
2025-05-24 18:59:58,356:INFO:          setuptools: 65.5.0
2025-05-24 18:59:58,356:INFO:             pycaret: 3.3.2
2025-05-24 18:59:58,356:INFO:             IPython: 8.36.0
2025-05-24 18:59:58,356:INFO:          ipywidgets: 8.1.7
2025-05-24 18:59:58,356:INFO:                tqdm: 4.67.1
2025-05-24 18:59:58,356:INFO:               numpy: 1.26.4
2025-05-24 18:59:58,356:INFO:              pandas: 2.1.4
2025-05-24 18:59:58,356:INFO:              jinja2: 3.1.6
2025-05-24 18:59:58,356:INFO:               scipy: 1.11.4
2025-05-24 18:59:58,356:INFO:              joblib: 1.3.2
2025-05-24 18:59:58,356:INFO:             sklearn: 1.4.2
2025-05-24 18:59:58,356:INFO:                pyod: 2.0.5
2025-05-24 18:59:58,356:INFO:            imblearn: 0.13.0
2025-05-24 18:59:58,356:INFO:   category_encoders: 2.7.0
2025-05-24 18:59:58,356:INFO:            lightgbm: 4.6.0
2025-05-24 18:59:58,356:INFO:               numba: 0.61.2
2025-05-24 18:59:58,356:INFO:            requests: 2.32.3
2025-05-24 18:59:58,356:INFO:          matplotlib: 3.7.5
2025-05-24 18:59:58,356:INFO:          scikitplot: 0.3.7
2025-05-24 18:59:58,356:INFO:         yellowbrick: 1.5
2025-05-24 18:59:58,356:INFO:              plotly: 5.24.1
2025-05-24 18:59:58,356:INFO:    plotly-resampler: Not installed
2025-05-24 18:59:58,356:INFO:             kaleido: 0.2.1
2025-05-24 18:59:58,357:INFO:           schemdraw: 0.15
2025-05-24 18:59:58,357:INFO:         statsmodels: 0.14.4
2025-05-24 18:59:58,357:INFO:              sktime: 0.26.0
2025-05-24 18:59:58,357:INFO:               tbats: 1.1.3
2025-05-24 18:59:58,357:INFO:            pmdarima: 2.0.4
2025-05-24 18:59:58,357:INFO:              psutil: 7.0.0
2025-05-24 18:59:58,357:INFO:          markupsafe: 3.0.2
2025-05-24 18:59:58,357:INFO:             pickle5: Not installed
2025-05-24 18:59:58,357:INFO:         cloudpickle: 3.1.1
2025-05-24 18:59:58,357:INFO:         deprecation: 2.1.0
2025-05-24 18:59:58,357:INFO:              xxhash: 3.5.0
2025-05-24 18:59:58,357:INFO:           wurlitzer: 3.1.1
2025-05-24 18:59:58,357:INFO:PyCaret optional dependencies:
2025-05-24 18:59:58,751:INFO:                shap: Not installed
2025-05-24 18:59:58,751:INFO:           interpret: Not installed
2025-05-24 18:59:58,751:INFO:                umap: Not installed
2025-05-24 18:59:58,751:INFO:     ydata_profiling: Not installed
2025-05-24 18:59:58,751:INFO:  explainerdashboard: Not installed
2025-05-24 18:59:58,751:INFO:             autoviz: Not installed
2025-05-24 18:59:58,751:INFO:           fairlearn: Not installed
2025-05-24 18:59:58,751:INFO:          deepchecks: Not installed
2025-05-24 18:59:58,751:INFO:             xgboost: Not installed
2025-05-24 18:59:58,751:INFO:            catboost: Not installed
2025-05-24 18:59:58,751:INFO:              kmodes: Not installed
2025-05-24 18:59:58,751:INFO:             mlxtend: Not installed
2025-05-24 18:59:58,751:INFO:       statsforecast: Not installed
2025-05-24 18:59:58,751:INFO:        tune_sklearn: Not installed
2025-05-24 18:59:58,751:INFO:                 ray: Not installed
2025-05-24 18:59:58,751:INFO:            hyperopt: Not installed
2025-05-24 18:59:58,751:INFO:              optuna: Not installed
2025-05-24 18:59:58,751:INFO:               skopt: Not installed
2025-05-24 18:59:58,751:INFO:              mlflow: Not installed
2025-05-24 18:59:58,751:INFO:              gradio: Not installed
2025-05-24 18:59:58,751:INFO:             fastapi: 0.115.12
2025-05-24 18:59:58,751:INFO:             uvicorn: 0.34.2
2025-05-24 18:59:58,751:INFO:              m2cgen: Not installed
2025-05-24 18:59:58,751:INFO:           evidently: Not installed
2025-05-24 18:59:58,752:INFO:               fugue: Not installed
2025-05-24 18:59:58,752:INFO:           streamlit: Not installed
2025-05-24 18:59:58,752:INFO:             prophet: Not installed
2025-05-24 18:59:58,752:INFO:None
2025-05-24 18:59:58,752:INFO:Set up data.
2025-05-24 18:59:58,759:INFO:Set up folding strategy.
2025-05-24 18:59:58,759:INFO:Set up train/test split.
2025-05-24 18:59:58,765:INFO:Set up index.
2025-05-24 18:59:58,765:INFO:Assigning column types.
2025-05-24 18:59:58,770:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 18:59:58,815:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 18:59:58,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:59:58,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:58,850:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:58,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 18:59:58,896:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:59:58,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:58,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:58,925:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 18:59:58,971:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:59:58,999:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:58,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,046:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 18:59:59,074:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,074:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,075:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 18:59:59,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,222:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,222:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 18:59:59,224:INFO:Preparing preprocessing pipeline...
2025-05-24 18:59:59,225:INFO:Set up simple imputation.
2025-05-24 18:59:59,229:INFO:Set up encoding of ordinal features.
2025-05-24 18:59:59,239:INFO:Set up encoding of categorical features.
2025-05-24 19:00:50,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:00:50,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:00:50,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:00:50,452:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:00:51,124:INFO:PyCaret ClassificationExperiment
2025-05-24 19:00:51,124:INFO:Logging name: clf-default-name
2025-05-24 19:00:51,124:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:00:51,124:INFO:version 3.3.2
2025-05-24 19:00:51,124:INFO:Initializing setup()
2025-05-24 19:00:51,124:INFO:self.USI: fa31
2025-05-24 19:00:51,124:INFO:self._variable_keys: {'fold_groups_param', 'pipeline', 'exp_id', '_ml_usecase', 'exp_name_log', 'X_train', 'y', 'y_train', 'n_jobs_param', 'fold_generator', 'memory', 'log_plots_param', 'fix_imbalance', 'seed', '_available_plots', 'USI', 'html_param', 'X', 'gpu_param', 'logging_param', 'fold_shuffle_param', 'X_test', 'data', 'target_param', 'gpu_n_jobs_param', 'is_multiclass', 'y_test', 'idx'}
2025-05-24 19:00:51,124:INFO:Checking environment
2025-05-24 19:00:51,124:INFO:python_version: 3.10.17
2025-05-24 19:00:51,124:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:00:51,124:INFO:machine: x86_64
2025-05-24 19:00:51,126:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:00:51,127:INFO:Memory: svmem(total=16407515136, available=9173127168, percent=44.1, used=5928398848, free=3156279296, active=2061070336, inactive=9479790592, buffers=229064704, cached=7093772288, shared=956346368, slab=612524032)
2025-05-24 19:00:51,128:INFO:Physical Core: 4
2025-05-24 19:00:51,128:INFO:Logical Core: 8
2025-05-24 19:00:51,128:INFO:Checking libraries
2025-05-24 19:00:51,128:INFO:System:
2025-05-24 19:00:51,128:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:00:51,128:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python
2025-05-24 19:00:51,128:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:00:51,128:INFO:PyCaret required dependencies:
2025-05-24 19:00:51,148:INFO:                 pip: 25.1.1
2025-05-24 19:00:51,148:INFO:          setuptools: 65.5.0
2025-05-24 19:00:51,148:INFO:             pycaret: 3.3.2
2025-05-24 19:00:51,148:INFO:             IPython: 8.36.0
2025-05-24 19:00:51,148:INFO:          ipywidgets: 8.1.7
2025-05-24 19:00:51,149:INFO:                tqdm: 4.67.1
2025-05-24 19:00:51,149:INFO:               numpy: 1.26.4
2025-05-24 19:00:51,149:INFO:              pandas: 2.1.4
2025-05-24 19:00:51,149:INFO:              jinja2: 3.1.6
2025-05-24 19:00:51,149:INFO:               scipy: 1.11.4
2025-05-24 19:00:51,149:INFO:              joblib: 1.3.2
2025-05-24 19:00:51,149:INFO:             sklearn: 1.4.2
2025-05-24 19:00:51,149:INFO:                pyod: 2.0.5
2025-05-24 19:00:51,149:INFO:            imblearn: 0.13.0
2025-05-24 19:00:51,149:INFO:   category_encoders: 2.7.0
2025-05-24 19:00:51,149:INFO:            lightgbm: 4.6.0
2025-05-24 19:00:51,149:INFO:               numba: 0.61.2
2025-05-24 19:00:51,149:INFO:            requests: 2.32.3
2025-05-24 19:00:51,149:INFO:          matplotlib: 3.7.5
2025-05-24 19:00:51,149:INFO:          scikitplot: 0.3.7
2025-05-24 19:00:51,150:INFO:         yellowbrick: 1.5
2025-05-24 19:00:51,150:INFO:              plotly: 5.24.1
2025-05-24 19:00:51,150:INFO:    plotly-resampler: Not installed
2025-05-24 19:00:51,150:INFO:             kaleido: 0.2.1
2025-05-24 19:00:51,150:INFO:           schemdraw: 0.15
2025-05-24 19:00:51,150:INFO:         statsmodels: 0.14.4
2025-05-24 19:00:51,150:INFO:              sktime: 0.26.0
2025-05-24 19:00:51,150:INFO:               tbats: 1.1.3
2025-05-24 19:00:51,150:INFO:            pmdarima: 2.0.4
2025-05-24 19:00:51,150:INFO:              psutil: 7.0.0
2025-05-24 19:00:51,150:INFO:          markupsafe: 3.0.2
2025-05-24 19:00:51,150:INFO:             pickle5: Not installed
2025-05-24 19:00:51,150:INFO:         cloudpickle: 3.1.1
2025-05-24 19:00:51,150:INFO:         deprecation: 2.1.0
2025-05-24 19:00:51,150:INFO:              xxhash: 3.5.0
2025-05-24 19:00:51,151:INFO:           wurlitzer: 3.1.1
2025-05-24 19:00:51,151:INFO:PyCaret optional dependencies:
2025-05-24 19:00:51,546:INFO:                shap: Not installed
2025-05-24 19:00:51,546:INFO:           interpret: Not installed
2025-05-24 19:00:51,546:INFO:                umap: Not installed
2025-05-24 19:00:51,546:INFO:     ydata_profiling: Not installed
2025-05-24 19:00:51,546:INFO:  explainerdashboard: Not installed
2025-05-24 19:00:51,546:INFO:             autoviz: Not installed
2025-05-24 19:00:51,546:INFO:           fairlearn: Not installed
2025-05-24 19:00:51,546:INFO:          deepchecks: Not installed
2025-05-24 19:00:51,546:INFO:             xgboost: Not installed
2025-05-24 19:00:51,547:INFO:            catboost: Not installed
2025-05-24 19:00:51,547:INFO:              kmodes: Not installed
2025-05-24 19:00:51,547:INFO:             mlxtend: Not installed
2025-05-24 19:00:51,547:INFO:       statsforecast: Not installed
2025-05-24 19:00:51,547:INFO:        tune_sklearn: Not installed
2025-05-24 19:00:51,547:INFO:                 ray: Not installed
2025-05-24 19:00:51,547:INFO:            hyperopt: Not installed
2025-05-24 19:00:51,547:INFO:              optuna: Not installed
2025-05-24 19:00:51,547:INFO:               skopt: Not installed
2025-05-24 19:00:51,547:INFO:              mlflow: Not installed
2025-05-24 19:00:51,547:INFO:              gradio: Not installed
2025-05-24 19:00:51,547:INFO:             fastapi: 0.115.12
2025-05-24 19:00:51,547:INFO:             uvicorn: 0.34.2
2025-05-24 19:00:51,547:INFO:              m2cgen: Not installed
2025-05-24 19:00:51,547:INFO:           evidently: Not installed
2025-05-24 19:00:51,547:INFO:               fugue: Not installed
2025-05-24 19:00:51,547:INFO:           streamlit: Not installed
2025-05-24 19:00:51,547:INFO:             prophet: Not installed
2025-05-24 19:00:51,547:INFO:None
2025-05-24 19:00:51,547:INFO:Set up data.
2025-05-24 19:00:51,555:INFO:Set up folding strategy.
2025-05-24 19:00:51,555:INFO:Set up train/test split.
2025-05-24 19:00:51,563:INFO:Set up index.
2025-05-24 19:00:51,563:INFO:Assigning column types.
2025-05-24 19:00:51,568:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:00:51,615:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,619:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,723:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:00:51,770:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:00:51,872:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,872:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,872:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:00:51,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:51,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:52,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:52,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:00:52,048:INFO:Preparing preprocessing pipeline...
2025-05-24 19:00:52,049:INFO:Set up simple imputation.
2025-05-24 19:00:52,055:INFO:Set up encoding of ordinal features.
2025-05-24 19:00:52,072:INFO:Set up encoding of categorical features.
2025-05-24 19:02:05,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/scipy/__init__.py:132: UserWarning: A NumPy version >=1.21.6 and <1.28.0 is required for this version of SciPy (detected version 2.2.6)
  warnings.warn(f"A NumPy version >={np_minversion} and <{np_maxversion}"

2025-05-24 19:07:31,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:31,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:31,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:31,788:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:32,389:INFO:PyCaret ClassificationExperiment
2025-05-24 19:07:32,389:INFO:Logging name: clf-default-name
2025-05-24 19:07:32,389:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:07:32,389:INFO:version 3.3.2
2025-05-24 19:07:32,389:INFO:Initializing setup()
2025-05-24 19:07:32,389:INFO:self.USI: 64da
2025-05-24 19:07:32,389:INFO:self._variable_keys: {'memory', 'gpu_param', '_available_plots', 'pipeline', 'X_test', 'gpu_n_jobs_param', 'html_param', 'y', 'seed', 'n_jobs_param', 'data', 'log_plots_param', '_ml_usecase', 'y_train', 'target_param', 'exp_name_log', 'USI', 'idx', 'X_train', 'fold_groups_param', 'exp_id', 'logging_param', 'X', 'is_multiclass', 'y_test', 'fold_shuffle_param', 'fix_imbalance', 'fold_generator'}
2025-05-24 19:07:32,389:INFO:Checking environment
2025-05-24 19:07:32,389:INFO:python_version: 3.10.17
2025-05-24 19:07:32,389:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:07:32,389:INFO:machine: x86_64
2025-05-24 19:07:32,391:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:07:32,391:INFO:Memory: svmem(total=16407515136, available=9008607232, percent=45.1, used=6058700800, free=900448256, active=2110414848, inactive=11483074560, buffers=287072256, cached=9161293824, shared=990564352, slab=787337216)
2025-05-24 19:07:32,392:INFO:Physical Core: 4
2025-05-24 19:07:32,392:INFO:Logical Core: 8
2025-05-24 19:07:32,392:INFO:Checking libraries
2025-05-24 19:07:32,392:INFO:System:
2025-05-24 19:07:32,392:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:07:32,392:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python
2025-05-24 19:07:32,392:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:07:32,392:INFO:PyCaret required dependencies:
2025-05-24 19:07:32,412:INFO:                 pip: 25.1.1
2025-05-24 19:07:32,412:INFO:          setuptools: 65.5.0
2025-05-24 19:07:32,412:INFO:             pycaret: 3.3.2
2025-05-24 19:07:32,412:INFO:             IPython: 8.36.0
2025-05-24 19:07:32,412:INFO:          ipywidgets: 8.1.7
2025-05-24 19:07:32,412:INFO:                tqdm: 4.67.1
2025-05-24 19:07:32,412:INFO:               numpy: 1.26.4
2025-05-24 19:07:32,412:INFO:              pandas: 2.1.4
2025-05-24 19:07:32,412:INFO:              jinja2: 3.1.6
2025-05-24 19:07:32,412:INFO:               scipy: 1.11.4
2025-05-24 19:07:32,413:INFO:              joblib: 1.3.2
2025-05-24 19:07:32,413:INFO:             sklearn: 1.4.2
2025-05-24 19:07:32,413:INFO:                pyod: 2.0.5
2025-05-24 19:07:32,413:INFO:            imblearn: 0.13.0
2025-05-24 19:07:32,413:INFO:   category_encoders: 2.7.0
2025-05-24 19:07:32,413:INFO:            lightgbm: 4.6.0
2025-05-24 19:07:32,413:INFO:               numba: 0.61.2
2025-05-24 19:07:32,413:INFO:            requests: 2.32.3
2025-05-24 19:07:32,413:INFO:          matplotlib: 3.7.5
2025-05-24 19:07:32,413:INFO:          scikitplot: 0.3.7
2025-05-24 19:07:32,413:INFO:         yellowbrick: 1.5
2025-05-24 19:07:32,413:INFO:              plotly: 5.24.1
2025-05-24 19:07:32,413:INFO:    plotly-resampler: Not installed
2025-05-24 19:07:32,413:INFO:             kaleido: 0.2.1
2025-05-24 19:07:32,413:INFO:           schemdraw: 0.15
2025-05-24 19:07:32,413:INFO:         statsmodels: 0.14.4
2025-05-24 19:07:32,413:INFO:              sktime: 0.26.0
2025-05-24 19:07:32,413:INFO:               tbats: 1.1.3
2025-05-24 19:07:32,413:INFO:            pmdarima: 2.0.4
2025-05-24 19:07:32,413:INFO:              psutil: 7.0.0
2025-05-24 19:07:32,413:INFO:          markupsafe: 3.0.2
2025-05-24 19:07:32,413:INFO:             pickle5: Not installed
2025-05-24 19:07:32,413:INFO:         cloudpickle: 3.1.1
2025-05-24 19:07:32,413:INFO:         deprecation: 2.1.0
2025-05-24 19:07:32,413:INFO:              xxhash: 3.5.0
2025-05-24 19:07:32,413:INFO:           wurlitzer: 3.1.1
2025-05-24 19:07:32,413:INFO:PyCaret optional dependencies:
2025-05-24 19:07:32,797:INFO:                shap: Not installed
2025-05-24 19:07:32,797:INFO:           interpret: Not installed
2025-05-24 19:07:32,797:INFO:                umap: Not installed
2025-05-24 19:07:32,797:INFO:     ydata_profiling: Not installed
2025-05-24 19:07:32,797:INFO:  explainerdashboard: Not installed
2025-05-24 19:07:32,797:INFO:             autoviz: Not installed
2025-05-24 19:07:32,797:INFO:           fairlearn: Not installed
2025-05-24 19:07:32,797:INFO:          deepchecks: Not installed
2025-05-24 19:07:32,797:INFO:             xgboost: Not installed
2025-05-24 19:07:32,797:INFO:            catboost: Not installed
2025-05-24 19:07:32,797:INFO:              kmodes: Not installed
2025-05-24 19:07:32,798:INFO:             mlxtend: Not installed
2025-05-24 19:07:32,798:INFO:       statsforecast: Not installed
2025-05-24 19:07:32,798:INFO:        tune_sklearn: Not installed
2025-05-24 19:07:32,798:INFO:                 ray: Not installed
2025-05-24 19:07:32,798:INFO:            hyperopt: Not installed
2025-05-24 19:07:32,798:INFO:              optuna: Not installed
2025-05-24 19:07:32,798:INFO:               skopt: Not installed
2025-05-24 19:07:32,798:INFO:              mlflow: Not installed
2025-05-24 19:07:32,798:INFO:              gradio: Not installed
2025-05-24 19:07:32,798:INFO:             fastapi: 0.115.12
2025-05-24 19:07:32,798:INFO:             uvicorn: 0.34.2
2025-05-24 19:07:32,798:INFO:              m2cgen: Not installed
2025-05-24 19:07:32,798:INFO:           evidently: Not installed
2025-05-24 19:07:32,798:INFO:               fugue: Not installed
2025-05-24 19:07:32,798:INFO:           streamlit: Not installed
2025-05-24 19:07:32,798:INFO:             prophet: Not installed
2025-05-24 19:07:32,798:INFO:None
2025-05-24 19:07:32,798:INFO:Set up data.
2025-05-24 19:07:32,805:INFO:Set up folding strategy.
2025-05-24 19:07:32,805:INFO:Set up train/test split.
2025-05-24 19:07:32,811:INFO:Set up index.
2025-05-24 19:07:32,811:INFO:Assigning column types.
2025-05-24 19:07:32,816:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:07:32,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:07:32,866:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:32,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:32,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:32,946:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:07:32,947:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:32,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:32,976:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:32,977:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:07:33,025:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:33,057:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,106:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:33,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,136:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:07:33,213:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,213:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,290:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:33,292:INFO:Preparing preprocessing pipeline...
2025-05-24 19:07:33,293:INFO:Set up simple imputation.
2025-05-24 19:07:33,297:INFO:Set up encoding of ordinal features.
2025-05-24 19:07:33,308:INFO:Set up encoding of categorical features.
2025-05-24 19:07:50,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:50,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:50,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:50,659:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:07:51,258:INFO:PyCaret ClassificationExperiment
2025-05-24 19:07:51,259:INFO:Logging name: clf-default-name
2025-05-24 19:07:51,259:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:07:51,259:INFO:version 3.3.2
2025-05-24 19:07:51,259:INFO:Initializing setup()
2025-05-24 19:07:51,259:INFO:self.USI: da29
2025-05-24 19:07:51,259:INFO:self._variable_keys: {'_available_plots', 'is_multiclass', 'pipeline', 'memory', 'fold_groups_param', 'X_test', 'n_jobs_param', 'idx', 'target_param', 'USI', 'fold_shuffle_param', 'logging_param', 'y_train', 'data', '_ml_usecase', 'fold_generator', 'seed', 'fix_imbalance', 'gpu_n_jobs_param', 'X_train', 'gpu_param', 'exp_id', 'html_param', 'exp_name_log', 'y', 'log_plots_param', 'y_test', 'X'}
2025-05-24 19:07:51,259:INFO:Checking environment
2025-05-24 19:07:51,259:INFO:python_version: 3.10.17
2025-05-24 19:07:51,259:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:07:51,259:INFO:machine: x86_64
2025-05-24 19:07:51,261:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:07:51,261:INFO:Memory: svmem(total=16407515136, available=9044324352, percent=44.9, used=6051860480, free=936206336, active=2120896512, inactive=11464187904, buffers=287170560, cached=9132277760, shared=961687552, slab=787382272)
2025-05-24 19:07:51,262:INFO:Physical Core: 4
2025-05-24 19:07:51,262:INFO:Logical Core: 8
2025-05-24 19:07:51,262:INFO:Checking libraries
2025-05-24 19:07:51,262:INFO:System:
2025-05-24 19:07:51,262:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:07:51,262:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:07:51,262:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:07:51,262:INFO:PyCaret required dependencies:
2025-05-24 19:07:51,282:INFO:                 pip: 25.1.1
2025-05-24 19:07:51,282:INFO:          setuptools: 65.5.0
2025-05-24 19:07:51,282:INFO:             pycaret: 3.3.2
2025-05-24 19:07:51,283:INFO:             IPython: 8.36.0
2025-05-24 19:07:51,283:INFO:          ipywidgets: 8.1.7
2025-05-24 19:07:51,283:INFO:                tqdm: 4.67.1
2025-05-24 19:07:51,283:INFO:               numpy: 1.26.4
2025-05-24 19:07:51,283:INFO:              pandas: 2.1.4
2025-05-24 19:07:51,283:INFO:              jinja2: 3.1.6
2025-05-24 19:07:51,283:INFO:               scipy: 1.11.4
2025-05-24 19:07:51,283:INFO:              joblib: 1.3.2
2025-05-24 19:07:51,283:INFO:             sklearn: 1.4.2
2025-05-24 19:07:51,283:INFO:                pyod: 2.0.5
2025-05-24 19:07:51,283:INFO:            imblearn: 0.13.0
2025-05-24 19:07:51,283:INFO:   category_encoders: 2.7.0
2025-05-24 19:07:51,283:INFO:            lightgbm: 4.6.0
2025-05-24 19:07:51,283:INFO:               numba: 0.61.2
2025-05-24 19:07:51,283:INFO:            requests: 2.32.3
2025-05-24 19:07:51,283:INFO:          matplotlib: 3.7.5
2025-05-24 19:07:51,283:INFO:          scikitplot: 0.3.7
2025-05-24 19:07:51,283:INFO:         yellowbrick: 1.5
2025-05-24 19:07:51,283:INFO:              plotly: 5.24.1
2025-05-24 19:07:51,283:INFO:    plotly-resampler: Not installed
2025-05-24 19:07:51,283:INFO:             kaleido: 0.2.1
2025-05-24 19:07:51,283:INFO:           schemdraw: 0.15
2025-05-24 19:07:51,283:INFO:         statsmodels: 0.14.4
2025-05-24 19:07:51,283:INFO:              sktime: 0.26.0
2025-05-24 19:07:51,283:INFO:               tbats: 1.1.3
2025-05-24 19:07:51,283:INFO:            pmdarima: 2.0.4
2025-05-24 19:07:51,283:INFO:              psutil: 7.0.0
2025-05-24 19:07:51,283:INFO:          markupsafe: 3.0.2
2025-05-24 19:07:51,283:INFO:             pickle5: Not installed
2025-05-24 19:07:51,283:INFO:         cloudpickle: 3.1.1
2025-05-24 19:07:51,283:INFO:         deprecation: 2.1.0
2025-05-24 19:07:51,284:INFO:              xxhash: 3.5.0
2025-05-24 19:07:51,284:INFO:           wurlitzer: 3.1.1
2025-05-24 19:07:51,284:INFO:PyCaret optional dependencies:
2025-05-24 19:07:51,698:INFO:                shap: Not installed
2025-05-24 19:07:51,698:INFO:           interpret: Not installed
2025-05-24 19:07:51,698:INFO:                umap: Not installed
2025-05-24 19:07:51,698:INFO:     ydata_profiling: Not installed
2025-05-24 19:07:51,699:INFO:  explainerdashboard: Not installed
2025-05-24 19:07:51,699:INFO:             autoviz: Not installed
2025-05-24 19:07:51,699:INFO:           fairlearn: Not installed
2025-05-24 19:07:51,699:INFO:          deepchecks: Not installed
2025-05-24 19:07:51,699:INFO:             xgboost: Not installed
2025-05-24 19:07:51,699:INFO:            catboost: Not installed
2025-05-24 19:07:51,699:INFO:              kmodes: Not installed
2025-05-24 19:07:51,699:INFO:             mlxtend: Not installed
2025-05-24 19:07:51,699:INFO:       statsforecast: Not installed
2025-05-24 19:07:51,699:INFO:        tune_sklearn: Not installed
2025-05-24 19:07:51,699:INFO:                 ray: Not installed
2025-05-24 19:07:51,699:INFO:            hyperopt: Not installed
2025-05-24 19:07:51,699:INFO:              optuna: Not installed
2025-05-24 19:07:51,699:INFO:               skopt: Not installed
2025-05-24 19:07:51,699:INFO:              mlflow: Not installed
2025-05-24 19:07:51,699:INFO:              gradio: Not installed
2025-05-24 19:07:51,699:INFO:             fastapi: 0.115.12
2025-05-24 19:07:51,699:INFO:             uvicorn: 0.34.2
2025-05-24 19:07:51,699:INFO:              m2cgen: Not installed
2025-05-24 19:07:51,699:INFO:           evidently: Not installed
2025-05-24 19:07:51,699:INFO:               fugue: Not installed
2025-05-24 19:07:51,699:INFO:           streamlit: Not installed
2025-05-24 19:07:51,699:INFO:             prophet: Not installed
2025-05-24 19:07:51,699:INFO:None
2025-05-24 19:07:51,699:INFO:Set up data.
2025-05-24 19:07:51,706:INFO:Set up folding strategy.
2025-05-24 19:07:51,706:INFO:Set up train/test split.
2025-05-24 19:07:51,712:INFO:Set up index.
2025-05-24 19:07:51,713:INFO:Assigning column types.
2025-05-24 19:07:51,717:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:07:51,764:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:07:51,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:51,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:51,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:51,850:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:07:51,851:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:51,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:51,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:51,881:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:07:51,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:51,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:51,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,012:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:07:52,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,042:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,042:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:07:52,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:07:52,204:INFO:Preparing preprocessing pipeline...
2025-05-24 19:07:52,205:INFO:Set up simple imputation.
2025-05-24 19:07:52,209:INFO:Set up encoding of ordinal features.
2025-05-24 19:07:52,219:INFO:Set up encoding of categorical features.
2025-05-24 19:08:45,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:08:45,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:08:45,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:08:45,712:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:08:46,313:INFO:PyCaret ClassificationExperiment
2025-05-24 19:08:46,313:INFO:Logging name: clf-default-name
2025-05-24 19:08:46,313:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:08:46,313:INFO:version 3.3.2
2025-05-24 19:08:46,314:INFO:Initializing setup()
2025-05-24 19:08:46,314:INFO:self.USI: 410e
2025-05-24 19:08:46,314:INFO:self._variable_keys: {'fold_groups_param', 'X_train', 'logging_param', 'data', 'is_multiclass', 'exp_id', 'y', 'log_plots_param', 'fold_generator', 'gpu_param', '_ml_usecase', 'n_jobs_param', 'exp_name_log', '_available_plots', 'fix_imbalance', 'html_param', 'gpu_n_jobs_param', 'y_test', 'seed', 'X_test', 'target_param', 'X', 'fold_shuffle_param', 'y_train', 'memory', 'idx', 'pipeline', 'USI'}
2025-05-24 19:08:46,314:INFO:Checking environment
2025-05-24 19:08:46,314:INFO:python_version: 3.10.17
2025-05-24 19:08:46,314:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:08:46,314:INFO:machine: x86_64
2025-05-24 19:08:46,316:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:08:46,316:INFO:Memory: svmem(total=16407515136, available=8993746944, percent=45.2, used=6082670592, free=886288384, active=2134376448, inactive=11470876672, buffers=287514624, cached=9151041536, shared=981454848, slab=786116608)
2025-05-24 19:08:46,317:INFO:Physical Core: 4
2025-05-24 19:08:46,317:INFO:Logical Core: 8
2025-05-24 19:08:46,317:INFO:Checking libraries
2025-05-24 19:08:46,317:INFO:System:
2025-05-24 19:08:46,317:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:08:46,317:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:08:46,317:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:08:46,317:INFO:PyCaret required dependencies:
2025-05-24 19:08:46,337:INFO:                 pip: 25.1.1
2025-05-24 19:08:46,337:INFO:          setuptools: 65.5.0
2025-05-24 19:08:46,337:INFO:             pycaret: 3.3.2
2025-05-24 19:08:46,337:INFO:             IPython: 8.36.0
2025-05-24 19:08:46,337:INFO:          ipywidgets: 8.1.7
2025-05-24 19:08:46,337:INFO:                tqdm: 4.67.1
2025-05-24 19:08:46,337:INFO:               numpy: 1.26.4
2025-05-24 19:08:46,337:INFO:              pandas: 2.1.4
2025-05-24 19:08:46,337:INFO:              jinja2: 3.1.6
2025-05-24 19:08:46,337:INFO:               scipy: 1.11.4
2025-05-24 19:08:46,338:INFO:              joblib: 1.3.2
2025-05-24 19:08:46,338:INFO:             sklearn: 1.4.2
2025-05-24 19:08:46,338:INFO:                pyod: 2.0.5
2025-05-24 19:08:46,338:INFO:            imblearn: 0.13.0
2025-05-24 19:08:46,338:INFO:   category_encoders: 2.7.0
2025-05-24 19:08:46,338:INFO:            lightgbm: 4.6.0
2025-05-24 19:08:46,338:INFO:               numba: 0.61.2
2025-05-24 19:08:46,338:INFO:            requests: 2.32.3
2025-05-24 19:08:46,338:INFO:          matplotlib: 3.7.5
2025-05-24 19:08:46,338:INFO:          scikitplot: 0.3.7
2025-05-24 19:08:46,338:INFO:         yellowbrick: 1.5
2025-05-24 19:08:46,338:INFO:              plotly: 5.24.1
2025-05-24 19:08:46,338:INFO:    plotly-resampler: Not installed
2025-05-24 19:08:46,338:INFO:             kaleido: 0.2.1
2025-05-24 19:08:46,338:INFO:           schemdraw: 0.15
2025-05-24 19:08:46,338:INFO:         statsmodels: 0.14.4
2025-05-24 19:08:46,338:INFO:              sktime: 0.26.0
2025-05-24 19:08:46,338:INFO:               tbats: 1.1.3
2025-05-24 19:08:46,338:INFO:            pmdarima: 2.0.4
2025-05-24 19:08:46,338:INFO:              psutil: 7.0.0
2025-05-24 19:08:46,338:INFO:          markupsafe: 3.0.2
2025-05-24 19:08:46,338:INFO:             pickle5: Not installed
2025-05-24 19:08:46,338:INFO:         cloudpickle: 3.1.1
2025-05-24 19:08:46,338:INFO:         deprecation: 2.1.0
2025-05-24 19:08:46,338:INFO:              xxhash: 3.5.0
2025-05-24 19:08:46,338:INFO:           wurlitzer: 3.1.1
2025-05-24 19:08:46,338:INFO:PyCaret optional dependencies:
2025-05-24 19:08:46,723:INFO:                shap: Not installed
2025-05-24 19:08:46,724:INFO:           interpret: Not installed
2025-05-24 19:08:46,724:INFO:                umap: Not installed
2025-05-24 19:08:46,724:INFO:     ydata_profiling: Not installed
2025-05-24 19:08:46,724:INFO:  explainerdashboard: Not installed
2025-05-24 19:08:46,724:INFO:             autoviz: Not installed
2025-05-24 19:08:46,724:INFO:           fairlearn: Not installed
2025-05-24 19:08:46,724:INFO:          deepchecks: Not installed
2025-05-24 19:08:46,724:INFO:             xgboost: Not installed
2025-05-24 19:08:46,724:INFO:            catboost: Not installed
2025-05-24 19:08:46,724:INFO:              kmodes: Not installed
2025-05-24 19:08:46,724:INFO:             mlxtend: Not installed
2025-05-24 19:08:46,724:INFO:       statsforecast: Not installed
2025-05-24 19:08:46,724:INFO:        tune_sklearn: Not installed
2025-05-24 19:08:46,724:INFO:                 ray: Not installed
2025-05-24 19:08:46,724:INFO:            hyperopt: Not installed
2025-05-24 19:08:46,724:INFO:              optuna: Not installed
2025-05-24 19:08:46,724:INFO:               skopt: Not installed
2025-05-24 19:08:46,724:INFO:              mlflow: Not installed
2025-05-24 19:08:46,724:INFO:              gradio: Not installed
2025-05-24 19:08:46,724:INFO:             fastapi: 0.115.12
2025-05-24 19:08:46,724:INFO:             uvicorn: 0.34.2
2025-05-24 19:08:46,724:INFO:              m2cgen: Not installed
2025-05-24 19:08:46,724:INFO:           evidently: Not installed
2025-05-24 19:08:46,724:INFO:               fugue: Not installed
2025-05-24 19:08:46,724:INFO:           streamlit: Not installed
2025-05-24 19:08:46,724:INFO:             prophet: Not installed
2025-05-24 19:08:46,724:INFO:None
2025-05-24 19:08:46,724:INFO:Set up data.
2025-05-24 19:08:46,731:INFO:Set up folding strategy.
2025-05-24 19:08:46,732:INFO:Set up train/test split.
2025-05-24 19:08:46,738:INFO:Set up index.
2025-05-24 19:08:46,738:INFO:Assigning column types.
2025-05-24 19:08:46,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:08:46,790:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:08:46,793:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:08:46,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:46,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:46,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:08:46,874:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:08:46,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:46,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:46,903:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:08:46,951:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:08:46,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:46,984:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,033:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:08:47,067:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,068:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:08:47,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:08:47,228:INFO:Preparing preprocessing pipeline...
2025-05-24 19:08:47,229:INFO:Set up simple imputation.
2025-05-24 19:08:47,234:INFO:Set up encoding of ordinal features.
2025-05-24 19:08:47,244:INFO:Set up encoding of categorical features.
2025-05-24 19:09:52,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:09:52,764:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:09:52,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:09:52,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:09:53,365:INFO:PyCaret ClassificationExperiment
2025-05-24 19:09:53,365:INFO:Logging name: clf-default-name
2025-05-24 19:09:53,365:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:09:53,365:INFO:version 3.3.2
2025-05-24 19:09:53,365:INFO:Initializing setup()
2025-05-24 19:09:53,365:INFO:self.USI: dcb1
2025-05-24 19:09:53,365:INFO:self._variable_keys: {'data', 'idx', 'fold_generator', 'log_plots_param', 'is_multiclass', 'html_param', 'memory', 'seed', 'X_test', 'exp_id', 'X_train', 'n_jobs_param', 'y_train', 'fix_imbalance', 'target_param', 'y_test', 'pipeline', 'X', 'USI', 'fold_groups_param', 'y', '_available_plots', 'gpu_param', '_ml_usecase', 'logging_param', 'gpu_n_jobs_param', 'fold_shuffle_param', 'exp_name_log'}
2025-05-24 19:09:53,365:INFO:Checking environment
2025-05-24 19:09:53,365:INFO:python_version: 3.10.17
2025-05-24 19:09:53,365:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:09:53,365:INFO:machine: x86_64
2025-05-24 19:09:53,367:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:09:53,368:INFO:Memory: svmem(total=16407515136, available=8915509248, percent=45.7, used=6183092224, free=806834176, active=2136899584, inactive=11575980032, buffers=287920128, cached=9129668608, shared=959262720, slab=786931712)
2025-05-24 19:09:53,369:INFO:Physical Core: 4
2025-05-24 19:09:53,369:INFO:Logical Core: 8
2025-05-24 19:09:53,369:INFO:Checking libraries
2025-05-24 19:09:53,369:INFO:System:
2025-05-24 19:09:53,369:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:09:53,369:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:09:53,369:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:09:53,369:INFO:PyCaret required dependencies:
2025-05-24 19:09:53,391:INFO:                 pip: 25.1.1
2025-05-24 19:09:53,391:INFO:          setuptools: 65.5.0
2025-05-24 19:09:53,391:INFO:             pycaret: 3.3.2
2025-05-24 19:09:53,391:INFO:             IPython: 8.36.0
2025-05-24 19:09:53,391:INFO:          ipywidgets: 8.1.7
2025-05-24 19:09:53,392:INFO:                tqdm: 4.67.1
2025-05-24 19:09:53,392:INFO:               numpy: 1.26.4
2025-05-24 19:09:53,392:INFO:              pandas: 2.1.4
2025-05-24 19:09:53,392:INFO:              jinja2: 3.1.6
2025-05-24 19:09:53,392:INFO:               scipy: 1.11.4
2025-05-24 19:09:53,392:INFO:              joblib: 1.3.2
2025-05-24 19:09:53,392:INFO:             sklearn: 1.4.2
2025-05-24 19:09:53,392:INFO:                pyod: 2.0.5
2025-05-24 19:09:53,392:INFO:            imblearn: 0.13.0
2025-05-24 19:09:53,392:INFO:   category_encoders: 2.7.0
2025-05-24 19:09:53,392:INFO:            lightgbm: 4.6.0
2025-05-24 19:09:53,392:INFO:               numba: 0.61.2
2025-05-24 19:09:53,392:INFO:            requests: 2.32.3
2025-05-24 19:09:53,392:INFO:          matplotlib: 3.7.5
2025-05-24 19:09:53,392:INFO:          scikitplot: 0.3.7
2025-05-24 19:09:53,393:INFO:         yellowbrick: 1.5
2025-05-24 19:09:53,393:INFO:              plotly: 5.24.1
2025-05-24 19:09:53,393:INFO:    plotly-resampler: Not installed
2025-05-24 19:09:53,393:INFO:             kaleido: 0.2.1
2025-05-24 19:09:53,393:INFO:           schemdraw: 0.15
2025-05-24 19:09:53,393:INFO:         statsmodels: 0.14.4
2025-05-24 19:09:53,393:INFO:              sktime: 0.26.0
2025-05-24 19:09:53,393:INFO:               tbats: 1.1.3
2025-05-24 19:09:53,393:INFO:            pmdarima: 2.0.4
2025-05-24 19:09:53,393:INFO:              psutil: 7.0.0
2025-05-24 19:09:53,393:INFO:          markupsafe: 3.0.2
2025-05-24 19:09:53,393:INFO:             pickle5: Not installed
2025-05-24 19:09:53,393:INFO:         cloudpickle: 3.1.1
2025-05-24 19:09:53,393:INFO:         deprecation: 2.1.0
2025-05-24 19:09:53,393:INFO:              xxhash: 3.5.0
2025-05-24 19:09:53,394:INFO:           wurlitzer: 3.1.1
2025-05-24 19:09:53,394:INFO:PyCaret optional dependencies:
2025-05-24 19:09:53,778:INFO:                shap: Not installed
2025-05-24 19:09:53,778:INFO:           interpret: Not installed
2025-05-24 19:09:53,778:INFO:                umap: Not installed
2025-05-24 19:09:53,778:INFO:     ydata_profiling: Not installed
2025-05-24 19:09:53,779:INFO:  explainerdashboard: Not installed
2025-05-24 19:09:53,779:INFO:             autoviz: Not installed
2025-05-24 19:09:53,779:INFO:           fairlearn: Not installed
2025-05-24 19:09:53,779:INFO:          deepchecks: Not installed
2025-05-24 19:09:53,779:INFO:             xgboost: Not installed
2025-05-24 19:09:53,779:INFO:            catboost: Not installed
2025-05-24 19:09:53,779:INFO:              kmodes: Not installed
2025-05-24 19:09:53,779:INFO:             mlxtend: Not installed
2025-05-24 19:09:53,779:INFO:       statsforecast: Not installed
2025-05-24 19:09:53,779:INFO:        tune_sklearn: Not installed
2025-05-24 19:09:53,779:INFO:                 ray: Not installed
2025-05-24 19:09:53,779:INFO:            hyperopt: Not installed
2025-05-24 19:09:53,779:INFO:              optuna: Not installed
2025-05-24 19:09:53,779:INFO:               skopt: Not installed
2025-05-24 19:09:53,779:INFO:              mlflow: Not installed
2025-05-24 19:09:53,779:INFO:              gradio: Not installed
2025-05-24 19:09:53,779:INFO:             fastapi: 0.115.12
2025-05-24 19:09:53,779:INFO:             uvicorn: 0.34.2
2025-05-24 19:09:53,779:INFO:              m2cgen: Not installed
2025-05-24 19:09:53,779:INFO:           evidently: Not installed
2025-05-24 19:09:53,779:INFO:               fugue: Not installed
2025-05-24 19:09:53,779:INFO:           streamlit: Not installed
2025-05-24 19:09:53,779:INFO:             prophet: Not installed
2025-05-24 19:09:53,779:INFO:None
2025-05-24 19:09:53,779:INFO:Set up data.
2025-05-24 19:09:53,786:INFO:Set up folding strategy.
2025-05-24 19:09:53,786:INFO:Set up train/test split.
2025-05-24 19:09:53,792:INFO:Set up index.
2025-05-24 19:09:53,793:INFO:Assigning column types.
2025-05-24 19:09:53,797:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:09:53,843:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:09:53,846:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:09:53,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:53,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:53,926:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:09:53,927:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:09:53,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:53,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:53,956:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:09:54,002:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:09:54,030:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,030:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:09:54,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,106:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:09:54,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:09:54,258:INFO:Preparing preprocessing pipeline...
2025-05-24 19:09:54,259:INFO:Set up simple imputation.
2025-05-24 19:09:54,263:INFO:Set up encoding of ordinal features.
2025-05-24 19:09:54,273:INFO:Set up encoding of categorical features.
2025-05-24 19:10:55,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:10:55,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:10:55,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:10:55,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:10:56,141:INFO:PyCaret ClassificationExperiment
2025-05-24 19:10:56,142:INFO:Logging name: clf-default-name
2025-05-24 19:10:56,142:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:10:56,142:INFO:version 3.3.2
2025-05-24 19:10:56,142:INFO:Initializing setup()
2025-05-24 19:10:56,142:INFO:self.USI: e2aa
2025-05-24 19:10:56,142:INFO:self._variable_keys: {'y_train', '_ml_usecase', '_available_plots', 'pipeline', 'y_test', 'memory', 'is_multiclass', 'exp_id', 'data', 'fold_generator', 'html_param', 'logging_param', 'X', 'fix_imbalance', 'X_test', 'gpu_n_jobs_param', 'idx', 'seed', 'exp_name_log', 'log_plots_param', 'n_jobs_param', 'USI', 'X_train', 'gpu_param', 'fold_shuffle_param', 'fold_groups_param', 'target_param', 'y'}
2025-05-24 19:10:56,142:INFO:Checking environment
2025-05-24 19:10:56,142:INFO:python_version: 3.10.17
2025-05-24 19:10:56,142:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:10:56,142:INFO:machine: x86_64
2025-05-24 19:10:56,144:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:10:56,144:INFO:Memory: svmem(total=16407515136, available=9023246336, percent=45.0, used=6042112000, free=910864384, active=2144612352, inactive=11429216256, buffers=288366592, cached=9166172160, shared=992514048, slab=789790720)
2025-05-24 19:10:56,145:INFO:Physical Core: 4
2025-05-24 19:10:56,145:INFO:Logical Core: 8
2025-05-24 19:10:56,145:INFO:Checking libraries
2025-05-24 19:10:56,145:INFO:System:
2025-05-24 19:10:56,145:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:10:56,146:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:10:56,146:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:10:56,146:INFO:PyCaret required dependencies:
2025-05-24 19:10:56,166:INFO:                 pip: 25.1.1
2025-05-24 19:10:56,166:INFO:          setuptools: 65.5.0
2025-05-24 19:10:56,166:INFO:             pycaret: 3.3.2
2025-05-24 19:10:56,166:INFO:             IPython: 8.36.0
2025-05-24 19:10:56,166:INFO:          ipywidgets: 8.1.7
2025-05-24 19:10:56,166:INFO:                tqdm: 4.67.1
2025-05-24 19:10:56,166:INFO:               numpy: 1.26.4
2025-05-24 19:10:56,166:INFO:              pandas: 2.1.4
2025-05-24 19:10:56,166:INFO:              jinja2: 3.1.6
2025-05-24 19:10:56,166:INFO:               scipy: 1.11.4
2025-05-24 19:10:56,166:INFO:              joblib: 1.3.2
2025-05-24 19:10:56,167:INFO:             sklearn: 1.4.2
2025-05-24 19:10:56,167:INFO:                pyod: 2.0.5
2025-05-24 19:10:56,167:INFO:            imblearn: 0.13.0
2025-05-24 19:10:56,167:INFO:   category_encoders: 2.6.2
2025-05-24 19:10:56,167:INFO:            lightgbm: 4.6.0
2025-05-24 19:10:56,167:INFO:               numba: 0.61.2
2025-05-24 19:10:56,167:INFO:            requests: 2.32.3
2025-05-24 19:10:56,167:INFO:          matplotlib: 3.7.5
2025-05-24 19:10:56,167:INFO:          scikitplot: 0.3.7
2025-05-24 19:10:56,167:INFO:         yellowbrick: 1.5
2025-05-24 19:10:56,167:INFO:              plotly: 5.24.1
2025-05-24 19:10:56,167:INFO:    plotly-resampler: Not installed
2025-05-24 19:10:56,167:INFO:             kaleido: 0.2.1
2025-05-24 19:10:56,167:INFO:           schemdraw: 0.15
2025-05-24 19:10:56,167:INFO:         statsmodels: 0.14.4
2025-05-24 19:10:56,167:INFO:              sktime: 0.26.0
2025-05-24 19:10:56,167:INFO:               tbats: 1.1.3
2025-05-24 19:10:56,167:INFO:            pmdarima: 2.0.4
2025-05-24 19:10:56,167:INFO:              psutil: 7.0.0
2025-05-24 19:10:56,167:INFO:          markupsafe: 3.0.2
2025-05-24 19:10:56,168:INFO:             pickle5: Not installed
2025-05-24 19:10:56,168:INFO:         cloudpickle: 3.1.1
2025-05-24 19:10:56,168:INFO:         deprecation: 2.1.0
2025-05-24 19:10:56,168:INFO:              xxhash: 3.5.0
2025-05-24 19:10:56,168:INFO:           wurlitzer: 3.1.1
2025-05-24 19:10:56,168:INFO:PyCaret optional dependencies:
2025-05-24 19:10:56,555:INFO:                shap: Not installed
2025-05-24 19:10:56,555:INFO:           interpret: Not installed
2025-05-24 19:10:56,555:INFO:                umap: Not installed
2025-05-24 19:10:56,555:INFO:     ydata_profiling: Not installed
2025-05-24 19:10:56,555:INFO:  explainerdashboard: Not installed
2025-05-24 19:10:56,555:INFO:             autoviz: Not installed
2025-05-24 19:10:56,555:INFO:           fairlearn: Not installed
2025-05-24 19:10:56,555:INFO:          deepchecks: Not installed
2025-05-24 19:10:56,555:INFO:             xgboost: Not installed
2025-05-24 19:10:56,555:INFO:            catboost: Not installed
2025-05-24 19:10:56,555:INFO:              kmodes: Not installed
2025-05-24 19:10:56,555:INFO:             mlxtend: Not installed
2025-05-24 19:10:56,555:INFO:       statsforecast: Not installed
2025-05-24 19:10:56,555:INFO:        tune_sklearn: Not installed
2025-05-24 19:10:56,556:INFO:                 ray: Not installed
2025-05-24 19:10:56,556:INFO:            hyperopt: Not installed
2025-05-24 19:10:56,556:INFO:              optuna: Not installed
2025-05-24 19:10:56,556:INFO:               skopt: Not installed
2025-05-24 19:10:56,556:INFO:              mlflow: Not installed
2025-05-24 19:10:56,556:INFO:              gradio: Not installed
2025-05-24 19:10:56,556:INFO:             fastapi: 0.115.12
2025-05-24 19:10:56,556:INFO:             uvicorn: 0.34.2
2025-05-24 19:10:56,556:INFO:              m2cgen: Not installed
2025-05-24 19:10:56,556:INFO:           evidently: Not installed
2025-05-24 19:10:56,556:INFO:               fugue: Not installed
2025-05-24 19:10:56,556:INFO:           streamlit: Not installed
2025-05-24 19:10:56,556:INFO:             prophet: Not installed
2025-05-24 19:10:56,556:INFO:None
2025-05-24 19:10:56,556:INFO:Set up data.
2025-05-24 19:10:56,563:INFO:Set up folding strategy.
2025-05-24 19:10:56,564:INFO:Set up train/test split.
2025-05-24 19:10:56,570:INFO:Set up index.
2025-05-24 19:10:56,570:INFO:Assigning column types.
2025-05-24 19:10:56,575:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:10:56,624:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,627:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,664:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,743:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,743:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,744:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:10:56,792:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,871:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:10:56,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,901:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:10:56,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:56,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:57,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:57,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:10:57,060:INFO:Preparing preprocessing pipeline...
2025-05-24 19:10:57,062:INFO:Set up simple imputation.
2025-05-24 19:10:57,066:INFO:Set up encoding of ordinal features.
2025-05-24 19:10:57,076:INFO:Set up encoding of categorical features.
2025-05-24 19:11:56,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:11:56,388:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:11:56,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:11:56,389:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:11:56,985:INFO:PyCaret ClassificationExperiment
2025-05-24 19:11:56,985:INFO:Logging name: clf-default-name
2025-05-24 19:11:56,985:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:11:56,985:INFO:version 3.3.2
2025-05-24 19:11:56,985:INFO:Initializing setup()
2025-05-24 19:11:56,985:INFO:self.USI: a626
2025-05-24 19:11:56,985:INFO:self._variable_keys: {'fold_shuffle_param', 'memory', 'X_test', 'log_plots_param', 'pipeline', 'exp_name_log', 'fix_imbalance', 'gpu_param', 'seed', 'X', 'fold_generator', '_ml_usecase', 'idx', 'html_param', 'y_train', 'exp_id', 'y', 'data', 'n_jobs_param', 'X_train', 'y_test', 'fold_groups_param', 'gpu_n_jobs_param', 'target_param', 'logging_param', 'USI', '_available_plots', 'is_multiclass'}
2025-05-24 19:11:56,985:INFO:Checking environment
2025-05-24 19:11:56,985:INFO:python_version: 3.10.17
2025-05-24 19:11:56,985:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:11:56,986:INFO:machine: x86_64
2025-05-24 19:11:56,987:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:11:56,988:INFO:Memory: svmem(total=16407515136, available=9398611968, percent=42.7, used=5821628416, free=1285480448, active=2236956672, inactive=11196657664, buffers=288641024, cached=9011765248, shared=837632000, slab=784605184)
2025-05-24 19:11:56,988:INFO:Physical Core: 4
2025-05-24 19:11:56,989:INFO:Logical Core: 8
2025-05-24 19:11:56,989:INFO:Checking libraries
2025-05-24 19:11:56,989:INFO:System:
2025-05-24 19:11:56,989:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:11:56,989:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:11:56,989:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:11:56,989:INFO:PyCaret required dependencies:
2025-05-24 19:11:57,011:INFO:                 pip: 25.1.1
2025-05-24 19:11:57,011:INFO:          setuptools: 65.5.0
2025-05-24 19:11:57,011:INFO:             pycaret: 3.3.2
2025-05-24 19:11:57,011:INFO:             IPython: 8.36.0
2025-05-24 19:11:57,011:INFO:          ipywidgets: 8.1.7
2025-05-24 19:11:57,011:INFO:                tqdm: 4.67.1
2025-05-24 19:11:57,011:INFO:               numpy: 1.26.4
2025-05-24 19:11:57,011:INFO:              pandas: 2.1.4
2025-05-24 19:11:57,011:INFO:              jinja2: 3.1.6
2025-05-24 19:11:57,011:INFO:               scipy: 1.11.4
2025-05-24 19:11:57,011:INFO:              joblib: 1.3.2
2025-05-24 19:11:57,011:INFO:             sklearn: 1.4.2
2025-05-24 19:11:57,011:INFO:                pyod: 2.0.5
2025-05-24 19:11:57,011:INFO:            imblearn: 0.13.0
2025-05-24 19:11:57,011:INFO:   category_encoders: 2.6.2
2025-05-24 19:11:57,011:INFO:            lightgbm: 4.6.0
2025-05-24 19:11:57,011:INFO:               numba: 0.61.2
2025-05-24 19:11:57,012:INFO:            requests: 2.32.3
2025-05-24 19:11:57,012:INFO:          matplotlib: 3.7.5
2025-05-24 19:11:57,012:INFO:          scikitplot: 0.3.7
2025-05-24 19:11:57,012:INFO:         yellowbrick: 1.5
2025-05-24 19:11:57,012:INFO:              plotly: 5.24.1
2025-05-24 19:11:57,012:INFO:    plotly-resampler: Not installed
2025-05-24 19:11:57,012:INFO:             kaleido: 0.2.1
2025-05-24 19:11:57,012:INFO:           schemdraw: 0.15
2025-05-24 19:11:57,012:INFO:         statsmodels: 0.14.4
2025-05-24 19:11:57,012:INFO:              sktime: 0.26.0
2025-05-24 19:11:57,012:INFO:               tbats: 1.1.3
2025-05-24 19:11:57,012:INFO:            pmdarima: 2.0.4
2025-05-24 19:11:57,012:INFO:              psutil: 7.0.0
2025-05-24 19:11:57,012:INFO:          markupsafe: 3.0.2
2025-05-24 19:11:57,012:INFO:             pickle5: Not installed
2025-05-24 19:11:57,012:INFO:         cloudpickle: 3.1.1
2025-05-24 19:11:57,013:INFO:         deprecation: 2.1.0
2025-05-24 19:11:57,013:INFO:              xxhash: 3.5.0
2025-05-24 19:11:57,013:INFO:           wurlitzer: 3.1.1
2025-05-24 19:11:57,013:INFO:PyCaret optional dependencies:
2025-05-24 19:11:57,396:INFO:                shap: Not installed
2025-05-24 19:11:57,396:INFO:           interpret: Not installed
2025-05-24 19:11:57,396:INFO:                umap: Not installed
2025-05-24 19:11:57,396:INFO:     ydata_profiling: Not installed
2025-05-24 19:11:57,396:INFO:  explainerdashboard: Not installed
2025-05-24 19:11:57,396:INFO:             autoviz: Not installed
2025-05-24 19:11:57,396:INFO:           fairlearn: Not installed
2025-05-24 19:11:57,396:INFO:          deepchecks: Not installed
2025-05-24 19:11:57,396:INFO:             xgboost: Not installed
2025-05-24 19:11:57,396:INFO:            catboost: Not installed
2025-05-24 19:11:57,396:INFO:              kmodes: Not installed
2025-05-24 19:11:57,397:INFO:             mlxtend: Not installed
2025-05-24 19:11:57,397:INFO:       statsforecast: Not installed
2025-05-24 19:11:57,397:INFO:        tune_sklearn: Not installed
2025-05-24 19:11:57,397:INFO:                 ray: Not installed
2025-05-24 19:11:57,397:INFO:            hyperopt: Not installed
2025-05-24 19:11:57,397:INFO:              optuna: Not installed
2025-05-24 19:11:57,397:INFO:               skopt: Not installed
2025-05-24 19:11:57,397:INFO:              mlflow: Not installed
2025-05-24 19:11:57,397:INFO:              gradio: Not installed
2025-05-24 19:11:57,397:INFO:             fastapi: 0.115.12
2025-05-24 19:11:57,397:INFO:             uvicorn: 0.34.2
2025-05-24 19:11:57,397:INFO:              m2cgen: Not installed
2025-05-24 19:11:57,397:INFO:           evidently: Not installed
2025-05-24 19:11:57,397:INFO:               fugue: Not installed
2025-05-24 19:11:57,397:INFO:           streamlit: Not installed
2025-05-24 19:11:57,397:INFO:             prophet: Not installed
2025-05-24 19:11:57,398:INFO:None
2025-05-24 19:11:57,398:INFO:Set up data.
2025-05-24 19:11:57,407:INFO:Set up folding strategy.
2025-05-24 19:11:57,407:INFO:Set up train/test split.
2025-05-24 19:11:57,413:INFO:Set up index.
2025-05-24 19:11:57,413:INFO:Assigning column types.
2025-05-24 19:11:57,418:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:11:57,463:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,466:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,497:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,497:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,545:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,573:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:11:57,620:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,650:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,696:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:11:57,724:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,724:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,725:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:11:57,798:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:11:57,874:INFO:Preparing preprocessing pipeline...
2025-05-24 19:11:57,875:INFO:Set up simple imputation.
2025-05-24 19:11:57,881:INFO:Set up encoding of ordinal features.
2025-05-24 19:11:57,891:INFO:Set up encoding of categorical features.
2025-05-24 19:12:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:12:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:12:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:12:06,206:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:12:06,806:INFO:PyCaret ClassificationExperiment
2025-05-24 19:12:06,806:INFO:Logging name: clf-default-name
2025-05-24 19:12:06,806:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:12:06,806:INFO:version 3.3.2
2025-05-24 19:12:06,806:INFO:Initializing setup()
2025-05-24 19:12:06,806:INFO:self.USI: 97b3
2025-05-24 19:12:06,806:INFO:self._variable_keys: {'data', 'y_test', 'y', '_ml_usecase', '_available_plots', 'fold_generator', 'n_jobs_param', 'logging_param', 'exp_name_log', 'log_plots_param', 'pipeline', 'X_train', 'gpu_param', 'X_test', 'y_train', 'is_multiclass', 'exp_id', 'gpu_n_jobs_param', 'fix_imbalance', 'fold_shuffle_param', 'html_param', 'target_param', 'memory', 'idx', 'fold_groups_param', 'USI', 'X', 'seed'}
2025-05-24 19:12:06,806:INFO:Checking environment
2025-05-24 19:12:06,807:INFO:python_version: 3.10.17
2025-05-24 19:12:06,807:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:12:06,807:INFO:machine: x86_64
2025-05-24 19:12:06,809:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:12:06,809:INFO:Memory: svmem(total=16407515136, available=9418862592, percent=42.6, used=5835096064, free=1304973312, active=2238672896, inactive=11201581056, buffers=288743424, cached=8978702336, shared=803909632, slab=784605184)
2025-05-24 19:12:06,810:INFO:Physical Core: 4
2025-05-24 19:12:06,810:INFO:Logical Core: 8
2025-05-24 19:12:06,810:INFO:Checking libraries
2025-05-24 19:12:06,810:INFO:System:
2025-05-24 19:12:06,810:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:12:06,810:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:12:06,810:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:12:06,810:INFO:PyCaret required dependencies:
2025-05-24 19:12:06,836:INFO:                 pip: 25.1.1
2025-05-24 19:12:06,836:INFO:          setuptools: 65.5.0
2025-05-24 19:12:06,836:INFO:             pycaret: 3.3.2
2025-05-24 19:12:06,836:INFO:             IPython: 8.36.0
2025-05-24 19:12:06,837:INFO:          ipywidgets: 8.1.7
2025-05-24 19:12:06,837:INFO:                tqdm: 4.67.1
2025-05-24 19:12:06,837:INFO:               numpy: 1.26.4
2025-05-24 19:12:06,837:INFO:              pandas: 2.1.4
2025-05-24 19:12:06,837:INFO:              jinja2: 3.1.6
2025-05-24 19:12:06,837:INFO:               scipy: 1.11.4
2025-05-24 19:12:06,837:INFO:              joblib: 1.3.2
2025-05-24 19:12:06,837:INFO:             sklearn: 1.4.2
2025-05-24 19:12:06,837:INFO:                pyod: 2.0.5
2025-05-24 19:12:06,837:INFO:            imblearn: 0.13.0
2025-05-24 19:12:06,837:INFO:   category_encoders: 2.6.2
2025-05-24 19:12:06,837:INFO:            lightgbm: 4.6.0
2025-05-24 19:12:06,837:INFO:               numba: 0.61.2
2025-05-24 19:12:06,837:INFO:            requests: 2.32.3
2025-05-24 19:12:06,837:INFO:          matplotlib: 3.7.5
2025-05-24 19:12:06,837:INFO:          scikitplot: 0.3.7
2025-05-24 19:12:06,838:INFO:         yellowbrick: 1.5
2025-05-24 19:12:06,838:INFO:              plotly: 5.24.1
2025-05-24 19:12:06,838:INFO:    plotly-resampler: Not installed
2025-05-24 19:12:06,838:INFO:             kaleido: 0.2.1
2025-05-24 19:12:06,838:INFO:           schemdraw: 0.15
2025-05-24 19:12:06,838:INFO:         statsmodels: 0.14.4
2025-05-24 19:12:06,838:INFO:              sktime: 0.26.0
2025-05-24 19:12:06,838:INFO:               tbats: 1.1.3
2025-05-24 19:12:06,838:INFO:            pmdarima: 2.0.4
2025-05-24 19:12:06,838:INFO:              psutil: 7.0.0
2025-05-24 19:12:06,838:INFO:          markupsafe: 3.0.2
2025-05-24 19:12:06,838:INFO:             pickle5: Not installed
2025-05-24 19:12:06,838:INFO:         cloudpickle: 3.1.1
2025-05-24 19:12:06,838:INFO:         deprecation: 2.1.0
2025-05-24 19:12:06,838:INFO:              xxhash: 3.5.0
2025-05-24 19:12:06,839:INFO:           wurlitzer: 3.1.1
2025-05-24 19:12:06,839:INFO:PyCaret optional dependencies:
2025-05-24 19:12:07,235:INFO:                shap: Not installed
2025-05-24 19:12:07,235:INFO:           interpret: Not installed
2025-05-24 19:12:07,235:INFO:                umap: Not installed
2025-05-24 19:12:07,235:INFO:     ydata_profiling: Not installed
2025-05-24 19:12:07,235:INFO:  explainerdashboard: Not installed
2025-05-24 19:12:07,235:INFO:             autoviz: Not installed
2025-05-24 19:12:07,235:INFO:           fairlearn: Not installed
2025-05-24 19:12:07,235:INFO:          deepchecks: Not installed
2025-05-24 19:12:07,235:INFO:             xgboost: Not installed
2025-05-24 19:12:07,235:INFO:            catboost: Not installed
2025-05-24 19:12:07,235:INFO:              kmodes: Not installed
2025-05-24 19:12:07,235:INFO:             mlxtend: Not installed
2025-05-24 19:12:07,235:INFO:       statsforecast: Not installed
2025-05-24 19:12:07,236:INFO:        tune_sklearn: Not installed
2025-05-24 19:12:07,236:INFO:                 ray: Not installed
2025-05-24 19:12:07,236:INFO:            hyperopt: Not installed
2025-05-24 19:12:07,236:INFO:              optuna: Not installed
2025-05-24 19:12:07,236:INFO:               skopt: Not installed
2025-05-24 19:12:07,236:INFO:              mlflow: Not installed
2025-05-24 19:12:07,236:INFO:              gradio: Not installed
2025-05-24 19:12:07,236:INFO:             fastapi: 0.115.12
2025-05-24 19:12:07,236:INFO:             uvicorn: 0.34.2
2025-05-24 19:12:07,236:INFO:              m2cgen: Not installed
2025-05-24 19:12:07,236:INFO:           evidently: Not installed
2025-05-24 19:12:07,236:INFO:               fugue: Not installed
2025-05-24 19:12:07,236:INFO:           streamlit: Not installed
2025-05-24 19:12:07,236:INFO:             prophet: Not installed
2025-05-24 19:12:07,236:INFO:None
2025-05-24 19:12:07,236:INFO:Set up data.
2025-05-24 19:12:07,243:INFO:Set up folding strategy.
2025-05-24 19:12:07,243:INFO:Set up train/test split.
2025-05-24 19:12:07,249:INFO:Set up index.
2025-05-24 19:12:07,249:INFO:Assigning column types.
2025-05-24 19:12:07,253:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:12:07,301:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,304:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,337:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,386:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:12:07,464:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,493:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,493:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,542:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:12:07,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,572:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:12:07,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:12:07,728:INFO:Preparing preprocessing pipeline...
2025-05-24 19:12:07,730:INFO:Set up simple imputation.
2025-05-24 19:12:07,734:INFO:Set up encoding of ordinal features.
2025-05-24 19:12:07,744:INFO:Set up encoding of categorical features.
2025-05-24 19:13:20,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:13:20,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:13:20,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:13:20,171:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:13:20,766:INFO:PyCaret ClassificationExperiment
2025-05-24 19:13:20,766:INFO:Logging name: clf-default-name
2025-05-24 19:13:20,766:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:13:20,766:INFO:version 3.3.2
2025-05-24 19:13:20,766:INFO:Initializing setup()
2025-05-24 19:13:20,766:INFO:self.USI: 3f6e
2025-05-24 19:13:20,766:INFO:self._variable_keys: {'is_multiclass', 'memory', 'target_param', 'pipeline', 'X', 'fold_groups_param', 'gpu_param', 'data', 'log_plots_param', 'fold_shuffle_param', 'X_train', 'exp_id', 'idx', 'X_test', 'y_test', 'n_jobs_param', 'exp_name_log', 'y_train', 'gpu_n_jobs_param', 'seed', 'USI', 'html_param', '_ml_usecase', 'logging_param', 'fold_generator', 'y', 'fix_imbalance', '_available_plots'}
2025-05-24 19:13:20,766:INFO:Checking environment
2025-05-24 19:13:20,766:INFO:python_version: 3.10.17
2025-05-24 19:13:20,766:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:13:20,766:INFO:machine: x86_64
2025-05-24 19:13:20,768:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:13:20,768:INFO:Memory: svmem(total=16407515136, available=9334247424, percent=43.1, used=5908856832, free=1219854336, active=2247192576, inactive=11256066048, buffers=289083392, cached=8989720576, shared=814768128, slab=784785408)
2025-05-24 19:13:20,769:INFO:Physical Core: 4
2025-05-24 19:13:20,769:INFO:Logical Core: 8
2025-05-24 19:13:20,769:INFO:Checking libraries
2025-05-24 19:13:20,769:INFO:System:
2025-05-24 19:13:20,769:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:13:20,769:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:13:20,769:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:13:20,769:INFO:PyCaret required dependencies:
2025-05-24 19:13:20,789:INFO:                 pip: 25.1.1
2025-05-24 19:13:20,789:INFO:          setuptools: 65.5.0
2025-05-24 19:13:20,789:INFO:             pycaret: 3.3.2
2025-05-24 19:13:20,789:INFO:             IPython: 8.36.0
2025-05-24 19:13:20,789:INFO:          ipywidgets: 8.1.7
2025-05-24 19:13:20,789:INFO:                tqdm: 4.67.1
2025-05-24 19:13:20,789:INFO:               numpy: 1.26.4
2025-05-24 19:13:20,790:INFO:              pandas: 2.1.4
2025-05-24 19:13:20,790:INFO:              jinja2: 3.1.6
2025-05-24 19:13:20,790:INFO:               scipy: 1.11.4
2025-05-24 19:13:20,790:INFO:              joblib: 1.3.2
2025-05-24 19:13:20,790:INFO:             sklearn: 1.4.2
2025-05-24 19:13:20,790:INFO:                pyod: 2.0.5
2025-05-24 19:13:20,790:INFO:            imblearn: 0.13.0
2025-05-24 19:13:20,790:INFO:   category_encoders: 2.6.2
2025-05-24 19:13:20,790:INFO:            lightgbm: 4.6.0
2025-05-24 19:13:20,790:INFO:               numba: 0.61.2
2025-05-24 19:13:20,790:INFO:            requests: 2.32.3
2025-05-24 19:13:20,790:INFO:          matplotlib: 3.7.5
2025-05-24 19:13:20,790:INFO:          scikitplot: 0.3.7
2025-05-24 19:13:20,790:INFO:         yellowbrick: 1.5
2025-05-24 19:13:20,790:INFO:              plotly: 5.24.1
2025-05-24 19:13:20,790:INFO:    plotly-resampler: Not installed
2025-05-24 19:13:20,790:INFO:             kaleido: 0.2.1
2025-05-24 19:13:20,790:INFO:           schemdraw: 0.15
2025-05-24 19:13:20,790:INFO:         statsmodels: 0.14.4
2025-05-24 19:13:20,790:INFO:              sktime: 0.26.0
2025-05-24 19:13:20,790:INFO:               tbats: 1.1.3
2025-05-24 19:13:20,790:INFO:            pmdarima: 2.0.4
2025-05-24 19:13:20,790:INFO:              psutil: 7.0.0
2025-05-24 19:13:20,790:INFO:          markupsafe: 3.0.2
2025-05-24 19:13:20,790:INFO:             pickle5: Not installed
2025-05-24 19:13:20,790:INFO:         cloudpickle: 3.1.1
2025-05-24 19:13:20,790:INFO:         deprecation: 2.1.0
2025-05-24 19:13:20,790:INFO:              xxhash: 3.5.0
2025-05-24 19:13:20,791:INFO:           wurlitzer: 3.1.1
2025-05-24 19:13:20,791:INFO:PyCaret optional dependencies:
2025-05-24 19:13:21,177:INFO:                shap: Not installed
2025-05-24 19:13:21,177:INFO:           interpret: Not installed
2025-05-24 19:13:21,177:INFO:                umap: Not installed
2025-05-24 19:13:21,177:INFO:     ydata_profiling: Not installed
2025-05-24 19:13:21,177:INFO:  explainerdashboard: Not installed
2025-05-24 19:13:21,177:INFO:             autoviz: Not installed
2025-05-24 19:13:21,177:INFO:           fairlearn: Not installed
2025-05-24 19:13:21,177:INFO:          deepchecks: Not installed
2025-05-24 19:13:21,177:INFO:             xgboost: Not installed
2025-05-24 19:13:21,177:INFO:            catboost: Not installed
2025-05-24 19:13:21,177:INFO:              kmodes: Not installed
2025-05-24 19:13:21,177:INFO:             mlxtend: Not installed
2025-05-24 19:13:21,177:INFO:       statsforecast: Not installed
2025-05-24 19:13:21,178:INFO:        tune_sklearn: Not installed
2025-05-24 19:13:21,178:INFO:                 ray: Not installed
2025-05-24 19:13:21,178:INFO:            hyperopt: Not installed
2025-05-24 19:13:21,178:INFO:              optuna: Not installed
2025-05-24 19:13:21,178:INFO:               skopt: Not installed
2025-05-24 19:13:21,178:INFO:              mlflow: Not installed
2025-05-24 19:13:21,178:INFO:              gradio: Not installed
2025-05-24 19:13:21,178:INFO:             fastapi: 0.115.12
2025-05-24 19:13:21,178:INFO:             uvicorn: 0.34.2
2025-05-24 19:13:21,178:INFO:              m2cgen: Not installed
2025-05-24 19:13:21,178:INFO:           evidently: Not installed
2025-05-24 19:13:21,178:INFO:               fugue: Not installed
2025-05-24 19:13:21,178:INFO:           streamlit: Not installed
2025-05-24 19:13:21,178:INFO:             prophet: Not installed
2025-05-24 19:13:21,178:INFO:None
2025-05-24 19:13:21,178:INFO:Set up data.
2025-05-24 19:13:21,185:INFO:Set up folding strategy.
2025-05-24 19:13:21,185:INFO:Set up train/test split.
2025-05-24 19:13:21,191:INFO:Set up index.
2025-05-24 19:13:21,191:INFO:Assigning column types.
2025-05-24 19:13:21,196:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:13:21,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,245:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,327:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,356:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:13:21,404:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,433:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,481:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:13:21,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,511:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,511:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:13:21,588:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,588:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:13:21,668:INFO:Preparing preprocessing pipeline...
2025-05-24 19:13:21,669:INFO:Set up simple imputation.
2025-05-24 19:13:21,673:INFO:Set up encoding of ordinal features.
2025-05-24 19:13:21,683:INFO:Set up encoding of categorical features.
2025-05-24 19:17:29,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:17:29,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:17:29,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:17:29,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:17:30,443:INFO:PyCaret ClassificationExperiment
2025-05-24 19:17:30,444:INFO:Logging name: clf-default-name
2025-05-24 19:17:30,444:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:17:30,444:INFO:version 3.3.2
2025-05-24 19:17:30,444:INFO:Initializing setup()
2025-05-24 19:17:30,444:INFO:self.USI: 10f3
2025-05-24 19:17:30,444:INFO:self._variable_keys: {'_available_plots', 'fold_shuffle_param', 'exp_id', 'data', 'X_test', 'idx', 'fold_generator', 'X', 'n_jobs_param', 'fix_imbalance', '_ml_usecase', 'USI', 'X_train', 'y', 'log_plots_param', 'memory', 'y_train', 'gpu_param', 'y_test', 'gpu_n_jobs_param', 'target_param', 'logging_param', 'fold_groups_param', 'is_multiclass', 'pipeline', 'html_param', 'seed', 'exp_name_log'}
2025-05-24 19:17:30,444:INFO:Checking environment
2025-05-24 19:17:30,444:INFO:python_version: 3.10.17
2025-05-24 19:17:30,444:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:17:30,444:INFO:machine: x86_64
2025-05-24 19:17:30,446:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:17:30,446:INFO:Memory: svmem(total=16407515136, available=8976166912, percent=45.3, used=6103224320, free=859799552, active=2250244096, inactive=11372855296, buffers=290258944, cached=9154232320, shared=978481152, slab=789585920)
2025-05-24 19:17:30,447:INFO:Physical Core: 4
2025-05-24 19:17:30,447:INFO:Logical Core: 8
2025-05-24 19:17:30,447:INFO:Checking libraries
2025-05-24 19:17:30,447:INFO:System:
2025-05-24 19:17:30,447:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:17:30,447:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:17:30,447:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:17:30,447:INFO:PyCaret required dependencies:
2025-05-24 19:17:30,467:INFO:                 pip: 25.1.1
2025-05-24 19:17:30,467:INFO:          setuptools: 65.5.0
2025-05-24 19:17:30,468:INFO:             pycaret: 3.3.2
2025-05-24 19:17:30,468:INFO:             IPython: 8.36.0
2025-05-24 19:17:30,468:INFO:          ipywidgets: 8.1.7
2025-05-24 19:17:30,468:INFO:                tqdm: 4.67.1
2025-05-24 19:17:30,468:INFO:               numpy: 1.26.4
2025-05-24 19:17:30,468:INFO:              pandas: 2.1.4
2025-05-24 19:17:30,468:INFO:              jinja2: 3.1.6
2025-05-24 19:17:30,468:INFO:               scipy: 1.11.4
2025-05-24 19:17:30,468:INFO:              joblib: 1.3.2
2025-05-24 19:17:30,468:INFO:             sklearn: 1.4.2
2025-05-24 19:17:30,468:INFO:                pyod: 2.0.5
2025-05-24 19:17:30,468:INFO:            imblearn: 0.13.0
2025-05-24 19:17:30,468:INFO:   category_encoders: 2.6.2
2025-05-24 19:17:30,468:INFO:            lightgbm: 4.6.0
2025-05-24 19:17:30,468:INFO:               numba: 0.61.2
2025-05-24 19:17:30,468:INFO:            requests: 2.32.3
2025-05-24 19:17:30,468:INFO:          matplotlib: 3.7.5
2025-05-24 19:17:30,468:INFO:          scikitplot: 0.3.7
2025-05-24 19:17:30,468:INFO:         yellowbrick: 1.5
2025-05-24 19:17:30,468:INFO:              plotly: 5.24.1
2025-05-24 19:17:30,468:INFO:    plotly-resampler: Not installed
2025-05-24 19:17:30,468:INFO:             kaleido: 0.2.1
2025-05-24 19:17:30,468:INFO:           schemdraw: 0.15
2025-05-24 19:17:30,468:INFO:         statsmodels: 0.14.4
2025-05-24 19:17:30,468:INFO:              sktime: 0.26.0
2025-05-24 19:17:30,468:INFO:               tbats: 1.1.3
2025-05-24 19:17:30,468:INFO:            pmdarima: 2.0.4
2025-05-24 19:17:30,468:INFO:              psutil: 7.0.0
2025-05-24 19:17:30,468:INFO:          markupsafe: 3.0.2
2025-05-24 19:17:30,468:INFO:             pickle5: Not installed
2025-05-24 19:17:30,469:INFO:         cloudpickle: 3.1.1
2025-05-24 19:17:30,469:INFO:         deprecation: 2.1.0
2025-05-24 19:17:30,469:INFO:              xxhash: 3.5.0
2025-05-24 19:17:30,469:INFO:           wurlitzer: 3.1.1
2025-05-24 19:17:30,469:INFO:PyCaret optional dependencies:
2025-05-24 19:17:30,860:INFO:                shap: Not installed
2025-05-24 19:17:30,860:INFO:           interpret: Not installed
2025-05-24 19:17:30,860:INFO:                umap: Not installed
2025-05-24 19:17:30,860:INFO:     ydata_profiling: Not installed
2025-05-24 19:17:30,860:INFO:  explainerdashboard: Not installed
2025-05-24 19:17:30,860:INFO:             autoviz: Not installed
2025-05-24 19:17:30,860:INFO:           fairlearn: Not installed
2025-05-24 19:17:30,860:INFO:          deepchecks: Not installed
2025-05-24 19:17:30,860:INFO:             xgboost: Not installed
2025-05-24 19:17:30,860:INFO:            catboost: Not installed
2025-05-24 19:17:30,861:INFO:              kmodes: Not installed
2025-05-24 19:17:30,861:INFO:             mlxtend: Not installed
2025-05-24 19:17:30,861:INFO:       statsforecast: Not installed
2025-05-24 19:17:30,861:INFO:        tune_sklearn: Not installed
2025-05-24 19:17:30,861:INFO:                 ray: Not installed
2025-05-24 19:17:30,861:INFO:            hyperopt: Not installed
2025-05-24 19:17:30,861:INFO:              optuna: Not installed
2025-05-24 19:17:30,861:INFO:               skopt: Not installed
2025-05-24 19:17:30,861:INFO:              mlflow: Not installed
2025-05-24 19:17:30,861:INFO:              gradio: Not installed
2025-05-24 19:17:30,861:INFO:             fastapi: 0.115.12
2025-05-24 19:17:30,861:INFO:             uvicorn: 0.34.2
2025-05-24 19:17:30,861:INFO:              m2cgen: Not installed
2025-05-24 19:17:30,861:INFO:           evidently: Not installed
2025-05-24 19:17:30,861:INFO:               fugue: Not installed
2025-05-24 19:17:30,861:INFO:           streamlit: Not installed
2025-05-24 19:17:30,861:INFO:             prophet: Not installed
2025-05-24 19:17:30,861:INFO:None
2025-05-24 19:17:30,861:INFO:Set up data.
2025-05-24 19:17:30,868:INFO:Set up folding strategy.
2025-05-24 19:17:30,868:INFO:Set up train/test split.
2025-05-24 19:17:30,874:INFO:Set up index.
2025-05-24 19:17:30,874:INFO:Assigning column types.
2025-05-24 19:17:30,879:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:17:30,923:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:17:30,926:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:17:30,958:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:30,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:17:31,004:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:17:31,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,032:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:17:31,077:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:17:31,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,105:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,151:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:17:31,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,179:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:17:31,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:17:31,329:INFO:Preparing preprocessing pipeline...
2025-05-24 19:17:31,331:INFO:Set up simple imputation.
2025-05-24 19:17:31,335:INFO:Set up encoding of ordinal features.
2025-05-24 19:17:31,345:INFO:Set up encoding of categorical features.
2025-05-24 19:18:23,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:18:23,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:18:23,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:18:23,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:18:23,927:INFO:PyCaret ClassificationExperiment
2025-05-24 19:18:23,927:INFO:Logging name: clf-default-name
2025-05-24 19:18:23,927:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:18:23,927:INFO:version 3.3.2
2025-05-24 19:18:23,927:INFO:Initializing setup()
2025-05-24 19:18:23,928:INFO:self.USI: 30bb
2025-05-24 19:18:23,928:INFO:self._variable_keys: {'gpu_n_jobs_param', 'exp_id', 'X_test', 'fold_groups_param', 'USI', 'fold_generator', 'y_test', 'memory', 'target_param', 'pipeline', 'idx', 'gpu_param', '_ml_usecase', 'exp_name_log', 'seed', 'y_train', 'fix_imbalance', 'is_multiclass', 'data', 'y', '_available_plots', 'X_train', 'X', 'html_param', 'fold_shuffle_param', 'logging_param', 'log_plots_param', 'n_jobs_param'}
2025-05-24 19:18:23,928:INFO:Checking environment
2025-05-24 19:18:23,928:INFO:python_version: 3.10.17
2025-05-24 19:18:23,928:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:18:23,928:INFO:machine: x86_64
2025-05-24 19:18:23,930:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:18:23,930:INFO:Memory: svmem(total=16407515136, available=8998473728, percent=45.2, used=6100905984, free=881680384, active=2250928128, inactive=11367833600, buffers=290594816, cached=9134333952, shared=958459904, slab=789581824)
2025-05-24 19:18:23,931:INFO:Physical Core: 4
2025-05-24 19:18:23,931:INFO:Logical Core: 8
2025-05-24 19:18:23,931:INFO:Checking libraries
2025-05-24 19:18:23,931:INFO:System:
2025-05-24 19:18:23,931:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:18:23,931:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:18:23,931:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:18:23,931:INFO:PyCaret required dependencies:
2025-05-24 19:18:23,951:INFO:                 pip: 25.1.1
2025-05-24 19:18:23,951:INFO:          setuptools: 65.5.0
2025-05-24 19:18:23,952:INFO:             pycaret: 3.3.2
2025-05-24 19:18:23,952:INFO:             IPython: 8.36.0
2025-05-24 19:18:23,952:INFO:          ipywidgets: 8.1.7
2025-05-24 19:18:23,952:INFO:                tqdm: 4.67.1
2025-05-24 19:18:23,952:INFO:               numpy: 1.26.4
2025-05-24 19:18:23,952:INFO:              pandas: 2.1.4
2025-05-24 19:18:23,952:INFO:              jinja2: 3.1.6
2025-05-24 19:18:23,952:INFO:               scipy: 1.11.4
2025-05-24 19:18:23,952:INFO:              joblib: 1.3.2
2025-05-24 19:18:23,952:INFO:             sklearn: 1.4.2
2025-05-24 19:18:23,952:INFO:                pyod: 2.0.5
2025-05-24 19:18:23,952:INFO:            imblearn: 0.13.0
2025-05-24 19:18:23,952:INFO:   category_encoders: 2.6.2
2025-05-24 19:18:23,952:INFO:            lightgbm: 4.6.0
2025-05-24 19:18:23,952:INFO:               numba: 0.61.2
2025-05-24 19:18:23,952:INFO:            requests: 2.32.3
2025-05-24 19:18:23,952:INFO:          matplotlib: 3.7.5
2025-05-24 19:18:23,952:INFO:          scikitplot: 0.3.7
2025-05-24 19:18:23,952:INFO:         yellowbrick: 1.5
2025-05-24 19:18:23,952:INFO:              plotly: 5.24.1
2025-05-24 19:18:23,952:INFO:    plotly-resampler: Not installed
2025-05-24 19:18:23,952:INFO:             kaleido: 0.2.1
2025-05-24 19:18:23,952:INFO:           schemdraw: 0.15
2025-05-24 19:18:23,952:INFO:         statsmodels: 0.14.4
2025-05-24 19:18:23,952:INFO:              sktime: 0.26.0
2025-05-24 19:18:23,952:INFO:               tbats: 1.1.3
2025-05-24 19:18:23,952:INFO:            pmdarima: 2.0.4
2025-05-24 19:18:23,952:INFO:              psutil: 7.0.0
2025-05-24 19:18:23,952:INFO:          markupsafe: 3.0.2
2025-05-24 19:18:23,952:INFO:             pickle5: Not installed
2025-05-24 19:18:23,953:INFO:         cloudpickle: 3.1.1
2025-05-24 19:18:23,953:INFO:         deprecation: 2.1.0
2025-05-24 19:18:23,953:INFO:              xxhash: 3.5.0
2025-05-24 19:18:23,953:INFO:           wurlitzer: 3.1.1
2025-05-24 19:18:23,953:INFO:PyCaret optional dependencies:
2025-05-24 19:18:24,349:INFO:                shap: Not installed
2025-05-24 19:18:24,349:INFO:           interpret: Not installed
2025-05-24 19:18:24,349:INFO:                umap: Not installed
2025-05-24 19:18:24,350:INFO:     ydata_profiling: Not installed
2025-05-24 19:18:24,350:INFO:  explainerdashboard: Not installed
2025-05-24 19:18:24,350:INFO:             autoviz: Not installed
2025-05-24 19:18:24,350:INFO:           fairlearn: Not installed
2025-05-24 19:18:24,350:INFO:          deepchecks: Not installed
2025-05-24 19:18:24,350:INFO:             xgboost: Not installed
2025-05-24 19:18:24,350:INFO:            catboost: Not installed
2025-05-24 19:18:24,350:INFO:              kmodes: Not installed
2025-05-24 19:18:24,350:INFO:             mlxtend: Not installed
2025-05-24 19:18:24,350:INFO:       statsforecast: Not installed
2025-05-24 19:18:24,350:INFO:        tune_sklearn: Not installed
2025-05-24 19:18:24,350:INFO:                 ray: Not installed
2025-05-24 19:18:24,350:INFO:            hyperopt: Not installed
2025-05-24 19:18:24,350:INFO:              optuna: Not installed
2025-05-24 19:18:24,351:INFO:               skopt: Not installed
2025-05-24 19:18:24,351:INFO:              mlflow: Not installed
2025-05-24 19:18:24,351:INFO:              gradio: Not installed
2025-05-24 19:18:24,351:INFO:             fastapi: 0.115.12
2025-05-24 19:18:24,351:INFO:             uvicorn: 0.34.2
2025-05-24 19:18:24,351:INFO:              m2cgen: Not installed
2025-05-24 19:18:24,351:INFO:           evidently: Not installed
2025-05-24 19:18:24,351:INFO:               fugue: Not installed
2025-05-24 19:18:24,351:INFO:           streamlit: Not installed
2025-05-24 19:18:24,351:INFO:             prophet: Not installed
2025-05-24 19:18:24,351:INFO:None
2025-05-24 19:18:24,351:INFO:Set up data.
2025-05-24 19:18:24,361:INFO:Set up folding strategy.
2025-05-24 19:18:24,361:INFO:Set up train/test split.
2025-05-24 19:18:24,367:INFO:Set up index.
2025-05-24 19:18:24,368:INFO:Assigning column types.
2025-05-24 19:18:24,374:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:18:24,427:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,430:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,529:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,529:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,566:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:18:24,615:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,692:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:18:24,720:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,721:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:18:24,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:18:24,875:INFO:Preparing preprocessing pipeline...
2025-05-24 19:18:24,876:INFO:Set up simple imputation.
2025-05-24 19:18:24,880:INFO:Set up encoding of ordinal features.
2025-05-24 19:18:24,890:INFO:Set up encoding of categorical features.
2025-05-24 19:19:52,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:19:52,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:19:52,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:19:52,629:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:19:53,235:INFO:PyCaret ClassificationExperiment
2025-05-24 19:19:53,235:INFO:Logging name: clf-default-name
2025-05-24 19:19:53,235:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:19:53,236:INFO:version 3.3.2
2025-05-24 19:19:53,236:INFO:Initializing setup()
2025-05-24 19:19:53,236:INFO:self.USI: f7cd
2025-05-24 19:19:53,236:INFO:self._variable_keys: {'fold_generator', 'exp_id', 'exp_name_log', 'memory', 'gpu_n_jobs_param', 'pipeline', 'gpu_param', 'is_multiclass', 'fold_groups_param', 'log_plots_param', 'seed', 'n_jobs_param', 'fold_shuffle_param', 'idx', 'USI', 'X_train', 'X_test', 'fix_imbalance', 'y_train', 'X', 'y', 'data', 'target_param', '_ml_usecase', 'logging_param', 'y_test', '_available_plots', 'html_param'}
2025-05-24 19:19:53,236:INFO:Checking environment
2025-05-24 19:19:53,236:INFO:python_version: 3.10.17
2025-05-24 19:19:53,236:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:19:53,236:INFO:machine: x86_64
2025-05-24 19:19:53,238:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:19:53,238:INFO:Memory: svmem(total=16407515136, available=8979664896, percent=45.3, used=6100516864, free=862060544, active=2251698176, inactive=11369525248, buffers=291061760, cached=9153875968, shared=977690624, slab=789798912)
2025-05-24 19:19:53,239:INFO:Physical Core: 4
2025-05-24 19:19:53,239:INFO:Logical Core: 8
2025-05-24 19:19:53,239:INFO:Checking libraries
2025-05-24 19:19:53,239:INFO:System:
2025-05-24 19:19:53,239:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:19:53,239:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:19:53,239:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:19:53,239:INFO:PyCaret required dependencies:
2025-05-24 19:19:53,260:INFO:                 pip: 25.1.1
2025-05-24 19:19:53,260:INFO:          setuptools: 65.5.0
2025-05-24 19:19:53,260:INFO:             pycaret: 3.3.2
2025-05-24 19:19:53,260:INFO:             IPython: 8.36.0
2025-05-24 19:19:53,260:INFO:          ipywidgets: 8.1.7
2025-05-24 19:19:53,260:INFO:                tqdm: 4.67.1
2025-05-24 19:19:53,260:INFO:               numpy: 1.26.4
2025-05-24 19:19:53,260:INFO:              pandas: 2.1.4
2025-05-24 19:19:53,260:INFO:              jinja2: 3.1.6
2025-05-24 19:19:53,260:INFO:               scipy: 1.11.4
2025-05-24 19:19:53,260:INFO:              joblib: 1.3.2
2025-05-24 19:19:53,260:INFO:             sklearn: 1.4.2
2025-05-24 19:19:53,260:INFO:                pyod: 2.0.5
2025-05-24 19:19:53,260:INFO:            imblearn: 0.13.0
2025-05-24 19:19:53,260:INFO:   category_encoders: 2.6.2
2025-05-24 19:19:53,260:INFO:            lightgbm: 4.6.0
2025-05-24 19:19:53,261:INFO:               numba: 0.61.2
2025-05-24 19:19:53,261:INFO:            requests: 2.32.3
2025-05-24 19:19:53,261:INFO:          matplotlib: 3.7.5
2025-05-24 19:19:53,261:INFO:          scikitplot: 0.3.7
2025-05-24 19:19:53,261:INFO:         yellowbrick: 1.5
2025-05-24 19:19:53,261:INFO:              plotly: 5.24.1
2025-05-24 19:19:53,261:INFO:    plotly-resampler: Not installed
2025-05-24 19:19:53,261:INFO:             kaleido: 0.2.1
2025-05-24 19:19:53,261:INFO:           schemdraw: 0.15
2025-05-24 19:19:53,261:INFO:         statsmodels: 0.14.4
2025-05-24 19:19:53,261:INFO:              sktime: 0.26.0
2025-05-24 19:19:53,261:INFO:               tbats: 1.1.3
2025-05-24 19:19:53,261:INFO:            pmdarima: 2.0.4
2025-05-24 19:19:53,261:INFO:              psutil: 7.0.0
2025-05-24 19:19:53,261:INFO:          markupsafe: 3.0.2
2025-05-24 19:19:53,262:INFO:             pickle5: Not installed
2025-05-24 19:19:53,262:INFO:         cloudpickle: 3.1.1
2025-05-24 19:19:53,262:INFO:         deprecation: 2.1.0
2025-05-24 19:19:53,262:INFO:              xxhash: 3.5.0
2025-05-24 19:19:53,262:INFO:           wurlitzer: 3.1.1
2025-05-24 19:19:53,262:INFO:PyCaret optional dependencies:
2025-05-24 19:19:53,643:INFO:                shap: Not installed
2025-05-24 19:19:53,643:INFO:           interpret: Not installed
2025-05-24 19:19:53,643:INFO:                umap: Not installed
2025-05-24 19:19:53,643:INFO:     ydata_profiling: Not installed
2025-05-24 19:19:53,643:INFO:  explainerdashboard: Not installed
2025-05-24 19:19:53,643:INFO:             autoviz: Not installed
2025-05-24 19:19:53,643:INFO:           fairlearn: Not installed
2025-05-24 19:19:53,643:INFO:          deepchecks: Not installed
2025-05-24 19:19:53,643:INFO:             xgboost: Not installed
2025-05-24 19:19:53,643:INFO:            catboost: Not installed
2025-05-24 19:19:53,643:INFO:              kmodes: Not installed
2025-05-24 19:19:53,643:INFO:             mlxtend: Not installed
2025-05-24 19:19:53,643:INFO:       statsforecast: Not installed
2025-05-24 19:19:53,644:INFO:        tune_sklearn: Not installed
2025-05-24 19:19:53,644:INFO:                 ray: Not installed
2025-05-24 19:19:53,644:INFO:            hyperopt: Not installed
2025-05-24 19:19:53,644:INFO:              optuna: Not installed
2025-05-24 19:19:53,644:INFO:               skopt: Not installed
2025-05-24 19:19:53,644:INFO:              mlflow: Not installed
2025-05-24 19:19:53,644:INFO:              gradio: Not installed
2025-05-24 19:19:53,644:INFO:             fastapi: 0.115.12
2025-05-24 19:19:53,644:INFO:             uvicorn: 0.34.2
2025-05-24 19:19:53,644:INFO:              m2cgen: Not installed
2025-05-24 19:19:53,644:INFO:           evidently: Not installed
2025-05-24 19:19:53,644:INFO:               fugue: Not installed
2025-05-24 19:19:53,644:INFO:           streamlit: Not installed
2025-05-24 19:19:53,644:INFO:             prophet: Not installed
2025-05-24 19:19:53,644:INFO:None
2025-05-24 19:19:53,645:INFO:Set up data.
2025-05-24 19:19:53,654:INFO:Set up folding strategy.
2025-05-24 19:19:53,654:INFO:Set up train/test split.
2025-05-24 19:19:53,660:INFO:Set up index.
2025-05-24 19:19:53,660:INFO:Assigning column types.
2025-05-24 19:19:53,665:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:19:53,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,713:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,745:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,745:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,791:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,819:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,819:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,820:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:19:53,865:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,894:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:19:53,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:53,968:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:19:54,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:54,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:54,115:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:54,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:19:54,117:INFO:Preparing preprocessing pipeline...
2025-05-24 19:19:54,118:INFO:Set up simple imputation.
2025-05-24 19:19:54,123:INFO:Set up encoding of ordinal features.
2025-05-24 19:19:54,133:INFO:Set up encoding of categorical features.
2025-05-24 19:21:31,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:21:31,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:21:31,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:21:31,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:21:32,015:INFO:PyCaret ClassificationExperiment
2025-05-24 19:21:32,015:INFO:Logging name: clf-default-name
2025-05-24 19:21:32,015:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:21:32,015:INFO:version 3.3.2
2025-05-24 19:21:32,015:INFO:Initializing setup()
2025-05-24 19:21:32,015:INFO:self.USI: 4cc6
2025-05-24 19:21:32,015:INFO:self._variable_keys: {'fold_shuffle_param', 'fold_generator', '_ml_usecase', 'y_test', 'gpu_n_jobs_param', 'n_jobs_param', 'exp_id', 'fix_imbalance', 'X_test', 'data', 'logging_param', 'USI', 'is_multiclass', 'fold_groups_param', 'seed', 'html_param', 'target_param', 'pipeline', 'gpu_param', 'log_plots_param', '_available_plots', 'memory', 'idx', 'y_train', 'X', 'y', 'exp_name_log', 'X_train'}
2025-05-24 19:21:32,015:INFO:Checking environment
2025-05-24 19:21:32,015:INFO:python_version: 3.10.17
2025-05-24 19:21:32,015:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:21:32,015:INFO:machine: x86_64
2025-05-24 19:21:32,017:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:21:32,017:INFO:Memory: svmem(total=16407515136, available=8983224320, percent=45.2, used=6106599424, free=864935936, active=2252341248, inactive=11378937856, buffers=291602432, cached=9144377344, shared=968048640, slab=789798912)
2025-05-24 19:21:32,018:INFO:Physical Core: 4
2025-05-24 19:21:32,018:INFO:Logical Core: 8
2025-05-24 19:21:32,018:INFO:Checking libraries
2025-05-24 19:21:32,018:INFO:System:
2025-05-24 19:21:32,018:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:21:32,019:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:21:32,019:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:21:32,019:INFO:PyCaret required dependencies:
2025-05-24 19:21:32,048:INFO:                 pip: 25.1.1
2025-05-24 19:21:32,048:INFO:          setuptools: 65.5.0
2025-05-24 19:21:32,048:INFO:             pycaret: 3.3.2
2025-05-24 19:21:32,048:INFO:             IPython: 8.36.0
2025-05-24 19:21:32,048:INFO:          ipywidgets: 8.1.7
2025-05-24 19:21:32,048:INFO:                tqdm: 4.67.1
2025-05-24 19:21:32,048:INFO:               numpy: 1.26.4
2025-05-24 19:21:32,048:INFO:              pandas: 2.1.4
2025-05-24 19:21:32,049:INFO:              jinja2: 3.1.6
2025-05-24 19:21:32,049:INFO:               scipy: 1.11.4
2025-05-24 19:21:32,049:INFO:              joblib: 1.3.2
2025-05-24 19:21:32,049:INFO:             sklearn: 1.4.2
2025-05-24 19:21:32,049:INFO:                pyod: 2.0.5
2025-05-24 19:21:32,049:INFO:            imblearn: 0.13.0
2025-05-24 19:21:32,049:INFO:   category_encoders: 2.6.2
2025-05-24 19:21:32,049:INFO:            lightgbm: 4.6.0
2025-05-24 19:21:32,049:INFO:               numba: 0.61.2
2025-05-24 19:21:32,049:INFO:            requests: 2.32.3
2025-05-24 19:21:32,049:INFO:          matplotlib: 3.7.5
2025-05-24 19:21:32,049:INFO:          scikitplot: 0.3.7
2025-05-24 19:21:32,049:INFO:         yellowbrick: 1.5
2025-05-24 19:21:32,049:INFO:              plotly: 5.24.1
2025-05-24 19:21:32,049:INFO:    plotly-resampler: Not installed
2025-05-24 19:21:32,050:INFO:             kaleido: 0.2.1
2025-05-24 19:21:32,050:INFO:           schemdraw: 0.15
2025-05-24 19:21:32,050:INFO:         statsmodels: 0.14.4
2025-05-24 19:21:32,050:INFO:              sktime: 0.26.0
2025-05-24 19:21:32,050:INFO:               tbats: 1.1.3
2025-05-24 19:21:32,050:INFO:            pmdarima: 2.0.4
2025-05-24 19:21:32,050:INFO:              psutil: 7.0.0
2025-05-24 19:21:32,050:INFO:          markupsafe: 3.0.2
2025-05-24 19:21:32,050:INFO:             pickle5: Not installed
2025-05-24 19:21:32,050:INFO:         cloudpickle: 3.1.1
2025-05-24 19:21:32,050:INFO:         deprecation: 2.1.0
2025-05-24 19:21:32,050:INFO:              xxhash: 3.5.0
2025-05-24 19:21:32,050:INFO:           wurlitzer: 3.1.1
2025-05-24 19:21:32,050:INFO:PyCaret optional dependencies:
2025-05-24 19:21:32,442:INFO:                shap: Not installed
2025-05-24 19:21:32,442:INFO:           interpret: Not installed
2025-05-24 19:21:32,442:INFO:                umap: Not installed
2025-05-24 19:21:32,442:INFO:     ydata_profiling: Not installed
2025-05-24 19:21:32,442:INFO:  explainerdashboard: Not installed
2025-05-24 19:21:32,442:INFO:             autoviz: Not installed
2025-05-24 19:21:32,442:INFO:           fairlearn: Not installed
2025-05-24 19:21:32,442:INFO:          deepchecks: Not installed
2025-05-24 19:21:32,442:INFO:             xgboost: Not installed
2025-05-24 19:21:32,442:INFO:            catboost: Not installed
2025-05-24 19:21:32,442:INFO:              kmodes: Not installed
2025-05-24 19:21:32,442:INFO:             mlxtend: Not installed
2025-05-24 19:21:32,442:INFO:       statsforecast: Not installed
2025-05-24 19:21:32,442:INFO:        tune_sklearn: Not installed
2025-05-24 19:21:32,442:INFO:                 ray: Not installed
2025-05-24 19:21:32,442:INFO:            hyperopt: Not installed
2025-05-24 19:21:32,442:INFO:              optuna: Not installed
2025-05-24 19:21:32,442:INFO:               skopt: Not installed
2025-05-24 19:21:32,442:INFO:              mlflow: Not installed
2025-05-24 19:21:32,442:INFO:              gradio: Not installed
2025-05-24 19:21:32,442:INFO:             fastapi: 0.115.12
2025-05-24 19:21:32,443:INFO:             uvicorn: 0.34.2
2025-05-24 19:21:32,443:INFO:              m2cgen: Not installed
2025-05-24 19:21:32,443:INFO:           evidently: Not installed
2025-05-24 19:21:32,443:INFO:               fugue: Not installed
2025-05-24 19:21:32,443:INFO:           streamlit: Not installed
2025-05-24 19:21:32,443:INFO:             prophet: Not installed
2025-05-24 19:21:32,443:INFO:None
2025-05-24 19:21:32,443:INFO:Set up data.
2025-05-24 19:21:32,450:INFO:Set up folding strategy.
2025-05-24 19:21:32,450:INFO:Set up train/test split.
2025-05-24 19:21:32,456:INFO:Set up index.
2025-05-24 19:21:32,456:INFO:Assigning column types.
2025-05-24 19:21:32,460:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:21:32,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,509:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,541:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,587:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,617:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:21:32,662:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,691:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,738:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:21:32,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,767:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:21:32,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,917:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,917:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:21:32,919:INFO:Preparing preprocessing pipeline...
2025-05-24 19:21:32,920:INFO:Set up simple imputation.
2025-05-24 19:21:32,924:INFO:Set up encoding of ordinal features.
2025-05-24 19:21:32,935:INFO:Set up encoding of categorical features.
2025-05-24 19:25:49,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:25:49,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:25:49,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:25:49,951:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:25:50,544:INFO:PyCaret ClassificationExperiment
2025-05-24 19:25:50,544:INFO:Logging name: clf-default-name
2025-05-24 19:25:50,544:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:25:50,544:INFO:version 3.3.2
2025-05-24 19:25:50,544:INFO:Initializing setup()
2025-05-24 19:25:50,544:INFO:self.USI: 3ac1
2025-05-24 19:25:50,544:INFO:self._variable_keys: {'pipeline', 'idx', 'fold_shuffle_param', 'gpu_n_jobs_param', 'is_multiclass', 'logging_param', 'fix_imbalance', 'fold_groups_param', 'X_train', 'exp_id', 'log_plots_param', 'X', 'y', 'seed', 'data', 'USI', 'memory', 'y_train', 'y_test', 'html_param', 'exp_name_log', '_ml_usecase', 'fold_generator', 'X_test', '_available_plots', 'target_param', 'n_jobs_param', 'gpu_param'}
2025-05-24 19:25:50,544:INFO:Checking environment
2025-05-24 19:25:50,544:INFO:python_version: 3.10.17
2025-05-24 19:25:50,545:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:25:50,545:INFO:machine: x86_64
2025-05-24 19:25:50,547:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:25:50,547:INFO:Memory: svmem(total=16407515136, available=8921956352, percent=45.6, used=6155792384, free=795934720, active=2283917312, inactive=11407794176, buffers=293154816, cached=9162633216, shared=980123648, slab=790106112)
2025-05-24 19:25:50,548:INFO:Physical Core: 4
2025-05-24 19:25:50,548:INFO:Logical Core: 8
2025-05-24 19:25:50,548:INFO:Checking libraries
2025-05-24 19:25:50,548:INFO:System:
2025-05-24 19:25:50,548:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:25:50,548:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:25:50,548:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:25:50,548:INFO:PyCaret required dependencies:
2025-05-24 19:25:50,568:INFO:                 pip: 25.1.1
2025-05-24 19:25:50,568:INFO:          setuptools: 65.5.0
2025-05-24 19:25:50,568:INFO:             pycaret: 3.3.2
2025-05-24 19:25:50,569:INFO:             IPython: 8.36.0
2025-05-24 19:25:50,569:INFO:          ipywidgets: 8.1.7
2025-05-24 19:25:50,569:INFO:                tqdm: 4.67.1
2025-05-24 19:25:50,569:INFO:               numpy: 1.26.4
2025-05-24 19:25:50,569:INFO:              pandas: 2.1.4
2025-05-24 19:25:50,569:INFO:              jinja2: 3.1.6
2025-05-24 19:25:50,569:INFO:               scipy: 1.11.4
2025-05-24 19:25:50,569:INFO:              joblib: 1.3.2
2025-05-24 19:25:50,569:INFO:             sklearn: 1.4.2
2025-05-24 19:25:50,569:INFO:                pyod: 2.0.5
2025-05-24 19:25:50,569:INFO:            imblearn: 0.13.0
2025-05-24 19:25:50,569:INFO:   category_encoders: 2.6.2
2025-05-24 19:25:50,569:INFO:            lightgbm: 4.6.0
2025-05-24 19:25:50,569:INFO:               numba: 0.61.2
2025-05-24 19:25:50,569:INFO:            requests: 2.32.3
2025-05-24 19:25:50,569:INFO:          matplotlib: 3.7.5
2025-05-24 19:25:50,569:INFO:          scikitplot: 0.3.7
2025-05-24 19:25:50,570:INFO:         yellowbrick: 1.5
2025-05-24 19:25:50,570:INFO:              plotly: 5.24.1
2025-05-24 19:25:50,570:INFO:    plotly-resampler: Not installed
2025-05-24 19:25:50,570:INFO:             kaleido: 0.2.1
2025-05-24 19:25:50,570:INFO:           schemdraw: 0.15
2025-05-24 19:25:50,570:INFO:         statsmodels: 0.14.4
2025-05-24 19:25:50,570:INFO:              sktime: 0.26.0
2025-05-24 19:25:50,570:INFO:               tbats: 1.1.3
2025-05-24 19:25:50,570:INFO:            pmdarima: 2.0.4
2025-05-24 19:25:50,570:INFO:              psutil: 7.0.0
2025-05-24 19:25:50,570:INFO:          markupsafe: 3.0.2
2025-05-24 19:25:50,570:INFO:             pickle5: Not installed
2025-05-24 19:25:50,570:INFO:         cloudpickle: 3.1.1
2025-05-24 19:25:50,570:INFO:         deprecation: 2.1.0
2025-05-24 19:25:50,570:INFO:              xxhash: 3.5.0
2025-05-24 19:25:50,571:INFO:           wurlitzer: 3.1.1
2025-05-24 19:25:50,571:INFO:PyCaret optional dependencies:
2025-05-24 19:25:50,958:INFO:                shap: Not installed
2025-05-24 19:25:50,958:INFO:           interpret: Not installed
2025-05-24 19:25:50,959:INFO:                umap: Not installed
2025-05-24 19:25:50,959:INFO:     ydata_profiling: Not installed
2025-05-24 19:25:50,959:INFO:  explainerdashboard: Not installed
2025-05-24 19:25:50,959:INFO:             autoviz: Not installed
2025-05-24 19:25:50,959:INFO:           fairlearn: Not installed
2025-05-24 19:25:50,959:INFO:          deepchecks: Not installed
2025-05-24 19:25:50,959:INFO:             xgboost: Not installed
2025-05-24 19:25:50,959:INFO:            catboost: Not installed
2025-05-24 19:25:50,959:INFO:              kmodes: Not installed
2025-05-24 19:25:50,959:INFO:             mlxtend: Not installed
2025-05-24 19:25:50,959:INFO:       statsforecast: Not installed
2025-05-24 19:25:50,959:INFO:        tune_sklearn: Not installed
2025-05-24 19:25:50,959:INFO:                 ray: Not installed
2025-05-24 19:25:50,959:INFO:            hyperopt: Not installed
2025-05-24 19:25:50,959:INFO:              optuna: Not installed
2025-05-24 19:25:50,960:INFO:               skopt: Not installed
2025-05-24 19:25:50,960:INFO:              mlflow: Not installed
2025-05-24 19:25:50,960:INFO:              gradio: Not installed
2025-05-24 19:25:50,960:INFO:             fastapi: 0.115.12
2025-05-24 19:25:50,960:INFO:             uvicorn: 0.34.2
2025-05-24 19:25:50,960:INFO:              m2cgen: Not installed
2025-05-24 19:25:50,960:INFO:           evidently: Not installed
2025-05-24 19:25:50,960:INFO:               fugue: Not installed
2025-05-24 19:25:50,960:INFO:           streamlit: Not installed
2025-05-24 19:25:50,960:INFO:             prophet: Not installed
2025-05-24 19:25:50,960:INFO:None
2025-05-24 19:25:50,960:INFO:Set up data.
2025-05-24 19:25:50,977:INFO:Set up folding strategy.
2025-05-24 19:25:50,978:INFO:Set up train/test split.
2025-05-24 19:25:50,987:INFO:Set up index.
2025-05-24 19:25:50,987:INFO:Assigning column types.
2025-05-24 19:25:50,991:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:25:51,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,038:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,114:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,115:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,143:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:25:51,188:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,215:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,215:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,265:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:25:51,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,293:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:25:51,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:51,445:INFO:Preparing preprocessing pipeline...
2025-05-24 19:25:51,446:INFO:Set up label encoding.
2025-05-24 19:25:51,446:INFO:Set up simple imputation.
2025-05-24 19:25:51,451:INFO:Set up encoding of ordinal features.
2025-05-24 19:25:51,460:INFO:Set up encoding of categorical features.
2025-05-24 19:25:51,611:INFO:Finished creating preprocessing pipeline.
2025-05-24 19:25:51,670:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-24 19:25:51,670:INFO:Creating final display dataframe.
2025-05-24 19:25:52,056:INFO:Setup _display_container:                     Description                                   Value
0                    Session id                                     123
1                        Target                              GradeClass
2                   Target type                              Multiclass
3                Target mapping  0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4
4           Original data shape                              (2392, 15)
5        Transformed data shape                              (2392, 25)
6   Transformed train set shape                              (1674, 25)
7    Transformed test set shape                               (718, 25)
8               Ignore features                                       1
9              Numeric features                                       3
10         Categorical features                                       9
11                   Preprocess                                    True
12              Imputation type                                  simple
13           Numeric imputation                                    mean
14       Categorical imputation                                    mode
15     Maximum one-hot encoding                                      25
16              Encoding method                                    None
17               Fold Generator                         StratifiedKFold
18                  Fold Number                                      10
19                     CPU Jobs                                      -1
20                      Use GPU                                   False
21               Log Experiment                                   False
22              Experiment Name                        clf-default-name
23                          USI                                    3ac1
2025-05-24 19:25:52,136:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:52,136:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:52,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:52,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:25:52,211:INFO:setup() successfully completed in 1.67s...............
2025-05-24 19:25:52,211:INFO:Initializing compare_models()
2025-05-24 19:25:52,211:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-24 19:25:52,212:INFO:Checking exceptions
2025-05-24 19:25:52,216:INFO:Preparing display monitor
2025-05-24 19:25:52,219:INFO:Initializing Logistic Regression
2025-05-24 19:25:52,219:INFO:Total runtime is 1.8477439880371094e-06 minutes
2025-05-24 19:25:52,219:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:52,220:INFO:Initializing create_model()
2025-05-24 19:25:52,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:52,220:INFO:Checking exceptions
2025-05-24 19:25:52,220:INFO:Importing libraries
2025-05-24 19:25:52,220:INFO:Copying training dataset
2025-05-24 19:25:52,225:INFO:Defining folds
2025-05-24 19:25:52,226:INFO:Declaring metric variables
2025-05-24 19:25:52,226:INFO:Importing untrained model
2025-05-24 19:25:52,226:INFO:Logistic Regression Imported successfully
2025-05-24 19:25:52,226:INFO:Starting cross validation
2025-05-24 19:25:52,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:25:56,230:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,234:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,239:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,245:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,347:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,354:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,361:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,381:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,416:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,438:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:56,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,455:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,476:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,532:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,537:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,543:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:56,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:56,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,090:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:57,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:25:57,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:57,136:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,139:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,147:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:57,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,153:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,156:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,166:INFO:Calculating mean and std
2025-05-24 19:25:57,167:INFO:Creating metrics dataframe
2025-05-24 19:25:57,170:INFO:Uploading results into container
2025-05-24 19:25:57,171:INFO:Uploading model into container now
2025-05-24 19:25:57,171:INFO:_master_model_container: 1
2025-05-24 19:25:57,172:INFO:_display_container: 2
2025-05-24 19:25:57,172:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 19:25:57,172:INFO:create_model() successfully completed......................................
2025-05-24 19:25:57,278:INFO:SubProcess create_model() end ==================================
2025-05-24 19:25:57,278:INFO:Creating metrics dataframe
2025-05-24 19:25:57,282:INFO:Initializing K Neighbors Classifier
2025-05-24 19:25:57,282:INFO:Total runtime is 0.08438095251719156 minutes
2025-05-24 19:25:57,282:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:57,283:INFO:Initializing create_model()
2025-05-24 19:25:57,283:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:57,283:INFO:Checking exceptions
2025-05-24 19:25:57,283:INFO:Importing libraries
2025-05-24 19:25:57,283:INFO:Copying training dataset
2025-05-24 19:25:57,290:INFO:Defining folds
2025-05-24 19:25:57,290:INFO:Declaring metric variables
2025-05-24 19:25:57,290:INFO:Importing untrained model
2025-05-24 19:25:57,290:INFO:K Neighbors Classifier Imported successfully
2025-05-24 19:25:57,291:INFO:Starting cross validation
2025-05-24 19:25:57,293:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:25:57,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,686:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,686:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,687:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,692:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,697:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,697:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,706:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,709:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,710:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,717:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,723:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,876:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,880:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,883:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,884:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,888:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,891:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:57,904:INFO:Calculating mean and std
2025-05-24 19:25:57,905:INFO:Creating metrics dataframe
2025-05-24 19:25:57,907:INFO:Uploading results into container
2025-05-24 19:25:57,907:INFO:Uploading model into container now
2025-05-24 19:25:57,908:INFO:_master_model_container: 2
2025-05-24 19:25:57,908:INFO:_display_container: 2
2025-05-24 19:25:57,908:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-24 19:25:57,908:INFO:create_model() successfully completed......................................
2025-05-24 19:25:57,990:INFO:SubProcess create_model() end ==================================
2025-05-24 19:25:57,990:INFO:Creating metrics dataframe
2025-05-24 19:25:57,995:INFO:Initializing Naive Bayes
2025-05-24 19:25:57,995:INFO:Total runtime is 0.09625817934672037 minutes
2025-05-24 19:25:57,995:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:57,995:INFO:Initializing create_model()
2025-05-24 19:25:57,995:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:57,995:INFO:Checking exceptions
2025-05-24 19:25:57,996:INFO:Importing libraries
2025-05-24 19:25:57,996:INFO:Copying training dataset
2025-05-24 19:25:58,003:INFO:Defining folds
2025-05-24 19:25:58,003:INFO:Declaring metric variables
2025-05-24 19:25:58,003:INFO:Importing untrained model
2025-05-24 19:25:58,004:INFO:Naive Bayes Imported successfully
2025-05-24 19:25:58,004:INFO:Starting cross validation
2025-05-24 19:25:58,006:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:25:58,299:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,301:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,305:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,308:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,311:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,312:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,324:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,324:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,347:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:58,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,506:INFO:Calculating mean and std
2025-05-24 19:25:58,507:INFO:Creating metrics dataframe
2025-05-24 19:25:58,509:INFO:Uploading results into container
2025-05-24 19:25:58,509:INFO:Uploading model into container now
2025-05-24 19:25:58,510:INFO:_master_model_container: 3
2025-05-24 19:25:58,510:INFO:_display_container: 2
2025-05-24 19:25:58,510:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-24 19:25:58,510:INFO:create_model() successfully completed......................................
2025-05-24 19:25:58,590:INFO:SubProcess create_model() end ==================================
2025-05-24 19:25:58,590:INFO:Creating metrics dataframe
2025-05-24 19:25:58,594:INFO:Initializing Decision Tree Classifier
2025-05-24 19:25:58,595:INFO:Total runtime is 0.10625666777292887 minutes
2025-05-24 19:25:58,595:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:58,595:INFO:Initializing create_model()
2025-05-24 19:25:58,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:58,595:INFO:Checking exceptions
2025-05-24 19:25:58,595:INFO:Importing libraries
2025-05-24 19:25:58,595:INFO:Copying training dataset
2025-05-24 19:25:58,602:INFO:Defining folds
2025-05-24 19:25:58,602:INFO:Declaring metric variables
2025-05-24 19:25:58,603:INFO:Importing untrained model
2025-05-24 19:25:58,603:INFO:Decision Tree Classifier Imported successfully
2025-05-24 19:25:58,603:INFO:Starting cross validation
2025-05-24 19:25:58,606:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:25:58,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,913:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,923:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,923:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,926:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,947:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,949:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:58,952:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,131:INFO:Calculating mean and std
2025-05-24 19:25:59,132:INFO:Creating metrics dataframe
2025-05-24 19:25:59,133:INFO:Uploading results into container
2025-05-24 19:25:59,134:INFO:Uploading model into container now
2025-05-24 19:25:59,134:INFO:_master_model_container: 4
2025-05-24 19:25:59,134:INFO:_display_container: 2
2025-05-24 19:25:59,135:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-24 19:25:59,135:INFO:create_model() successfully completed......................................
2025-05-24 19:25:59,217:INFO:SubProcess create_model() end ==================================
2025-05-24 19:25:59,217:INFO:Creating metrics dataframe
2025-05-24 19:25:59,222:INFO:Initializing SVM - Linear Kernel
2025-05-24 19:25:59,222:INFO:Total runtime is 0.11671139399210612 minutes
2025-05-24 19:25:59,222:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:59,223:INFO:Initializing create_model()
2025-05-24 19:25:59,223:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:59,223:INFO:Checking exceptions
2025-05-24 19:25:59,223:INFO:Importing libraries
2025-05-24 19:25:59,223:INFO:Copying training dataset
2025-05-24 19:25:59,230:INFO:Defining folds
2025-05-24 19:25:59,231:INFO:Declaring metric variables
2025-05-24 19:25:59,231:INFO:Importing untrained model
2025-05-24 19:25:59,231:INFO:SVM - Linear Kernel Imported successfully
2025-05-24 19:25:59,232:INFO:Starting cross validation
2025-05-24 19:25:59,234:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:25:59,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,616:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,617:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,640:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,646:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,648:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,655:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,655:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,658:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,662:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,666:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,669:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,871:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,877:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:25:59,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:25:59,883:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,886:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,890:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:25:59,902:INFO:Calculating mean and std
2025-05-24 19:25:59,902:INFO:Creating metrics dataframe
2025-05-24 19:25:59,905:INFO:Uploading results into container
2025-05-24 19:25:59,905:INFO:Uploading model into container now
2025-05-24 19:25:59,905:INFO:_master_model_container: 5
2025-05-24 19:25:59,905:INFO:_display_container: 2
2025-05-24 19:25:59,906:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-24 19:25:59,906:INFO:create_model() successfully completed......................................
2025-05-24 19:25:59,995:INFO:SubProcess create_model() end ==================================
2025-05-24 19:25:59,995:INFO:Creating metrics dataframe
2025-05-24 19:25:59,999:INFO:Initializing Ridge Classifier
2025-05-24 19:25:59,999:INFO:Total runtime is 0.12965736786524454 minutes
2025-05-24 19:25:59,999:INFO:SubProcess create_model() called ==================================
2025-05-24 19:25:59,999:INFO:Initializing create_model()
2025-05-24 19:25:59,999:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:25:59,999:INFO:Checking exceptions
2025-05-24 19:25:59,999:INFO:Importing libraries
2025-05-24 19:25:59,999:INFO:Copying training dataset
2025-05-24 19:26:00,005:INFO:Defining folds
2025-05-24 19:26:00,005:INFO:Declaring metric variables
2025-05-24 19:26:00,005:INFO:Importing untrained model
2025-05-24 19:26:00,005:INFO:Ridge Classifier Imported successfully
2025-05-24 19:26:00,007:INFO:Starting cross validation
2025-05-24 19:26:00,009:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:00,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,319:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,349:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,354:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,356:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,359:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,361:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,363:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,368:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,505:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,508:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:00,510:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,510:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,514:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:00,517:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:00,528:INFO:Calculating mean and std
2025-05-24 19:26:00,528:INFO:Creating metrics dataframe
2025-05-24 19:26:00,530:INFO:Uploading results into container
2025-05-24 19:26:00,531:INFO:Uploading model into container now
2025-05-24 19:26:00,531:INFO:_master_model_container: 6
2025-05-24 19:26:00,531:INFO:_display_container: 2
2025-05-24 19:26:00,532:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-24 19:26:00,532:INFO:create_model() successfully completed......................................
2025-05-24 19:26:00,615:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:00,616:INFO:Creating metrics dataframe
2025-05-24 19:26:00,620:INFO:Initializing Random Forest Classifier
2025-05-24 19:26:00,620:INFO:Total runtime is 0.14002013206481934 minutes
2025-05-24 19:26:00,621:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:00,621:INFO:Initializing create_model()
2025-05-24 19:26:00,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:00,621:INFO:Checking exceptions
2025-05-24 19:26:00,621:INFO:Importing libraries
2025-05-24 19:26:00,621:INFO:Copying training dataset
2025-05-24 19:26:00,628:INFO:Defining folds
2025-05-24 19:26:00,628:INFO:Declaring metric variables
2025-05-24 19:26:00,629:INFO:Importing untrained model
2025-05-24 19:26:00,629:INFO:Random Forest Classifier Imported successfully
2025-05-24 19:26:00,629:INFO:Starting cross validation
2025-05-24 19:26:00,632:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:01,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,470:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,510:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,516:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,523:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,552:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,573:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,579:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,585:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:01,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,010:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,050:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,068:INFO:Calculating mean and std
2025-05-24 19:26:02,069:INFO:Creating metrics dataframe
2025-05-24 19:26:02,072:INFO:Uploading results into container
2025-05-24 19:26:02,073:INFO:Uploading model into container now
2025-05-24 19:26:02,074:INFO:_master_model_container: 7
2025-05-24 19:26:02,074:INFO:_display_container: 2
2025-05-24 19:26:02,074:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-24 19:26:02,075:INFO:create_model() successfully completed......................................
2025-05-24 19:26:02,160:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:02,161:INFO:Creating metrics dataframe
2025-05-24 19:26:02,165:INFO:Initializing Quadratic Discriminant Analysis
2025-05-24 19:26:02,165:INFO:Total runtime is 0.16576314369837442 minutes
2025-05-24 19:26:02,165:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:02,166:INFO:Initializing create_model()
2025-05-24 19:26:02,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:02,166:INFO:Checking exceptions
2025-05-24 19:26:02,166:INFO:Importing libraries
2025-05-24 19:26:02,166:INFO:Copying training dataset
2025-05-24 19:26:02,173:INFO:Defining folds
2025-05-24 19:26:02,173:INFO:Declaring metric variables
2025-05-24 19:26:02,173:INFO:Importing untrained model
2025-05-24 19:26:02,173:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-24 19:26:02,174:INFO:Starting cross validation
2025-05-24 19:26:02,176:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:02,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,399:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,410:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,412:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,413:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,430:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,439:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,503:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,505:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,508:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,510:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,511:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,511:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,514:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,514:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,529:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:26:02,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:02,675:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,677:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:02,692:INFO:Calculating mean and std
2025-05-24 19:26:02,693:INFO:Creating metrics dataframe
2025-05-24 19:26:02,695:INFO:Uploading results into container
2025-05-24 19:26:02,695:INFO:Uploading model into container now
2025-05-24 19:26:02,695:INFO:_master_model_container: 8
2025-05-24 19:26:02,695:INFO:_display_container: 2
2025-05-24 19:26:02,696:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-24 19:26:02,696:INFO:create_model() successfully completed......................................
2025-05-24 19:26:02,778:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:02,778:INFO:Creating metrics dataframe
2025-05-24 19:26:02,783:INFO:Initializing Ada Boost Classifier
2025-05-24 19:26:02,783:INFO:Total runtime is 0.17605994542439776 minutes
2025-05-24 19:26:02,783:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:02,783:INFO:Initializing create_model()
2025-05-24 19:26:02,783:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:02,783:INFO:Checking exceptions
2025-05-24 19:26:02,784:INFO:Importing libraries
2025-05-24 19:26:02,784:INFO:Copying training dataset
2025-05-24 19:26:02,790:INFO:Defining folds
2025-05-24 19:26:02,790:INFO:Declaring metric variables
2025-05-24 19:26:02,791:INFO:Importing untrained model
2025-05-24 19:26:02,791:INFO:Ada Boost Classifier Imported successfully
2025-05-24 19:26:02,791:INFO:Starting cross validation
2025-05-24 19:26:02,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:02,986:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:02,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,004:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,009:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,018:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,020:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,035:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,038:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,350:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,353:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,354:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,360:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,364:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,364:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,375:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,379:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,381:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,382:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,385:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:26:03,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,676:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:03,676:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,681:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:03,698:INFO:Calculating mean and std
2025-05-24 19:26:03,699:INFO:Creating metrics dataframe
2025-05-24 19:26:03,701:INFO:Uploading results into container
2025-05-24 19:26:03,701:INFO:Uploading model into container now
2025-05-24 19:26:03,701:INFO:_master_model_container: 9
2025-05-24 19:26:03,702:INFO:_display_container: 2
2025-05-24 19:26:03,702:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-24 19:26:03,702:INFO:create_model() successfully completed......................................
2025-05-24 19:26:03,783:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:03,784:INFO:Creating metrics dataframe
2025-05-24 19:26:03,788:INFO:Initializing Gradient Boosting Classifier
2025-05-24 19:26:03,788:INFO:Total runtime is 0.19281280438105264 minutes
2025-05-24 19:26:03,788:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:03,788:INFO:Initializing create_model()
2025-05-24 19:26:03,789:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:03,789:INFO:Checking exceptions
2025-05-24 19:26:03,789:INFO:Importing libraries
2025-05-24 19:26:03,789:INFO:Copying training dataset
2025-05-24 19:26:03,795:INFO:Defining folds
2025-05-24 19:26:03,795:INFO:Declaring metric variables
2025-05-24 19:26:03,796:INFO:Importing untrained model
2025-05-24 19:26:03,796:INFO:Gradient Boosting Classifier Imported successfully
2025-05-24 19:26:03,796:INFO:Starting cross validation
2025-05-24 19:26:03,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:06,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,526:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,527:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,529:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,532:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,533:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,536:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,537:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,539:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,540:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,542:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,552:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,586:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:06,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,601:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,601:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:06,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,384:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,398:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,402:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,419:INFO:Calculating mean and std
2025-05-24 19:26:08,420:INFO:Creating metrics dataframe
2025-05-24 19:26:08,422:INFO:Uploading results into container
2025-05-24 19:26:08,422:INFO:Uploading model into container now
2025-05-24 19:26:08,423:INFO:_master_model_container: 10
2025-05-24 19:26:08,423:INFO:_display_container: 2
2025-05-24 19:26:08,423:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-24 19:26:08,423:INFO:create_model() successfully completed......................................
2025-05-24 19:26:08,505:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:08,505:INFO:Creating metrics dataframe
2025-05-24 19:26:08,510:INFO:Initializing Linear Discriminant Analysis
2025-05-24 19:26:08,510:INFO:Total runtime is 0.2715114116668701 minutes
2025-05-24 19:26:08,510:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:08,511:INFO:Initializing create_model()
2025-05-24 19:26:08,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:08,511:INFO:Checking exceptions
2025-05-24 19:26:08,511:INFO:Importing libraries
2025-05-24 19:26:08,511:INFO:Copying training dataset
2025-05-24 19:26:08,517:INFO:Defining folds
2025-05-24 19:26:08,518:INFO:Declaring metric variables
2025-05-24 19:26:08,518:INFO:Importing untrained model
2025-05-24 19:26:08,518:INFO:Linear Discriminant Analysis Imported successfully
2025-05-24 19:26:08,519:INFO:Starting cross validation
2025-05-24 19:26:08,521:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:08,798:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,801:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,826:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,826:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,831:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,831:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,832:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,835:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,836:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,838:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,839:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,842:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,843:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,844:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,846:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,848:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,849:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,850:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,856:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,861:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:08,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:08,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,002:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,004:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:26:09,005:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,009:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,011:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:09,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,025:INFO:Calculating mean and std
2025-05-24 19:26:09,025:INFO:Creating metrics dataframe
2025-05-24 19:26:09,027:INFO:Uploading results into container
2025-05-24 19:26:09,028:INFO:Uploading model into container now
2025-05-24 19:26:09,028:INFO:_master_model_container: 11
2025-05-24 19:26:09,028:INFO:_display_container: 2
2025-05-24 19:26:09,029:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-24 19:26:09,029:INFO:create_model() successfully completed......................................
2025-05-24 19:26:09,111:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:09,111:INFO:Creating metrics dataframe
2025-05-24 19:26:09,115:INFO:Initializing Extra Trees Classifier
2025-05-24 19:26:09,116:INFO:Total runtime is 0.28160648345947265 minutes
2025-05-24 19:26:09,116:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:09,116:INFO:Initializing create_model()
2025-05-24 19:26:09,116:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:09,116:INFO:Checking exceptions
2025-05-24 19:26:09,117:INFO:Importing libraries
2025-05-24 19:26:09,117:INFO:Copying training dataset
2025-05-24 19:26:09,123:INFO:Defining folds
2025-05-24 19:26:09,123:INFO:Declaring metric variables
2025-05-24 19:26:09,124:INFO:Importing untrained model
2025-05-24 19:26:09,124:INFO:Extra Trees Classifier Imported successfully
2025-05-24 19:26:09,125:INFO:Starting cross validation
2025-05-24 19:26:09,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:26:09,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,946:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,953:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,960:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,982:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:09,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,400:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,402:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:26:10,404:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,408:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:26:10,424:INFO:Calculating mean and std
2025-05-24 19:26:10,426:INFO:Creating metrics dataframe
2025-05-24 19:26:10,432:INFO:Uploading results into container
2025-05-24 19:26:10,433:INFO:Uploading model into container now
2025-05-24 19:26:10,434:INFO:_master_model_container: 12
2025-05-24 19:26:10,435:INFO:_display_container: 2
2025-05-24 19:26:10,436:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-24 19:26:10,436:INFO:create_model() successfully completed......................................
2025-05-24 19:26:10,572:INFO:SubProcess create_model() end ==================================
2025-05-24 19:26:10,573:INFO:Creating metrics dataframe
2025-05-24 19:26:10,576:INFO:Initializing Light Gradient Boosting Machine
2025-05-24 19:26:10,577:INFO:Total runtime is 0.3059569279352824 minutes
2025-05-24 19:26:10,577:INFO:SubProcess create_model() called ==================================
2025-05-24 19:26:10,577:INFO:Initializing create_model()
2025-05-24 19:26:10,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11b748ac50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f1194209ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:26:10,577:INFO:Checking exceptions
2025-05-24 19:26:10,577:INFO:Importing libraries
2025-05-24 19:26:10,577:INFO:Copying training dataset
2025-05-24 19:26:10,584:INFO:Defining folds
2025-05-24 19:26:10,584:INFO:Declaring metric variables
2025-05-24 19:26:10,584:INFO:Importing untrained model
2025-05-24 19:26:10,585:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-24 19:26:10,585:INFO:Starting cross validation
2025-05-24 19:26:10,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:02,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:36:02,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:36:02,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:36:02,927:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-24 19:36:03,522:INFO:PyCaret ClassificationExperiment
2025-05-24 19:36:03,522:INFO:Logging name: clf-default-name
2025-05-24 19:36:03,522:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-24 19:36:03,522:INFO:version 3.3.2
2025-05-24 19:36:03,522:INFO:Initializing setup()
2025-05-24 19:36:03,523:INFO:self.USI: 4907
2025-05-24 19:36:03,523:INFO:self._variable_keys: {'_available_plots', 'fold_shuffle_param', 'fold_groups_param', '_ml_usecase', 'fix_imbalance', 'seed', 'y_train', 'html_param', 'idx', 'target_param', 'memory', 'n_jobs_param', 'exp_id', 'X', 'is_multiclass', 'gpu_n_jobs_param', 'exp_name_log', 'logging_param', 'USI', 'gpu_param', 'y_test', 'log_plots_param', 'fold_generator', 'data', 'X_train', 'X_test', 'pipeline', 'y'}
2025-05-24 19:36:03,523:INFO:Checking environment
2025-05-24 19:36:03,523:INFO:python_version: 3.10.17
2025-05-24 19:36:03,523:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-24 19:36:03,523:INFO:machine: x86_64
2025-05-24 19:36:03,525:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:36:03,525:INFO:Memory: svmem(total=16407515136, available=9050234880, percent=44.8, used=6113898496, free=1491714048, active=2342211584, inactive=10781630464, buffers=290164736, cached=8511737856, shared=893722624, slab=787251200)
2025-05-24 19:36:03,526:INFO:Physical Core: 4
2025-05-24 19:36:03,526:INFO:Logical Core: 8
2025-05-24 19:36:03,526:INFO:Checking libraries
2025-05-24 19:36:03,526:INFO:System:
2025-05-24 19:36:03,526:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-24 19:36:03,526:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-24 19:36:03,526:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-24 19:36:03,526:INFO:PyCaret required dependencies:
2025-05-24 19:36:03,547:INFO:                 pip: 25.1.1
2025-05-24 19:36:03,547:INFO:          setuptools: 65.5.0
2025-05-24 19:36:03,547:INFO:             pycaret: 3.3.2
2025-05-24 19:36:03,547:INFO:             IPython: 8.36.0
2025-05-24 19:36:03,547:INFO:          ipywidgets: 8.1.7
2025-05-24 19:36:03,547:INFO:                tqdm: 4.67.1
2025-05-24 19:36:03,547:INFO:               numpy: 1.26.4
2025-05-24 19:36:03,547:INFO:              pandas: 2.1.4
2025-05-24 19:36:03,547:INFO:              jinja2: 3.1.6
2025-05-24 19:36:03,547:INFO:               scipy: 1.11.4
2025-05-24 19:36:03,547:INFO:              joblib: 1.3.2
2025-05-24 19:36:03,547:INFO:             sklearn: 1.4.2
2025-05-24 19:36:03,547:INFO:                pyod: 2.0.5
2025-05-24 19:36:03,547:INFO:            imblearn: 0.13.0
2025-05-24 19:36:03,547:INFO:   category_encoders: 2.6.2
2025-05-24 19:36:03,547:INFO:            lightgbm: 4.6.0
2025-05-24 19:36:03,547:INFO:               numba: 0.61.2
2025-05-24 19:36:03,547:INFO:            requests: 2.32.3
2025-05-24 19:36:03,547:INFO:          matplotlib: 3.7.5
2025-05-24 19:36:03,548:INFO:          scikitplot: 0.3.7
2025-05-24 19:36:03,548:INFO:         yellowbrick: 1.5
2025-05-24 19:36:03,548:INFO:              plotly: 5.24.1
2025-05-24 19:36:03,548:INFO:    plotly-resampler: Not installed
2025-05-24 19:36:03,548:INFO:             kaleido: 0.2.1
2025-05-24 19:36:03,548:INFO:           schemdraw: 0.15
2025-05-24 19:36:03,548:INFO:         statsmodels: 0.14.4
2025-05-24 19:36:03,548:INFO:              sktime: 0.26.0
2025-05-24 19:36:03,548:INFO:               tbats: 1.1.3
2025-05-24 19:36:03,548:INFO:            pmdarima: 2.0.4
2025-05-24 19:36:03,548:INFO:              psutil: 7.0.0
2025-05-24 19:36:03,548:INFO:          markupsafe: 3.0.2
2025-05-24 19:36:03,548:INFO:             pickle5: Not installed
2025-05-24 19:36:03,548:INFO:         cloudpickle: 3.1.1
2025-05-24 19:36:03,548:INFO:         deprecation: 2.1.0
2025-05-24 19:36:03,548:INFO:              xxhash: 3.5.0
2025-05-24 19:36:03,548:INFO:           wurlitzer: 3.1.1
2025-05-24 19:36:03,548:INFO:PyCaret optional dependencies:
2025-05-24 19:36:03,932:INFO:                shap: Not installed
2025-05-24 19:36:03,932:INFO:           interpret: Not installed
2025-05-24 19:36:03,932:INFO:                umap: Not installed
2025-05-24 19:36:03,932:INFO:     ydata_profiling: Not installed
2025-05-24 19:36:03,932:INFO:  explainerdashboard: Not installed
2025-05-24 19:36:03,932:INFO:             autoviz: Not installed
2025-05-24 19:36:03,932:INFO:           fairlearn: Not installed
2025-05-24 19:36:03,932:INFO:          deepchecks: Not installed
2025-05-24 19:36:03,932:INFO:             xgboost: Not installed
2025-05-24 19:36:03,932:INFO:            catboost: Not installed
2025-05-24 19:36:03,932:INFO:              kmodes: Not installed
2025-05-24 19:36:03,932:INFO:             mlxtend: Not installed
2025-05-24 19:36:03,932:INFO:       statsforecast: Not installed
2025-05-24 19:36:03,933:INFO:        tune_sklearn: Not installed
2025-05-24 19:36:03,933:INFO:                 ray: Not installed
2025-05-24 19:36:03,933:INFO:            hyperopt: Not installed
2025-05-24 19:36:03,933:INFO:              optuna: Not installed
2025-05-24 19:36:03,933:INFO:               skopt: Not installed
2025-05-24 19:36:03,933:INFO:              mlflow: Not installed
2025-05-24 19:36:03,933:INFO:              gradio: Not installed
2025-05-24 19:36:03,933:INFO:             fastapi: 0.115.12
2025-05-24 19:36:03,933:INFO:             uvicorn: 0.34.2
2025-05-24 19:36:03,933:INFO:              m2cgen: Not installed
2025-05-24 19:36:03,933:INFO:           evidently: Not installed
2025-05-24 19:36:03,933:INFO:               fugue: Not installed
2025-05-24 19:36:03,933:INFO:           streamlit: Not installed
2025-05-24 19:36:03,933:INFO:             prophet: Not installed
2025-05-24 19:36:03,933:INFO:None
2025-05-24 19:36:03,933:INFO:Set up data.
2025-05-24 19:36:03,951:INFO:Set up folding strategy.
2025-05-24 19:36:03,951:INFO:Set up train/test split.
2025-05-24 19:36:03,960:INFO:Set up index.
2025-05-24 19:36:03,960:INFO:Assigning column types.
2025-05-24 19:36:03,964:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-24 19:36:04,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,014:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,094:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,124:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,124:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,124:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-24 19:36:04,172:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,249:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-24 19:36:04,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,279:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-24 19:36:04,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:04,436:INFO:Preparing preprocessing pipeline...
2025-05-24 19:36:04,437:INFO:Set up label encoding.
2025-05-24 19:36:04,437:INFO:Set up simple imputation.
2025-05-24 19:36:04,442:INFO:Set up encoding of ordinal features.
2025-05-24 19:36:04,451:INFO:Set up encoding of categorical features.
2025-05-24 19:36:04,603:INFO:Finished creating preprocessing pipeline.
2025-05-24 19:36:04,661:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-24 19:36:04,661:INFO:Creating final display dataframe.
2025-05-24 19:36:05,045:INFO:Setup _display_container:                     Description                                   Value
0                    Session id                                     123
1                        Target                              GradeClass
2                   Target type                              Multiclass
3                Target mapping  0.0: 0, 1.0: 1, 2.0: 2, 3.0: 3, 4.0: 4
4           Original data shape                              (2392, 15)
5        Transformed data shape                              (2392, 25)
6   Transformed train set shape                              (1674, 25)
7    Transformed test set shape                               (718, 25)
8               Ignore features                                       1
9              Numeric features                                       3
10         Categorical features                                       9
11                   Preprocess                                    True
12              Imputation type                                  simple
13           Numeric imputation                                    mean
14       Categorical imputation                                    mode
15     Maximum one-hot encoding                                      25
16              Encoding method                                    None
17               Fold Generator                         StratifiedKFold
18                  Fold Number                                      10
19                     CPU Jobs                                      -1
20                      Use GPU                                   False
21               Log Experiment                                   False
22              Experiment Name                        clf-default-name
23                          USI                                    4907
2025-05-24 19:36:05,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:05,134:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:05,210:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:05,210:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-24 19:36:05,212:INFO:setup() successfully completed in 1.69s...............
2025-05-24 19:36:05,212:INFO:Initializing compare_models()
2025-05-24 19:36:05,212:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-24 19:36:05,212:INFO:Checking exceptions
2025-05-24 19:36:05,216:INFO:Preparing display monitor
2025-05-24 19:36:05,220:INFO:Initializing Logistic Regression
2025-05-24 19:36:05,220:INFO:Total runtime is 1.5298525492350261e-06 minutes
2025-05-24 19:36:05,220:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:05,220:INFO:Initializing create_model()
2025-05-24 19:36:05,220:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:05,221:INFO:Checking exceptions
2025-05-24 19:36:05,221:INFO:Importing libraries
2025-05-24 19:36:05,221:INFO:Copying training dataset
2025-05-24 19:36:05,226:INFO:Defining folds
2025-05-24 19:36:05,226:INFO:Declaring metric variables
2025-05-24 19:36:05,227:INFO:Importing untrained model
2025-05-24 19:36:05,227:INFO:Logistic Regression Imported successfully
2025-05-24 19:36:05,227:INFO:Starting cross validation
2025-05-24 19:36:05,229:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:09,232:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,253:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,257:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,293:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:09,327:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,347:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,350:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,359:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,359:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,374:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,379:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,382:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,387:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,402:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,421:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:09,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:09,454:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:10,132:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-24 19:36:10,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:10,174:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,175:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:10,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,180:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,181:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,184:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,199:INFO:Calculating mean and std
2025-05-24 19:36:10,202:INFO:Creating metrics dataframe
2025-05-24 19:36:10,206:INFO:Uploading results into container
2025-05-24 19:36:10,206:INFO:Uploading model into container now
2025-05-24 19:36:10,207:INFO:_master_model_container: 1
2025-05-24 19:36:10,207:INFO:_display_container: 2
2025-05-24 19:36:10,207:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-24 19:36:10,207:INFO:create_model() successfully completed......................................
2025-05-24 19:36:10,315:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:10,315:INFO:Creating metrics dataframe
2025-05-24 19:36:10,319:INFO:Initializing K Neighbors Classifier
2025-05-24 19:36:10,319:INFO:Total runtime is 0.08497965733210246 minutes
2025-05-24 19:36:10,319:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:10,319:INFO:Initializing create_model()
2025-05-24 19:36:10,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:10,319:INFO:Checking exceptions
2025-05-24 19:36:10,319:INFO:Importing libraries
2025-05-24 19:36:10,320:INFO:Copying training dataset
2025-05-24 19:36:10,328:INFO:Defining folds
2025-05-24 19:36:10,328:INFO:Declaring metric variables
2025-05-24 19:36:10,328:INFO:Importing untrained model
2025-05-24 19:36:10,328:INFO:K Neighbors Classifier Imported successfully
2025-05-24 19:36:10,328:INFO:Starting cross validation
2025-05-24 19:36:10,332:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:10,705:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,709:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,712:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,714:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,715:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,717:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,722:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,723:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,726:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,729:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,734:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,738:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,749:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,933:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:10,951:INFO:Calculating mean and std
2025-05-24 19:36:10,952:INFO:Creating metrics dataframe
2025-05-24 19:36:10,954:INFO:Uploading results into container
2025-05-24 19:36:10,954:INFO:Uploading model into container now
2025-05-24 19:36:10,955:INFO:_master_model_container: 2
2025-05-24 19:36:10,955:INFO:_display_container: 2
2025-05-24 19:36:10,955:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-24 19:36:10,955:INFO:create_model() successfully completed......................................
2025-05-24 19:36:11,039:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:11,040:INFO:Creating metrics dataframe
2025-05-24 19:36:11,044:INFO:Initializing Naive Bayes
2025-05-24 19:36:11,044:INFO:Total runtime is 0.09706875085830688 minutes
2025-05-24 19:36:11,044:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:11,045:INFO:Initializing create_model()
2025-05-24 19:36:11,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:11,045:INFO:Checking exceptions
2025-05-24 19:36:11,045:INFO:Importing libraries
2025-05-24 19:36:11,045:INFO:Copying training dataset
2025-05-24 19:36:11,052:INFO:Defining folds
2025-05-24 19:36:11,052:INFO:Declaring metric variables
2025-05-24 19:36:11,053:INFO:Importing untrained model
2025-05-24 19:36:11,053:INFO:Naive Bayes Imported successfully
2025-05-24 19:36:11,053:INFO:Starting cross validation
2025-05-24 19:36:11,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:11,360:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,363:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,372:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,379:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,379:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,382:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,384:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,387:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,394:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,397:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,399:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,554:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,554:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:11,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,572:INFO:Calculating mean and std
2025-05-24 19:36:11,573:INFO:Creating metrics dataframe
2025-05-24 19:36:11,575:INFO:Uploading results into container
2025-05-24 19:36:11,575:INFO:Uploading model into container now
2025-05-24 19:36:11,576:INFO:_master_model_container: 3
2025-05-24 19:36:11,576:INFO:_display_container: 2
2025-05-24 19:36:11,576:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-24 19:36:11,576:INFO:create_model() successfully completed......................................
2025-05-24 19:36:11,659:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:11,659:INFO:Creating metrics dataframe
2025-05-24 19:36:11,664:INFO:Initializing Decision Tree Classifier
2025-05-24 19:36:11,664:INFO:Total runtime is 0.10739980141321817 minutes
2025-05-24 19:36:11,664:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:11,665:INFO:Initializing create_model()
2025-05-24 19:36:11,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:11,665:INFO:Checking exceptions
2025-05-24 19:36:11,665:INFO:Importing libraries
2025-05-24 19:36:11,665:INFO:Copying training dataset
2025-05-24 19:36:11,671:INFO:Defining folds
2025-05-24 19:36:11,672:INFO:Declaring metric variables
2025-05-24 19:36:11,672:INFO:Importing untrained model
2025-05-24 19:36:11,672:INFO:Decision Tree Classifier Imported successfully
2025-05-24 19:36:11,673:INFO:Starting cross validation
2025-05-24 19:36:11,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:11,970:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,988:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,988:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,988:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,989:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:11,996:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,004:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,008:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,010:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,018:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,025:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,167:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,174:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,174:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,178:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,181:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,193:INFO:Calculating mean and std
2025-05-24 19:36:12,193:INFO:Creating metrics dataframe
2025-05-24 19:36:12,195:INFO:Uploading results into container
2025-05-24 19:36:12,196:INFO:Uploading model into container now
2025-05-24 19:36:12,196:INFO:_master_model_container: 4
2025-05-24 19:36:12,196:INFO:_display_container: 2
2025-05-24 19:36:12,197:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-24 19:36:12,197:INFO:create_model() successfully completed......................................
2025-05-24 19:36:12,278:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:12,278:INFO:Creating metrics dataframe
2025-05-24 19:36:12,283:INFO:Initializing SVM - Linear Kernel
2025-05-24 19:36:12,283:INFO:Total runtime is 0.11771755615870157 minutes
2025-05-24 19:36:12,283:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:12,284:INFO:Initializing create_model()
2025-05-24 19:36:12,284:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:12,284:INFO:Checking exceptions
2025-05-24 19:36:12,284:INFO:Importing libraries
2025-05-24 19:36:12,284:INFO:Copying training dataset
2025-05-24 19:36:12,291:INFO:Defining folds
2025-05-24 19:36:12,291:INFO:Declaring metric variables
2025-05-24 19:36:12,291:INFO:Importing untrained model
2025-05-24 19:36:12,291:INFO:SVM - Linear Kernel Imported successfully
2025-05-24 19:36:12,292:INFO:Starting cross validation
2025-05-24 19:36:12,294:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:12,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,633:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,640:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,646:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,646:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,683:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,689:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,689:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,692:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,693:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,695:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,696:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,696:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,705:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,706:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,708:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,709:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,713:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,715:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,715:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,724:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,741:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,876:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,885:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,888:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:12,890:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,895:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:12,897:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:12,912:INFO:Calculating mean and std
2025-05-24 19:36:12,912:INFO:Creating metrics dataframe
2025-05-24 19:36:12,914:INFO:Uploading results into container
2025-05-24 19:36:12,915:INFO:Uploading model into container now
2025-05-24 19:36:12,915:INFO:_master_model_container: 5
2025-05-24 19:36:12,915:INFO:_display_container: 2
2025-05-24 19:36:12,916:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-24 19:36:12,916:INFO:create_model() successfully completed......................................
2025-05-24 19:36:13,001:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:13,001:INFO:Creating metrics dataframe
2025-05-24 19:36:13,006:INFO:Initializing Ridge Classifier
2025-05-24 19:36:13,006:INFO:Total runtime is 0.12976579268773394 minutes
2025-05-24 19:36:13,006:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:13,007:INFO:Initializing create_model()
2025-05-24 19:36:13,007:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:13,007:INFO:Checking exceptions
2025-05-24 19:36:13,007:INFO:Importing libraries
2025-05-24 19:36:13,007:INFO:Copying training dataset
2025-05-24 19:36:13,014:INFO:Defining folds
2025-05-24 19:36:13,014:INFO:Declaring metric variables
2025-05-24 19:36:13,014:INFO:Importing untrained model
2025-05-24 19:36:13,015:INFO:Ridge Classifier Imported successfully
2025-05-24 19:36:13,015:INFO:Starting cross validation
2025-05-24 19:36:13,017:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:13,307:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,317:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,324:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,327:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,327:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,344:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,344:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,347:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,353:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,356:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:13,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,500:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,500:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:13,503:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:13,512:INFO:Calculating mean and std
2025-05-24 19:36:13,513:INFO:Creating metrics dataframe
2025-05-24 19:36:13,515:INFO:Uploading results into container
2025-05-24 19:36:13,516:INFO:Uploading model into container now
2025-05-24 19:36:13,516:INFO:_master_model_container: 6
2025-05-24 19:36:13,516:INFO:_display_container: 2
2025-05-24 19:36:13,516:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-24 19:36:13,516:INFO:create_model() successfully completed......................................
2025-05-24 19:36:13,600:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:13,600:INFO:Creating metrics dataframe
2025-05-24 19:36:13,605:INFO:Initializing Random Forest Classifier
2025-05-24 19:36:13,605:INFO:Total runtime is 0.13974864085515337 minutes
2025-05-24 19:36:13,605:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:13,605:INFO:Initializing create_model()
2025-05-24 19:36:13,605:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:13,606:INFO:Checking exceptions
2025-05-24 19:36:13,606:INFO:Importing libraries
2025-05-24 19:36:13,606:INFO:Copying training dataset
2025-05-24 19:36:13,613:INFO:Defining folds
2025-05-24 19:36:13,613:INFO:Declaring metric variables
2025-05-24 19:36:13,613:INFO:Importing untrained model
2025-05-24 19:36:13,613:INFO:Random Forest Classifier Imported successfully
2025-05-24 19:36:13,614:INFO:Starting cross validation
2025-05-24 19:36:13,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:14,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,487:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,516:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,520:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,524:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,530:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,559:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:14,567:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,060:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,067:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,071:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,078:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,081:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,109:INFO:Calculating mean and std
2025-05-24 19:36:15,111:INFO:Creating metrics dataframe
2025-05-24 19:36:15,117:INFO:Uploading results into container
2025-05-24 19:36:15,119:INFO:Uploading model into container now
2025-05-24 19:36:15,120:INFO:_master_model_container: 7
2025-05-24 19:36:15,120:INFO:_display_container: 2
2025-05-24 19:36:15,121:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-24 19:36:15,121:INFO:create_model() successfully completed......................................
2025-05-24 19:36:15,218:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:15,218:INFO:Creating metrics dataframe
2025-05-24 19:36:15,223:INFO:Initializing Quadratic Discriminant Analysis
2025-05-24 19:36:15,223:INFO:Total runtime is 0.1667183955510457 minutes
2025-05-24 19:36:15,223:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:15,224:INFO:Initializing create_model()
2025-05-24 19:36:15,224:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:15,224:INFO:Checking exceptions
2025-05-24 19:36:15,224:INFO:Importing libraries
2025-05-24 19:36:15,224:INFO:Copying training dataset
2025-05-24 19:36:15,231:INFO:Defining folds
2025-05-24 19:36:15,231:INFO:Declaring metric variables
2025-05-24 19:36:15,231:INFO:Importing untrained model
2025-05-24 19:36:15,232:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-24 19:36:15,232:INFO:Starting cross validation
2025-05-24 19:36:15,235:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:15,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,531:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,533:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,537:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,537:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,540:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,545:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,547:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,551:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,552:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,561:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,562:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,565:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,684:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-24 19:36:15,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,722:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,725:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,729:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:15,732:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:15,750:INFO:Calculating mean and std
2025-05-24 19:36:15,751:INFO:Creating metrics dataframe
2025-05-24 19:36:15,753:INFO:Uploading results into container
2025-05-24 19:36:15,754:INFO:Uploading model into container now
2025-05-24 19:36:15,754:INFO:_master_model_container: 8
2025-05-24 19:36:15,754:INFO:_display_container: 2
2025-05-24 19:36:15,754:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-24 19:36:15,754:INFO:create_model() successfully completed......................................
2025-05-24 19:36:15,837:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:15,837:INFO:Creating metrics dataframe
2025-05-24 19:36:15,841:INFO:Initializing Ada Boost Classifier
2025-05-24 19:36:15,841:INFO:Total runtime is 0.1770250876744588 minutes
2025-05-24 19:36:15,842:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:15,842:INFO:Initializing create_model()
2025-05-24 19:36:15,842:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:15,842:INFO:Checking exceptions
2025-05-24 19:36:15,842:INFO:Importing libraries
2025-05-24 19:36:15,842:INFO:Copying training dataset
2025-05-24 19:36:15,849:INFO:Defining folds
2025-05-24 19:36:15,849:INFO:Declaring metric variables
2025-05-24 19:36:15,849:INFO:Importing untrained model
2025-05-24 19:36:15,850:INFO:Ada Boost Classifier Imported successfully
2025-05-24 19:36:15,850:INFO:Starting cross validation
2025-05-24 19:36:15,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:16,051:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,058:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,067:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,075:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,078:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,400:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,406:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,407:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,407:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,409:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,410:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,412:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,413:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,413:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,413:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,414:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,415:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,416:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,417:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,417:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,421:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,422:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,423:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,423:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,426:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,427:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,428:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,438:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,442:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-24 19:36:16,731:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,732:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:16,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,734:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,737:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,741:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:16,750:INFO:Calculating mean and std
2025-05-24 19:36:16,751:INFO:Creating metrics dataframe
2025-05-24 19:36:16,753:INFO:Uploading results into container
2025-05-24 19:36:16,753:INFO:Uploading model into container now
2025-05-24 19:36:16,754:INFO:_master_model_container: 9
2025-05-24 19:36:16,754:INFO:_display_container: 2
2025-05-24 19:36:16,754:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-24 19:36:16,754:INFO:create_model() successfully completed......................................
2025-05-24 19:36:16,836:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:16,836:INFO:Creating metrics dataframe
2025-05-24 19:36:16,840:INFO:Initializing Gradient Boosting Classifier
2025-05-24 19:36:16,840:INFO:Total runtime is 0.19367419481277462 minutes
2025-05-24 19:36:16,841:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:16,841:INFO:Initializing create_model()
2025-05-24 19:36:16,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:16,841:INFO:Checking exceptions
2025-05-24 19:36:16,841:INFO:Importing libraries
2025-05-24 19:36:16,841:INFO:Copying training dataset
2025-05-24 19:36:16,848:INFO:Defining folds
2025-05-24 19:36:16,848:INFO:Declaring metric variables
2025-05-24 19:36:16,849:INFO:Importing untrained model
2025-05-24 19:36:16,849:INFO:Gradient Boosting Classifier Imported successfully
2025-05-24 19:36:16,849:INFO:Starting cross validation
2025-05-24 19:36:16,852:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:19,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,573:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,576:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,583:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,592:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,600:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,606:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,611:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,613:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,616:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,621:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,625:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,633:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,633:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:19,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:19,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,457:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,459:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,475:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,492:INFO:Calculating mean and std
2025-05-24 19:36:21,493:INFO:Creating metrics dataframe
2025-05-24 19:36:21,495:INFO:Uploading results into container
2025-05-24 19:36:21,496:INFO:Uploading model into container now
2025-05-24 19:36:21,496:INFO:_master_model_container: 10
2025-05-24 19:36:21,496:INFO:_display_container: 2
2025-05-24 19:36:21,496:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-24 19:36:21,496:INFO:create_model() successfully completed......................................
2025-05-24 19:36:21,578:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:21,578:INFO:Creating metrics dataframe
2025-05-24 19:36:21,582:INFO:Initializing Linear Discriminant Analysis
2025-05-24 19:36:21,582:INFO:Total runtime is 0.2727054913838704 minutes
2025-05-24 19:36:21,583:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:21,583:INFO:Initializing create_model()
2025-05-24 19:36:21,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:21,583:INFO:Checking exceptions
2025-05-24 19:36:21,583:INFO:Importing libraries
2025-05-24 19:36:21,583:INFO:Copying training dataset
2025-05-24 19:36:21,590:INFO:Defining folds
2025-05-24 19:36:21,590:INFO:Declaring metric variables
2025-05-24 19:36:21,590:INFO:Importing untrained model
2025-05-24 19:36:21,590:INFO:Linear Discriminant Analysis Imported successfully
2025-05-24 19:36:21,591:INFO:Starting cross validation
2025-05-24 19:36:21,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:21,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,886:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,888:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,891:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,894:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,894:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,898:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,898:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,901:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,904:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,906:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,918:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:21,921:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,923:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,926:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:21,930:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:22,070:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,071:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-24 19:36:22,073:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,076:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,077:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,078:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:22,080:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,095:INFO:Calculating mean and std
2025-05-24 19:36:22,096:INFO:Creating metrics dataframe
2025-05-24 19:36:22,098:INFO:Uploading results into container
2025-05-24 19:36:22,098:INFO:Uploading model into container now
2025-05-24 19:36:22,099:INFO:_master_model_container: 11
2025-05-24 19:36:22,099:INFO:_display_container: 2
2025-05-24 19:36:22,099:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-24 19:36:22,099:INFO:create_model() successfully completed......................................
2025-05-24 19:36:22,182:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:22,182:INFO:Creating metrics dataframe
2025-05-24 19:36:22,186:INFO:Initializing Extra Trees Classifier
2025-05-24 19:36:22,186:INFO:Total runtime is 0.2827707211176554 minutes
2025-05-24 19:36:22,186:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:22,187:INFO:Initializing create_model()
2025-05-24 19:36:22,187:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:22,187:INFO:Checking exceptions
2025-05-24 19:36:22,187:INFO:Importing libraries
2025-05-24 19:36:22,187:INFO:Copying training dataset
2025-05-24 19:36:22,194:INFO:Defining folds
2025-05-24 19:36:22,194:INFO:Declaring metric variables
2025-05-24 19:36:22,194:INFO:Importing untrained model
2025-05-24 19:36:22,194:INFO:Extra Trees Classifier Imported successfully
2025-05-24 19:36:22,195:INFO:Starting cross validation
2025-05-24 19:36:22,197:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-24 19:36:22,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,996:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:22,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,002:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,005:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,006:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,009:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,033:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,040:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,061:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,062:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,075:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,080:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,084:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,488:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-24 19:36:23,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4.0') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-24 19:36:23,507:INFO:Calculating mean and std
2025-05-24 19:36:23,508:INFO:Creating metrics dataframe
2025-05-24 19:36:23,510:INFO:Uploading results into container
2025-05-24 19:36:23,510:INFO:Uploading model into container now
2025-05-24 19:36:23,510:INFO:_master_model_container: 12
2025-05-24 19:36:23,510:INFO:_display_container: 2
2025-05-24 19:36:23,511:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-24 19:36:23,511:INFO:create_model() successfully completed......................................
2025-05-24 19:36:23,594:INFO:SubProcess create_model() end ==================================
2025-05-24 19:36:23,594:INFO:Creating metrics dataframe
2025-05-24 19:36:23,599:INFO:Initializing Light Gradient Boosting Machine
2025-05-24 19:36:23,599:INFO:Total runtime is 0.3063116908073425 minutes
2025-05-24 19:36:23,599:INFO:SubProcess create_model() called ==================================
2025-05-24 19:36:23,599:INFO:Initializing create_model()
2025-05-24 19:36:23,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff5bcd1ec50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff599ab9ba0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-24 19:36:23,599:INFO:Checking exceptions
2025-05-24 19:36:23,600:INFO:Importing libraries
2025-05-24 19:36:23,600:INFO:Copying training dataset
2025-05-24 19:36:23,606:INFO:Defining folds
2025-05-24 19:36:23,606:INFO:Declaring metric variables
2025-05-24 19:36:23,607:INFO:Importing untrained model
2025-05-24 19:36:23,607:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-24 19:36:23,608:INFO:Starting cross validation
2025-05-24 19:36:23,610:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:32:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:32:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:32:46,855:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:32:47,453:INFO:PyCaret ClassificationExperiment
2025-05-27 20:32:47,453:INFO:Logging name: clf-default-name
2025-05-27 20:32:47,453:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 20:32:47,453:INFO:version 3.3.2
2025-05-27 20:32:47,453:INFO:Initializing setup()
2025-05-27 20:32:47,453:INFO:self.USI: 9854
2025-05-27 20:32:47,453:INFO:self._variable_keys: {'exp_id', 'y_test', 'y', 'memory', 'target_param', 'exp_name_log', 'data', 'n_jobs_param', 'fix_imbalance', 'pipeline', 'X_test', '_ml_usecase', 'X_train', 'USI', 'fold_shuffle_param', 'html_param', 'X', 'log_plots_param', 'seed', 'gpu_n_jobs_param', 'y_train', 'is_multiclass', 'idx', 'fold_groups_param', '_available_plots', 'fold_generator', 'gpu_param', 'logging_param'}
2025-05-27 20:32:47,453:INFO:Checking environment
2025-05-27 20:32:47,454:INFO:python_version: 3.10.17
2025-05-27 20:32:47,454:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 20:32:47,454:INFO:machine: x86_64
2025-05-27 20:32:47,455:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:32:47,456:INFO:Memory: svmem(total=16407515136, available=8849403904, percent=46.1, used=6247182336, free=1746452480, active=2503794688, inactive=10573209600, buffers=311857152, cached=8102023168, shared=961286144, slab=777940992)
2025-05-27 20:32:47,457:INFO:Physical Core: 4
2025-05-27 20:32:47,457:INFO:Logical Core: 8
2025-05-27 20:32:47,457:INFO:Checking libraries
2025-05-27 20:32:47,457:INFO:System:
2025-05-27 20:32:47,457:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 20:32:47,457:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 20:32:47,457:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:32:47,457:INFO:PyCaret required dependencies:
2025-05-27 20:32:47,477:INFO:                 pip: 25.1.1
2025-05-27 20:32:47,478:INFO:          setuptools: 65.5.0
2025-05-27 20:32:47,478:INFO:             pycaret: 3.3.2
2025-05-27 20:32:47,478:INFO:             IPython: 8.36.0
2025-05-27 20:32:47,478:INFO:          ipywidgets: 8.1.7
2025-05-27 20:32:47,478:INFO:                tqdm: 4.67.1
2025-05-27 20:32:47,478:INFO:               numpy: 1.26.4
2025-05-27 20:32:47,478:INFO:              pandas: 2.1.4
2025-05-27 20:32:47,478:INFO:              jinja2: 3.1.6
2025-05-27 20:32:47,478:INFO:               scipy: 1.11.4
2025-05-27 20:32:47,478:INFO:              joblib: 1.3.2
2025-05-27 20:32:47,478:INFO:             sklearn: 1.4.2
2025-05-27 20:32:47,478:INFO:                pyod: 2.0.5
2025-05-27 20:32:47,478:INFO:            imblearn: 0.13.0
2025-05-27 20:32:47,478:INFO:   category_encoders: 2.6.2
2025-05-27 20:32:47,478:INFO:            lightgbm: 4.6.0
2025-05-27 20:32:47,478:INFO:               numba: 0.61.2
2025-05-27 20:32:47,478:INFO:            requests: 2.32.3
2025-05-27 20:32:47,478:INFO:          matplotlib: 3.7.5
2025-05-27 20:32:47,478:INFO:          scikitplot: 0.3.7
2025-05-27 20:32:47,478:INFO:         yellowbrick: 1.5
2025-05-27 20:32:47,478:INFO:              plotly: 5.24.1
2025-05-27 20:32:47,478:INFO:    plotly-resampler: Not installed
2025-05-27 20:32:47,478:INFO:             kaleido: 0.2.1
2025-05-27 20:32:47,478:INFO:           schemdraw: 0.15
2025-05-27 20:32:47,478:INFO:         statsmodels: 0.14.4
2025-05-27 20:32:47,478:INFO:              sktime: 0.26.0
2025-05-27 20:32:47,478:INFO:               tbats: 1.1.3
2025-05-27 20:32:47,478:INFO:            pmdarima: 2.0.4
2025-05-27 20:32:47,479:INFO:              psutil: 7.0.0
2025-05-27 20:32:47,479:INFO:          markupsafe: 3.0.2
2025-05-27 20:32:47,479:INFO:             pickle5: Not installed
2025-05-27 20:32:47,479:INFO:         cloudpickle: 3.1.1
2025-05-27 20:32:47,479:INFO:         deprecation: 2.1.0
2025-05-27 20:32:47,479:INFO:              xxhash: 3.5.0
2025-05-27 20:32:47,479:INFO:           wurlitzer: 3.1.1
2025-05-27 20:32:47,479:INFO:PyCaret optional dependencies:
2025-05-27 20:32:47,864:INFO:                shap: Not installed
2025-05-27 20:32:47,864:INFO:           interpret: Not installed
2025-05-27 20:32:47,864:INFO:                umap: Not installed
2025-05-27 20:32:47,864:INFO:     ydata_profiling: Not installed
2025-05-27 20:32:47,864:INFO:  explainerdashboard: Not installed
2025-05-27 20:32:47,864:INFO:             autoviz: Not installed
2025-05-27 20:32:47,864:INFO:           fairlearn: Not installed
2025-05-27 20:32:47,864:INFO:          deepchecks: Not installed
2025-05-27 20:32:47,864:INFO:             xgboost: Not installed
2025-05-27 20:32:47,864:INFO:            catboost: Not installed
2025-05-27 20:32:47,864:INFO:              kmodes: Not installed
2025-05-27 20:32:47,864:INFO:             mlxtend: Not installed
2025-05-27 20:32:47,864:INFO:       statsforecast: Not installed
2025-05-27 20:32:47,864:INFO:        tune_sklearn: Not installed
2025-05-27 20:32:47,864:INFO:                 ray: Not installed
2025-05-27 20:32:47,864:INFO:            hyperopt: Not installed
2025-05-27 20:32:47,864:INFO:              optuna: Not installed
2025-05-27 20:32:47,864:INFO:               skopt: Not installed
2025-05-27 20:32:47,864:INFO:              mlflow: Not installed
2025-05-27 20:32:47,864:INFO:              gradio: Not installed
2025-05-27 20:32:47,864:INFO:             fastapi: 0.115.12
2025-05-27 20:32:47,864:INFO:             uvicorn: 0.34.2
2025-05-27 20:32:47,864:INFO:              m2cgen: Not installed
2025-05-27 20:32:47,864:INFO:           evidently: Not installed
2025-05-27 20:32:47,864:INFO:               fugue: Not installed
2025-05-27 20:32:47,864:INFO:           streamlit: Not installed
2025-05-27 20:32:47,865:INFO:             prophet: Not installed
2025-05-27 20:32:47,865:INFO:None
2025-05-27 20:32:47,865:INFO:Set up data.
2025-05-27 20:32:47,876:INFO:Set up folding strategy.
2025-05-27 20:32:47,876:INFO:Set up train/test split.
2025-05-27 20:32:47,886:INFO:Set up index.
2025-05-27 20:32:47,886:INFO:Assigning column types.
2025-05-27 20:32:47,889:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 20:32:47,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:32:47,941:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:32:47,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:47,973:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,019:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:32:48,020:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:32:48,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,048:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 20:32:48,095:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:32:48,123:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,170:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:32:48,198:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,199:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,199:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 20:32:48,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:48,356:INFO:Preparing preprocessing pipeline...
2025-05-27 20:32:48,357:INFO:Set up label encoding.
2025-05-27 20:32:48,357:INFO:Set up simple imputation.
2025-05-27 20:32:48,362:INFO:Set up encoding of ordinal features.
2025-05-27 20:32:48,370:INFO:Set up encoding of categorical features.
2025-05-27 20:32:48,528:INFO:Finished creating preprocessing pipeline.
2025-05-27 20:32:48,588:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 20:32:48,588:INFO:Creating final display dataframe.
2025-05-27 20:32:48,973:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           123
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                          mean
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                            10
19                     CPU Jobs                            -1
20                      Use GPU                         False
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          9854
2025-05-27 20:32:49,055:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:49,055:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:49,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:49,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:32:49,132:INFO:setup() successfully completed in 1.68s...............
2025-05-27 20:32:49,132:INFO:Initializing compare_models()
2025-05-27 20:32:49,132:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 20:32:49,132:INFO:Checking exceptions
2025-05-27 20:32:49,136:INFO:Preparing display monitor
2025-05-27 20:32:49,139:INFO:Initializing Logistic Regression
2025-05-27 20:32:49,139:INFO:Total runtime is 1.5616416931152343e-06 minutes
2025-05-27 20:32:49,139:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:49,140:INFO:Initializing create_model()
2025-05-27 20:32:49,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:49,140:INFO:Checking exceptions
2025-05-27 20:32:49,140:INFO:Importing libraries
2025-05-27 20:32:49,140:INFO:Copying training dataset
2025-05-27 20:32:49,145:INFO:Defining folds
2025-05-27 20:32:49,145:INFO:Declaring metric variables
2025-05-27 20:32:49,145:INFO:Importing untrained model
2025-05-27 20:32:49,146:INFO:Logistic Regression Imported successfully
2025-05-27 20:32:49,146:INFO:Starting cross validation
2025-05-27 20:32:49,149:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:53,199:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,231:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,240:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,240:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,250:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,252:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,304:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:53,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,327:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,361:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,400:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:53,408:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,420:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:53,433:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,078:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:54,082:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:32:54,122:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:54,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,126:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:54,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,132:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,135:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,143:INFO:Calculating mean and std
2025-05-27 20:32:54,144:INFO:Creating metrics dataframe
2025-05-27 20:32:54,147:INFO:Uploading results into container
2025-05-27 20:32:54,148:INFO:Uploading model into container now
2025-05-27 20:32:54,148:INFO:_master_model_container: 1
2025-05-27 20:32:54,148:INFO:_display_container: 2
2025-05-27 20:32:54,149:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 20:32:54,149:INFO:create_model() successfully completed......................................
2025-05-27 20:32:54,260:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:54,260:INFO:Creating metrics dataframe
2025-05-27 20:32:54,263:INFO:Initializing K Neighbors Classifier
2025-05-27 20:32:54,263:INFO:Total runtime is 0.08539163668950399 minutes
2025-05-27 20:32:54,263:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:54,263:INFO:Initializing create_model()
2025-05-27 20:32:54,263:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:54,263:INFO:Checking exceptions
2025-05-27 20:32:54,263:INFO:Importing libraries
2025-05-27 20:32:54,263:INFO:Copying training dataset
2025-05-27 20:32:54,269:INFO:Defining folds
2025-05-27 20:32:54,269:INFO:Declaring metric variables
2025-05-27 20:32:54,269:INFO:Importing untrained model
2025-05-27 20:32:54,270:INFO:K Neighbors Classifier Imported successfully
2025-05-27 20:32:54,270:INFO:Starting cross validation
2025-05-27 20:32:54,272:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:54,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,648:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,655:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,658:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,658:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,661:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,664:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,666:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,666:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,677:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,683:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,684:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,687:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,689:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,842:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,846:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,849:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,852:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,855:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,859:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:54,866:INFO:Calculating mean and std
2025-05-27 20:32:54,867:INFO:Creating metrics dataframe
2025-05-27 20:32:54,869:INFO:Uploading results into container
2025-05-27 20:32:54,869:INFO:Uploading model into container now
2025-05-27 20:32:54,870:INFO:_master_model_container: 2
2025-05-27 20:32:54,870:INFO:_display_container: 2
2025-05-27 20:32:54,870:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 20:32:54,870:INFO:create_model() successfully completed......................................
2025-05-27 20:32:54,947:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:54,948:INFO:Creating metrics dataframe
2025-05-27 20:32:54,952:INFO:Initializing Naive Bayes
2025-05-27 20:32:54,952:INFO:Total runtime is 0.09687844912211101 minutes
2025-05-27 20:32:54,952:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:54,953:INFO:Initializing create_model()
2025-05-27 20:32:54,953:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:54,953:INFO:Checking exceptions
2025-05-27 20:32:54,953:INFO:Importing libraries
2025-05-27 20:32:54,953:INFO:Copying training dataset
2025-05-27 20:32:54,959:INFO:Defining folds
2025-05-27 20:32:54,959:INFO:Declaring metric variables
2025-05-27 20:32:54,960:INFO:Importing untrained model
2025-05-27 20:32:54,960:INFO:Naive Bayes Imported successfully
2025-05-27 20:32:54,960:INFO:Starting cross validation
2025-05-27 20:32:54,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:55,250:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,256:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,260:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,261:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,264:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,279:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,279:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,283:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,292:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,295:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,297:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,299:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,444:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,444:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,447:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:55,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,463:INFO:Calculating mean and std
2025-05-27 20:32:55,464:INFO:Creating metrics dataframe
2025-05-27 20:32:55,466:INFO:Uploading results into container
2025-05-27 20:32:55,466:INFO:Uploading model into container now
2025-05-27 20:32:55,467:INFO:_master_model_container: 3
2025-05-27 20:32:55,467:INFO:_display_container: 2
2025-05-27 20:32:55,467:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 20:32:55,467:INFO:create_model() successfully completed......................................
2025-05-27 20:32:55,546:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:55,547:INFO:Creating metrics dataframe
2025-05-27 20:32:55,551:INFO:Initializing Decision Tree Classifier
2025-05-27 20:32:55,551:INFO:Total runtime is 0.1068602204322815 minutes
2025-05-27 20:32:55,551:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:55,551:INFO:Initializing create_model()
2025-05-27 20:32:55,551:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:55,552:INFO:Checking exceptions
2025-05-27 20:32:55,552:INFO:Importing libraries
2025-05-27 20:32:55,552:INFO:Copying training dataset
2025-05-27 20:32:55,558:INFO:Defining folds
2025-05-27 20:32:55,558:INFO:Declaring metric variables
2025-05-27 20:32:55,558:INFO:Importing untrained model
2025-05-27 20:32:55,559:INFO:Decision Tree Classifier Imported successfully
2025-05-27 20:32:55,559:INFO:Starting cross validation
2025-05-27 20:32:55,561:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:55,855:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,862:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,864:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,866:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,868:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,868:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,870:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,874:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,877:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,880:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,884:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,887:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,888:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,890:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,894:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,899:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,902:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:55,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,049:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,052:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,056:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,063:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,070:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,080:INFO:Calculating mean and std
2025-05-27 20:32:56,081:INFO:Creating metrics dataframe
2025-05-27 20:32:56,083:INFO:Uploading results into container
2025-05-27 20:32:56,083:INFO:Uploading model into container now
2025-05-27 20:32:56,084:INFO:_master_model_container: 4
2025-05-27 20:32:56,084:INFO:_display_container: 2
2025-05-27 20:32:56,084:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-27 20:32:56,084:INFO:create_model() successfully completed......................................
2025-05-27 20:32:56,164:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:56,164:INFO:Creating metrics dataframe
2025-05-27 20:32:56,169:INFO:Initializing SVM - Linear Kernel
2025-05-27 20:32:56,169:INFO:Total runtime is 0.11716289122899373 minutes
2025-05-27 20:32:56,169:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:56,170:INFO:Initializing create_model()
2025-05-27 20:32:56,170:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:56,170:INFO:Checking exceptions
2025-05-27 20:32:56,170:INFO:Importing libraries
2025-05-27 20:32:56,170:INFO:Copying training dataset
2025-05-27 20:32:56,176:INFO:Defining folds
2025-05-27 20:32:56,176:INFO:Declaring metric variables
2025-05-27 20:32:56,177:INFO:Importing untrained model
2025-05-27 20:32:56,177:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 20:32:56,177:INFO:Starting cross validation
2025-05-27 20:32:56,180:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:56,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,548:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,551:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,567:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,572:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,574:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,578:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,588:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,594:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,597:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,600:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,602:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,604:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,605:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,608:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,612:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,771:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,772:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,776:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:56,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:56,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,786:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:56,800:INFO:Calculating mean and std
2025-05-27 20:32:56,801:INFO:Creating metrics dataframe
2025-05-27 20:32:56,803:INFO:Uploading results into container
2025-05-27 20:32:56,803:INFO:Uploading model into container now
2025-05-27 20:32:56,804:INFO:_master_model_container: 5
2025-05-27 20:32:56,804:INFO:_display_container: 2
2025-05-27 20:32:56,804:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 20:32:56,804:INFO:create_model() successfully completed......................................
2025-05-27 20:32:56,885:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:56,885:INFO:Creating metrics dataframe
2025-05-27 20:32:56,889:INFO:Initializing Ridge Classifier
2025-05-27 20:32:56,890:INFO:Total runtime is 0.12917305231094361 minutes
2025-05-27 20:32:56,890:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:56,890:INFO:Initializing create_model()
2025-05-27 20:32:56,890:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:56,890:INFO:Checking exceptions
2025-05-27 20:32:56,890:INFO:Importing libraries
2025-05-27 20:32:56,890:INFO:Copying training dataset
2025-05-27 20:32:56,897:INFO:Defining folds
2025-05-27 20:32:56,897:INFO:Declaring metric variables
2025-05-27 20:32:56,897:INFO:Importing untrained model
2025-05-27 20:32:56,898:INFO:Ridge Classifier Imported successfully
2025-05-27 20:32:56,898:INFO:Starting cross validation
2025-05-27 20:32:56,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:57,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,180:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,185:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,187:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,188:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,191:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,194:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,195:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,195:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,197:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,199:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,201:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,203:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,203:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,206:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,206:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,207:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,210:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,211:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,212:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,213:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,213:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,215:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,218:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,222:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,222:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,225:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,227:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,229:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,231:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,368:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:57,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,374:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,374:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,376:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:32:57,377:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:57,386:INFO:Calculating mean and std
2025-05-27 20:32:57,386:INFO:Creating metrics dataframe
2025-05-27 20:32:57,388:INFO:Uploading results into container
2025-05-27 20:32:57,389:INFO:Uploading model into container now
2025-05-27 20:32:57,389:INFO:_master_model_container: 6
2025-05-27 20:32:57,389:INFO:_display_container: 2
2025-05-27 20:32:57,390:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-27 20:32:57,390:INFO:create_model() successfully completed......................................
2025-05-27 20:32:57,472:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:57,472:INFO:Creating metrics dataframe
2025-05-27 20:32:57,476:INFO:Initializing Random Forest Classifier
2025-05-27 20:32:57,476:INFO:Total runtime is 0.13894962867101035 minutes
2025-05-27 20:32:57,476:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:57,477:INFO:Initializing create_model()
2025-05-27 20:32:57,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:57,477:INFO:Checking exceptions
2025-05-27 20:32:57,477:INFO:Importing libraries
2025-05-27 20:32:57,477:INFO:Copying training dataset
2025-05-27 20:32:57,483:INFO:Defining folds
2025-05-27 20:32:57,483:INFO:Declaring metric variables
2025-05-27 20:32:57,484:INFO:Importing untrained model
2025-05-27 20:32:57,484:INFO:Random Forest Classifier Imported successfully
2025-05-27 20:32:57,484:INFO:Starting cross validation
2025-05-27 20:32:57,486:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:58,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,344:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,350:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,357:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,359:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,363:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,363:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,374:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,375:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,377:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,386:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,398:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,402:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,412:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,416:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,420:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,855:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,858:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,862:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,862:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,866:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:58,883:INFO:Calculating mean and std
2025-05-27 20:32:58,884:INFO:Creating metrics dataframe
2025-05-27 20:32:58,886:INFO:Uploading results into container
2025-05-27 20:32:58,886:INFO:Uploading model into container now
2025-05-27 20:32:58,887:INFO:_master_model_container: 7
2025-05-27 20:32:58,887:INFO:_display_container: 2
2025-05-27 20:32:58,887:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-27 20:32:58,887:INFO:create_model() successfully completed......................................
2025-05-27 20:32:58,968:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:58,968:INFO:Creating metrics dataframe
2025-05-27 20:32:58,973:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 20:32:58,973:INFO:Total runtime is 0.16389429171880088 minutes
2025-05-27 20:32:58,973:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:58,973:INFO:Initializing create_model()
2025-05-27 20:32:58,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:58,974:INFO:Checking exceptions
2025-05-27 20:32:58,974:INFO:Importing libraries
2025-05-27 20:32:58,974:INFO:Copying training dataset
2025-05-27 20:32:58,980:INFO:Defining folds
2025-05-27 20:32:58,980:INFO:Declaring metric variables
2025-05-27 20:32:58,980:INFO:Importing untrained model
2025-05-27 20:32:58,981:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 20:32:58,981:INFO:Starting cross validation
2025-05-27 20:32:58,983:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:59,187:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,198:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,213:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,232:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,238:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,283:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,293:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,296:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,299:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,299:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,303:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,303:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,306:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,312:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,317:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,317:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,428:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,428:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:32:59,473:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,475:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,475:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:32:59,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:32:59,492:INFO:Calculating mean and std
2025-05-27 20:32:59,493:INFO:Creating metrics dataframe
2025-05-27 20:32:59,495:INFO:Uploading results into container
2025-05-27 20:32:59,495:INFO:Uploading model into container now
2025-05-27 20:32:59,496:INFO:_master_model_container: 8
2025-05-27 20:32:59,496:INFO:_display_container: 2
2025-05-27 20:32:59,496:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 20:32:59,496:INFO:create_model() successfully completed......................................
2025-05-27 20:32:59,578:INFO:SubProcess create_model() end ==================================
2025-05-27 20:32:59,578:INFO:Creating metrics dataframe
2025-05-27 20:32:59,583:INFO:Initializing Ada Boost Classifier
2025-05-27 20:32:59,583:INFO:Total runtime is 0.17405776182810467 minutes
2025-05-27 20:32:59,583:INFO:SubProcess create_model() called ==================================
2025-05-27 20:32:59,583:INFO:Initializing create_model()
2025-05-27 20:32:59,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:32:59,583:INFO:Checking exceptions
2025-05-27 20:32:59,583:INFO:Importing libraries
2025-05-27 20:32:59,584:INFO:Copying training dataset
2025-05-27 20:32:59,590:INFO:Defining folds
2025-05-27 20:32:59,590:INFO:Declaring metric variables
2025-05-27 20:32:59,590:INFO:Importing untrained model
2025-05-27 20:32:59,591:INFO:Ada Boost Classifier Imported successfully
2025-05-27 20:32:59,591:INFO:Starting cross validation
2025-05-27 20:32:59,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:32:59,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,805:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:32:59,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:33:00,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,132:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,135:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,141:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,142:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,142:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,144:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,145:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,147:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,152:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,154:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,155:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,157:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,158:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,159:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,160:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,162:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,164:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,168:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,169:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,170:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,173:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,175:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,179:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,185:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,269:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:33:00,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:33:00,464:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:00,469:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,470:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:00,491:INFO:Calculating mean and std
2025-05-27 20:33:00,491:INFO:Creating metrics dataframe
2025-05-27 20:33:00,493:INFO:Uploading results into container
2025-05-27 20:33:00,494:INFO:Uploading model into container now
2025-05-27 20:33:00,494:INFO:_master_model_container: 9
2025-05-27 20:33:00,494:INFO:_display_container: 2
2025-05-27 20:33:00,495:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-27 20:33:00,495:INFO:create_model() successfully completed......................................
2025-05-27 20:33:00,578:INFO:SubProcess create_model() end ==================================
2025-05-27 20:33:00,578:INFO:Creating metrics dataframe
2025-05-27 20:33:00,583:INFO:Initializing Gradient Boosting Classifier
2025-05-27 20:33:00,583:INFO:Total runtime is 0.19072623252868653 minutes
2025-05-27 20:33:00,583:INFO:SubProcess create_model() called ==================================
2025-05-27 20:33:00,583:INFO:Initializing create_model()
2025-05-27 20:33:00,583:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:33:00,583:INFO:Checking exceptions
2025-05-27 20:33:00,584:INFO:Importing libraries
2025-05-27 20:33:00,584:INFO:Copying training dataset
2025-05-27 20:33:00,590:INFO:Defining folds
2025-05-27 20:33:00,590:INFO:Declaring metric variables
2025-05-27 20:33:00,590:INFO:Importing untrained model
2025-05-27 20:33:00,591:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 20:33:00,591:INFO:Starting cross validation
2025-05-27 20:33:00,593:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:33:03,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,291:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,298:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,301:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,304:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,304:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,356:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,362:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,364:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:03,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:03,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,180:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,182:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,184:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,185:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,186:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,189:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,189:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,192:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,204:INFO:Calculating mean and std
2025-05-27 20:33:05,205:INFO:Creating metrics dataframe
2025-05-27 20:33:05,206:INFO:Uploading results into container
2025-05-27 20:33:05,207:INFO:Uploading model into container now
2025-05-27 20:33:05,207:INFO:_master_model_container: 10
2025-05-27 20:33:05,207:INFO:_display_container: 2
2025-05-27 20:33:05,208:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 20:33:05,208:INFO:create_model() successfully completed......................................
2025-05-27 20:33:05,291:INFO:SubProcess create_model() end ==================================
2025-05-27 20:33:05,291:INFO:Creating metrics dataframe
2025-05-27 20:33:05,295:INFO:Initializing Linear Discriminant Analysis
2025-05-27 20:33:05,295:INFO:Total runtime is 0.2692661245663961 minutes
2025-05-27 20:33:05,295:INFO:SubProcess create_model() called ==================================
2025-05-27 20:33:05,296:INFO:Initializing create_model()
2025-05-27 20:33:05,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:33:05,296:INFO:Checking exceptions
2025-05-27 20:33:05,296:INFO:Importing libraries
2025-05-27 20:33:05,296:INFO:Copying training dataset
2025-05-27 20:33:05,302:INFO:Defining folds
2025-05-27 20:33:05,302:INFO:Declaring metric variables
2025-05-27 20:33:05,303:INFO:Importing untrained model
2025-05-27 20:33:05,303:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 20:33:05,303:INFO:Starting cross validation
2025-05-27 20:33:05,305:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:33:05,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,594:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,599:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,600:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,602:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,605:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,606:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,612:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,616:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,617:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,620:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,625:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,771:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,774:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:33:05,776:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:33:05,777:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:05,791:INFO:Calculating mean and std
2025-05-27 20:33:05,792:INFO:Creating metrics dataframe
2025-05-27 20:33:05,794:INFO:Uploading results into container
2025-05-27 20:33:05,794:INFO:Uploading model into container now
2025-05-27 20:33:05,795:INFO:_master_model_container: 11
2025-05-27 20:33:05,795:INFO:_display_container: 2
2025-05-27 20:33:05,795:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 20:33:05,795:INFO:create_model() successfully completed......................................
2025-05-27 20:33:05,878:INFO:SubProcess create_model() end ==================================
2025-05-27 20:33:05,878:INFO:Creating metrics dataframe
2025-05-27 20:33:05,882:INFO:Initializing Extra Trees Classifier
2025-05-27 20:33:05,882:INFO:Total runtime is 0.2790535926818848 minutes
2025-05-27 20:33:05,883:INFO:SubProcess create_model() called ==================================
2025-05-27 20:33:05,883:INFO:Initializing create_model()
2025-05-27 20:33:05,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:33:05,883:INFO:Checking exceptions
2025-05-27 20:33:05,883:INFO:Importing libraries
2025-05-27 20:33:05,883:INFO:Copying training dataset
2025-05-27 20:33:05,890:INFO:Defining folds
2025-05-27 20:33:05,890:INFO:Declaring metric variables
2025-05-27 20:33:05,890:INFO:Importing untrained model
2025-05-27 20:33:05,891:INFO:Extra Trees Classifier Imported successfully
2025-05-27 20:33:05,891:INFO:Starting cross validation
2025-05-27 20:33:05,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:33:06,703:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,709:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,714:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,715:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,719:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,724:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,726:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,731:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,747:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,749:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,753:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,754:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,762:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,768:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,787:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,800:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,804:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:06,807:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,210:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,214:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:33:07,221:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,225:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:33:07,247:INFO:Calculating mean and std
2025-05-27 20:33:07,249:INFO:Creating metrics dataframe
2025-05-27 20:33:07,254:INFO:Uploading results into container
2025-05-27 20:33:07,256:INFO:Uploading model into container now
2025-05-27 20:33:07,257:INFO:_master_model_container: 12
2025-05-27 20:33:07,258:INFO:_display_container: 2
2025-05-27 20:33:07,259:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-27 20:33:07,260:INFO:create_model() successfully completed......................................
2025-05-27 20:33:07,364:INFO:SubProcess create_model() end ==================================
2025-05-27 20:33:07,364:INFO:Creating metrics dataframe
2025-05-27 20:33:07,368:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 20:33:07,369:INFO:Total runtime is 0.3038231412569682 minutes
2025-05-27 20:33:07,369:INFO:SubProcess create_model() called ==================================
2025-05-27 20:33:07,369:INFO:Initializing create_model()
2025-05-27 20:33:07,369:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc7ebca6c50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fc7c8a69b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:33:07,369:INFO:Checking exceptions
2025-05-27 20:33:07,369:INFO:Importing libraries
2025-05-27 20:33:07,369:INFO:Copying training dataset
2025-05-27 20:33:07,376:INFO:Defining folds
2025-05-27 20:33:07,376:INFO:Declaring metric variables
2025-05-27 20:33:07,377:INFO:Importing untrained model
2025-05-27 20:33:07,377:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 20:33:07,378:INFO:Starting cross validation
2025-05-27 20:33:07,380:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:34:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:34:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:34:10,106:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:34:10,706:INFO:PyCaret ClassificationExperiment
2025-05-27 20:34:10,706:INFO:Logging name: clf-default-name
2025-05-27 20:34:10,706:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 20:34:10,706:INFO:version 3.3.2
2025-05-27 20:34:10,706:INFO:Initializing setup()
2025-05-27 20:34:10,706:INFO:self.USI: 0952
2025-05-27 20:34:10,706:INFO:self._variable_keys: {'fix_imbalance', 'pipeline', 'fold_generator', 'gpu_n_jobs_param', 'logging_param', 'html_param', 'exp_id', 'idx', 'X_train', 'USI', 'data', 'gpu_param', 'fold_groups_param', 'X', 'X_test', 'memory', 'y_train', 'n_jobs_param', 'target_param', '_available_plots', 'log_plots_param', 'is_multiclass', '_ml_usecase', 'y', 'seed', 'y_test', 'fold_shuffle_param', 'exp_name_log'}
2025-05-27 20:34:10,706:INFO:Checking environment
2025-05-27 20:34:10,707:INFO:python_version: 3.10.17
2025-05-27 20:34:10,707:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 20:34:10,707:INFO:machine: x86_64
2025-05-27 20:34:10,709:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:34:10,709:INFO:Memory: svmem(total=16407515136, available=8846032896, percent=46.1, used=6234738688, free=1742315520, active=2504744960, inactive=10564456448, buffers=312180736, cached=8118280192, shared=977100800, slab=778047488)
2025-05-27 20:34:10,710:INFO:Physical Core: 4
2025-05-27 20:34:10,710:INFO:Logical Core: 8
2025-05-27 20:34:10,710:INFO:Checking libraries
2025-05-27 20:34:10,710:INFO:System:
2025-05-27 20:34:10,710:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 20:34:10,710:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 20:34:10,710:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:34:10,710:INFO:PyCaret required dependencies:
2025-05-27 20:34:10,730:INFO:                 pip: 25.1.1
2025-05-27 20:34:10,730:INFO:          setuptools: 65.5.0
2025-05-27 20:34:10,730:INFO:             pycaret: 3.3.2
2025-05-27 20:34:10,730:INFO:             IPython: 8.36.0
2025-05-27 20:34:10,730:INFO:          ipywidgets: 8.1.7
2025-05-27 20:34:10,730:INFO:                tqdm: 4.67.1
2025-05-27 20:34:10,730:INFO:               numpy: 1.26.4
2025-05-27 20:34:10,730:INFO:              pandas: 2.1.4
2025-05-27 20:34:10,730:INFO:              jinja2: 3.1.6
2025-05-27 20:34:10,731:INFO:               scipy: 1.11.4
2025-05-27 20:34:10,731:INFO:              joblib: 1.3.2
2025-05-27 20:34:10,731:INFO:             sklearn: 1.4.2
2025-05-27 20:34:10,731:INFO:                pyod: 2.0.5
2025-05-27 20:34:10,731:INFO:            imblearn: 0.13.0
2025-05-27 20:34:10,731:INFO:   category_encoders: 2.6.2
2025-05-27 20:34:10,731:INFO:            lightgbm: 4.6.0
2025-05-27 20:34:10,731:INFO:               numba: 0.61.2
2025-05-27 20:34:10,731:INFO:            requests: 2.32.3
2025-05-27 20:34:10,731:INFO:          matplotlib: 3.7.5
2025-05-27 20:34:10,731:INFO:          scikitplot: 0.3.7
2025-05-27 20:34:10,731:INFO:         yellowbrick: 1.5
2025-05-27 20:34:10,731:INFO:              plotly: 5.24.1
2025-05-27 20:34:10,731:INFO:    plotly-resampler: Not installed
2025-05-27 20:34:10,731:INFO:             kaleido: 0.2.1
2025-05-27 20:34:10,731:INFO:           schemdraw: 0.15
2025-05-27 20:34:10,731:INFO:         statsmodels: 0.14.4
2025-05-27 20:34:10,731:INFO:              sktime: 0.26.0
2025-05-27 20:34:10,731:INFO:               tbats: 1.1.3
2025-05-27 20:34:10,731:INFO:            pmdarima: 2.0.4
2025-05-27 20:34:10,731:INFO:              psutil: 7.0.0
2025-05-27 20:34:10,731:INFO:          markupsafe: 3.0.2
2025-05-27 20:34:10,731:INFO:             pickle5: Not installed
2025-05-27 20:34:10,731:INFO:         cloudpickle: 3.1.1
2025-05-27 20:34:10,731:INFO:         deprecation: 2.1.0
2025-05-27 20:34:10,731:INFO:              xxhash: 3.5.0
2025-05-27 20:34:10,731:INFO:           wurlitzer: 3.1.1
2025-05-27 20:34:10,731:INFO:PyCaret optional dependencies:
2025-05-27 20:34:11,118:INFO:                shap: Not installed
2025-05-27 20:34:11,118:INFO:           interpret: Not installed
2025-05-27 20:34:11,118:INFO:                umap: Not installed
2025-05-27 20:34:11,118:INFO:     ydata_profiling: Not installed
2025-05-27 20:34:11,118:INFO:  explainerdashboard: Not installed
2025-05-27 20:34:11,118:INFO:             autoviz: Not installed
2025-05-27 20:34:11,119:INFO:           fairlearn: Not installed
2025-05-27 20:34:11,119:INFO:          deepchecks: Not installed
2025-05-27 20:34:11,119:INFO:             xgboost: Not installed
2025-05-27 20:34:11,119:INFO:            catboost: Not installed
2025-05-27 20:34:11,119:INFO:              kmodes: Not installed
2025-05-27 20:34:11,119:INFO:             mlxtend: Not installed
2025-05-27 20:34:11,119:INFO:       statsforecast: Not installed
2025-05-27 20:34:11,119:INFO:        tune_sklearn: Not installed
2025-05-27 20:34:11,119:INFO:                 ray: Not installed
2025-05-27 20:34:11,119:INFO:            hyperopt: Not installed
2025-05-27 20:34:11,119:INFO:              optuna: Not installed
2025-05-27 20:34:11,119:INFO:               skopt: Not installed
2025-05-27 20:34:11,119:INFO:              mlflow: Not installed
2025-05-27 20:34:11,119:INFO:              gradio: Not installed
2025-05-27 20:34:11,119:INFO:             fastapi: 0.115.12
2025-05-27 20:34:11,119:INFO:             uvicorn: 0.34.2
2025-05-27 20:34:11,119:INFO:              m2cgen: Not installed
2025-05-27 20:34:11,119:INFO:           evidently: Not installed
2025-05-27 20:34:11,119:INFO:               fugue: Not installed
2025-05-27 20:34:11,119:INFO:           streamlit: Not installed
2025-05-27 20:34:11,119:INFO:             prophet: Not installed
2025-05-27 20:34:11,119:INFO:None
2025-05-27 20:34:11,119:INFO:Set up data.
2025-05-27 20:34:11,131:INFO:Set up folding strategy.
2025-05-27 20:34:11,131:INFO:Set up train/test split.
2025-05-27 20:34:11,140:INFO:Set up index.
2025-05-27 20:34:11,141:INFO:Assigning column types.
2025-05-27 20:34:11,144:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 20:34:11,189:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,192:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,223:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,268:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,268:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,296:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 20:34:11,341:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,413:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:34:11,441:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,441:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,441:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 20:34:11,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,585:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,586:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:11,587:INFO:Preparing preprocessing pipeline...
2025-05-27 20:34:11,588:INFO:Set up label encoding.
2025-05-27 20:34:11,588:INFO:Set up simple imputation.
2025-05-27 20:34:11,594:INFO:Set up encoding of ordinal features.
2025-05-27 20:34:11,602:INFO:Set up encoding of categorical features.
2025-05-27 20:34:11,754:INFO:Finished creating preprocessing pipeline.
2025-05-27 20:34:11,812:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 20:34:11,812:INFO:Creating final display dataframe.
2025-05-27 20:34:12,201:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           123
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                          mean
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                            10
19                     CPU Jobs                            -1
20                      Use GPU                         False
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          0952
2025-05-27 20:34:12,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:12,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:12,353:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:12,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:34:12,355:INFO:setup() successfully completed in 1.65s...............
2025-05-27 20:34:12,355:INFO:Initializing compare_models()
2025-05-27 20:34:12,355:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 20:34:12,355:INFO:Checking exceptions
2025-05-27 20:34:12,359:INFO:Preparing display monitor
2025-05-27 20:34:12,362:INFO:Initializing Logistic Regression
2025-05-27 20:34:12,362:INFO:Total runtime is 1.422564188639323e-06 minutes
2025-05-27 20:34:12,362:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:12,363:INFO:Initializing create_model()
2025-05-27 20:34:12,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:12,363:INFO:Checking exceptions
2025-05-27 20:34:12,363:INFO:Importing libraries
2025-05-27 20:34:12,363:INFO:Copying training dataset
2025-05-27 20:34:12,368:INFO:Defining folds
2025-05-27 20:34:12,368:INFO:Declaring metric variables
2025-05-27 20:34:12,368:INFO:Importing untrained model
2025-05-27 20:34:12,369:INFO:Logistic Regression Imported successfully
2025-05-27 20:34:12,369:INFO:Starting cross validation
2025-05-27 20:34:12,372:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:16,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,357:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,357:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,362:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,382:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,421:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,425:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:16,436:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,437:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,438:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,440:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,442:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,446:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,452:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,455:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,458:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,465:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,524:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:16,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:16,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,213:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:17,220:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:34:17,257:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:17,259:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,263:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,264:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:17,266:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,266:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,288:INFO:Calculating mean and std
2025-05-27 20:34:17,289:INFO:Creating metrics dataframe
2025-05-27 20:34:17,292:INFO:Uploading results into container
2025-05-27 20:34:17,292:INFO:Uploading model into container now
2025-05-27 20:34:17,293:INFO:_master_model_container: 1
2025-05-27 20:34:17,293:INFO:_display_container: 2
2025-05-27 20:34:17,293:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 20:34:17,293:INFO:create_model() successfully completed......................................
2025-05-27 20:34:17,398:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:17,398:INFO:Creating metrics dataframe
2025-05-27 20:34:17,401:INFO:Initializing K Neighbors Classifier
2025-05-27 20:34:17,401:INFO:Total runtime is 0.08398708105087281 minutes
2025-05-27 20:34:17,402:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:17,402:INFO:Initializing create_model()
2025-05-27 20:34:17,402:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:17,402:INFO:Checking exceptions
2025-05-27 20:34:17,402:INFO:Importing libraries
2025-05-27 20:34:17,402:INFO:Copying training dataset
2025-05-27 20:34:17,409:INFO:Defining folds
2025-05-27 20:34:17,409:INFO:Declaring metric variables
2025-05-27 20:34:17,409:INFO:Importing untrained model
2025-05-27 20:34:17,409:INFO:K Neighbors Classifier Imported successfully
2025-05-27 20:34:17,409:INFO:Starting cross validation
2025-05-27 20:34:17,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:17,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,795:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,801:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,802:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,802:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,816:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:17,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,000:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,014:INFO:Calculating mean and std
2025-05-27 20:34:18,015:INFO:Creating metrics dataframe
2025-05-27 20:34:18,017:INFO:Uploading results into container
2025-05-27 20:34:18,018:INFO:Uploading model into container now
2025-05-27 20:34:18,018:INFO:_master_model_container: 2
2025-05-27 20:34:18,018:INFO:_display_container: 2
2025-05-27 20:34:18,018:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 20:34:18,018:INFO:create_model() successfully completed......................................
2025-05-27 20:34:18,101:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:18,101:INFO:Creating metrics dataframe
2025-05-27 20:34:18,106:INFO:Initializing Naive Bayes
2025-05-27 20:34:18,106:INFO:Total runtime is 0.09572367668151856 minutes
2025-05-27 20:34:18,106:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:18,106:INFO:Initializing create_model()
2025-05-27 20:34:18,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:18,106:INFO:Checking exceptions
2025-05-27 20:34:18,107:INFO:Importing libraries
2025-05-27 20:34:18,107:INFO:Copying training dataset
2025-05-27 20:34:18,116:INFO:Defining folds
2025-05-27 20:34:18,116:INFO:Declaring metric variables
2025-05-27 20:34:18,116:INFO:Importing untrained model
2025-05-27 20:34:18,116:INFO:Naive Bayes Imported successfully
2025-05-27 20:34:18,116:INFO:Starting cross validation
2025-05-27 20:34:18,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:18,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,425:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,426:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,438:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,443:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,444:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,444:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,447:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,450:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,455:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,456:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,462:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,467:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,469:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,620:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,621:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,625:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:18,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:18,646:INFO:Calculating mean and std
2025-05-27 20:34:18,647:INFO:Creating metrics dataframe
2025-05-27 20:34:18,649:INFO:Uploading results into container
2025-05-27 20:34:18,650:INFO:Uploading model into container now
2025-05-27 20:34:18,650:INFO:_master_model_container: 3
2025-05-27 20:34:18,650:INFO:_display_container: 2
2025-05-27 20:34:18,650:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 20:34:18,650:INFO:create_model() successfully completed......................................
2025-05-27 20:34:18,734:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:18,734:INFO:Creating metrics dataframe
2025-05-27 20:34:18,739:INFO:Initializing Decision Tree Classifier
2025-05-27 20:34:18,739:INFO:Total runtime is 0.10627992947896323 minutes
2025-05-27 20:34:18,739:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:18,740:INFO:Initializing create_model()
2025-05-27 20:34:18,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:18,740:INFO:Checking exceptions
2025-05-27 20:34:18,740:INFO:Importing libraries
2025-05-27 20:34:18,740:INFO:Copying training dataset
2025-05-27 20:34:18,747:INFO:Defining folds
2025-05-27 20:34:18,747:INFO:Declaring metric variables
2025-05-27 20:34:18,747:INFO:Importing untrained model
2025-05-27 20:34:18,747:INFO:Decision Tree Classifier Imported successfully
2025-05-27 20:34:18,748:INFO:Starting cross validation
2025-05-27 20:34:18,750:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:19,059:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,063:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,072:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,073:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,076:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,079:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,081:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,084:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,085:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,086:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,090:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,097:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,098:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,101:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,110:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,266:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,266:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,282:INFO:Calculating mean and std
2025-05-27 20:34:19,283:INFO:Creating metrics dataframe
2025-05-27 20:34:19,288:INFO:Uploading results into container
2025-05-27 20:34:19,289:INFO:Uploading model into container now
2025-05-27 20:34:19,290:INFO:_master_model_container: 4
2025-05-27 20:34:19,290:INFO:_display_container: 2
2025-05-27 20:34:19,291:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-27 20:34:19,291:INFO:create_model() successfully completed......................................
2025-05-27 20:34:19,391:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:19,391:INFO:Creating metrics dataframe
2025-05-27 20:34:19,395:INFO:Initializing SVM - Linear Kernel
2025-05-27 20:34:19,395:INFO:Total runtime is 0.11720895767211915 minutes
2025-05-27 20:34:19,395:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:19,395:INFO:Initializing create_model()
2025-05-27 20:34:19,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:19,395:INFO:Checking exceptions
2025-05-27 20:34:19,396:INFO:Importing libraries
2025-05-27 20:34:19,396:INFO:Copying training dataset
2025-05-27 20:34:19,401:INFO:Defining folds
2025-05-27 20:34:19,402:INFO:Declaring metric variables
2025-05-27 20:34:19,402:INFO:Importing untrained model
2025-05-27 20:34:19,402:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 20:34:19,403:INFO:Starting cross validation
2025-05-27 20:34:19,405:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:19,765:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,772:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,772:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,785:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,799:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,802:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,812:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,816:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,819:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,819:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,820:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,825:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,826:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,826:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,829:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,829:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,832:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,851:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,853:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,857:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,859:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:19,861:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,988:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,990:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:19,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:19,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,004:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,006:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,022:INFO:Calculating mean and std
2025-05-27 20:34:20,023:INFO:Creating metrics dataframe
2025-05-27 20:34:20,028:INFO:Uploading results into container
2025-05-27 20:34:20,029:INFO:Uploading model into container now
2025-05-27 20:34:20,030:INFO:_master_model_container: 5
2025-05-27 20:34:20,030:INFO:_display_container: 2
2025-05-27 20:34:20,031:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 20:34:20,031:INFO:create_model() successfully completed......................................
2025-05-27 20:34:20,141:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:20,142:INFO:Creating metrics dataframe
2025-05-27 20:34:20,146:INFO:Initializing Ridge Classifier
2025-05-27 20:34:20,146:INFO:Total runtime is 0.12973496516545616 minutes
2025-05-27 20:34:20,147:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:20,147:INFO:Initializing create_model()
2025-05-27 20:34:20,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:20,147:INFO:Checking exceptions
2025-05-27 20:34:20,147:INFO:Importing libraries
2025-05-27 20:34:20,147:INFO:Copying training dataset
2025-05-27 20:34:20,154:INFO:Defining folds
2025-05-27 20:34:20,154:INFO:Declaring metric variables
2025-05-27 20:34:20,155:INFO:Importing untrained model
2025-05-27 20:34:20,155:INFO:Ridge Classifier Imported successfully
2025-05-27 20:34:20,156:INFO:Starting cross validation
2025-05-27 20:34:20,158:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:20,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,444:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,455:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,458:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,459:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,459:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,462:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,465:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,469:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,473:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,476:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,481:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,481:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,487:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,487:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:20,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:20,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:20,658:INFO:Calculating mean and std
2025-05-27 20:34:20,658:INFO:Creating metrics dataframe
2025-05-27 20:34:20,661:INFO:Uploading results into container
2025-05-27 20:34:20,661:INFO:Uploading model into container now
2025-05-27 20:34:20,661:INFO:_master_model_container: 6
2025-05-27 20:34:20,661:INFO:_display_container: 2
2025-05-27 20:34:20,662:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-27 20:34:20,662:INFO:create_model() successfully completed......................................
2025-05-27 20:34:20,742:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:20,742:INFO:Creating metrics dataframe
2025-05-27 20:34:20,747:INFO:Initializing Random Forest Classifier
2025-05-27 20:34:20,747:INFO:Total runtime is 0.13974380890528362 minutes
2025-05-27 20:34:20,747:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:20,747:INFO:Initializing create_model()
2025-05-27 20:34:20,748:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:20,748:INFO:Checking exceptions
2025-05-27 20:34:20,748:INFO:Importing libraries
2025-05-27 20:34:20,748:INFO:Copying training dataset
2025-05-27 20:34:20,754:INFO:Defining folds
2025-05-27 20:34:20,755:INFO:Declaring metric variables
2025-05-27 20:34:20,755:INFO:Importing untrained model
2025-05-27 20:34:20,755:INFO:Random Forest Classifier Imported successfully
2025-05-27 20:34:20,756:INFO:Starting cross validation
2025-05-27 20:34:20,758:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:21,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,648:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,662:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,664:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,684:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,695:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,701:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,707:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,708:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,711:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,723:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,729:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:21,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,159:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,165:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,168:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,170:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,173:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,179:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,196:INFO:Calculating mean and std
2025-05-27 20:34:22,198:INFO:Creating metrics dataframe
2025-05-27 20:34:22,204:INFO:Uploading results into container
2025-05-27 20:34:22,205:INFO:Uploading model into container now
2025-05-27 20:34:22,207:INFO:_master_model_container: 7
2025-05-27 20:34:22,207:INFO:_display_container: 2
2025-05-27 20:34:22,208:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-27 20:34:22,208:INFO:create_model() successfully completed......................................
2025-05-27 20:34:22,302:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:22,302:INFO:Creating metrics dataframe
2025-05-27 20:34:22,306:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 20:34:22,306:INFO:Total runtime is 0.16573363145192466 minutes
2025-05-27 20:34:22,306:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:22,307:INFO:Initializing create_model()
2025-05-27 20:34:22,307:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:22,307:INFO:Checking exceptions
2025-05-27 20:34:22,307:INFO:Importing libraries
2025-05-27 20:34:22,307:INFO:Copying training dataset
2025-05-27 20:34:22,314:INFO:Defining folds
2025-05-27 20:34:22,314:INFO:Declaring metric variables
2025-05-27 20:34:22,314:INFO:Importing untrained model
2025-05-27 20:34:22,314:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 20:34:22,315:INFO:Starting cross validation
2025-05-27 20:34:22,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:22,531:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,548:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,552:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,552:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,583:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,637:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,637:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,665:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,669:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,670:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,675:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,759:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,770:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:34:22,804:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,806:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,816:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:22,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,824:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:22,840:INFO:Calculating mean and std
2025-05-27 20:34:22,841:INFO:Creating metrics dataframe
2025-05-27 20:34:22,843:INFO:Uploading results into container
2025-05-27 20:34:22,843:INFO:Uploading model into container now
2025-05-27 20:34:22,844:INFO:_master_model_container: 8
2025-05-27 20:34:22,844:INFO:_display_container: 2
2025-05-27 20:34:22,844:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 20:34:22,844:INFO:create_model() successfully completed......................................
2025-05-27 20:34:22,928:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:22,928:INFO:Creating metrics dataframe
2025-05-27 20:34:22,933:INFO:Initializing Ada Boost Classifier
2025-05-27 20:34:22,933:INFO:Total runtime is 0.17618088722229006 minutes
2025-05-27 20:34:22,933:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:22,934:INFO:Initializing create_model()
2025-05-27 20:34:22,934:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:22,934:INFO:Checking exceptions
2025-05-27 20:34:22,934:INFO:Importing libraries
2025-05-27 20:34:22,934:INFO:Copying training dataset
2025-05-27 20:34:22,941:INFO:Defining folds
2025-05-27 20:34:22,941:INFO:Declaring metric variables
2025-05-27 20:34:22,941:INFO:Importing untrained model
2025-05-27 20:34:22,941:INFO:Ada Boost Classifier Imported successfully
2025-05-27 20:34:22,942:INFO:Starting cross validation
2025-05-27 20:34:22,944:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:23,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,154:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,162:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,166:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,176:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,182:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,187:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,191:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,526:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,529:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,530:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,539:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,540:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,640:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:34:23,832:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,838:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:23,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,844:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:23,857:INFO:Calculating mean and std
2025-05-27 20:34:23,857:INFO:Creating metrics dataframe
2025-05-27 20:34:23,859:INFO:Uploading results into container
2025-05-27 20:34:23,860:INFO:Uploading model into container now
2025-05-27 20:34:23,860:INFO:_master_model_container: 9
2025-05-27 20:34:23,860:INFO:_display_container: 2
2025-05-27 20:34:23,861:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-27 20:34:23,861:INFO:create_model() successfully completed......................................
2025-05-27 20:34:23,945:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:23,945:INFO:Creating metrics dataframe
2025-05-27 20:34:23,949:INFO:Initializing Gradient Boosting Classifier
2025-05-27 20:34:23,950:INFO:Total runtime is 0.19312152465184532 minutes
2025-05-27 20:34:23,950:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:23,950:INFO:Initializing create_model()
2025-05-27 20:34:23,950:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:23,950:INFO:Checking exceptions
2025-05-27 20:34:23,951:INFO:Importing libraries
2025-05-27 20:34:23,951:INFO:Copying training dataset
2025-05-27 20:34:23,957:INFO:Defining folds
2025-05-27 20:34:23,957:INFO:Declaring metric variables
2025-05-27 20:34:23,958:INFO:Importing untrained model
2025-05-27 20:34:23,958:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 20:34:23,959:INFO:Starting cross validation
2025-05-27 20:34:23,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:26,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,661:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,664:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,681:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,681:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,684:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,688:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,694:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,697:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,706:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,708:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,711:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,712:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,712:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,713:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,717:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,721:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,723:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,724:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:26,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,731:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:26,735:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,548:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,566:INFO:Calculating mean and std
2025-05-27 20:34:28,566:INFO:Creating metrics dataframe
2025-05-27 20:34:28,568:INFO:Uploading results into container
2025-05-27 20:34:28,569:INFO:Uploading model into container now
2025-05-27 20:34:28,569:INFO:_master_model_container: 10
2025-05-27 20:34:28,569:INFO:_display_container: 2
2025-05-27 20:34:28,570:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 20:34:28,570:INFO:create_model() successfully completed......................................
2025-05-27 20:34:28,653:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:28,654:INFO:Creating metrics dataframe
2025-05-27 20:34:28,658:INFO:Initializing Linear Discriminant Analysis
2025-05-27 20:34:28,658:INFO:Total runtime is 0.27159471114476524 minutes
2025-05-27 20:34:28,658:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:28,658:INFO:Initializing create_model()
2025-05-27 20:34:28,659:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:28,659:INFO:Checking exceptions
2025-05-27 20:34:28,659:INFO:Importing libraries
2025-05-27 20:34:28,659:INFO:Copying training dataset
2025-05-27 20:34:28,665:INFO:Defining folds
2025-05-27 20:34:28,665:INFO:Declaring metric variables
2025-05-27 20:34:28,665:INFO:Importing untrained model
2025-05-27 20:34:28,666:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 20:34:28,666:INFO:Starting cross validation
2025-05-27 20:34:28,668:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:28,952:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,962:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,965:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,967:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,970:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,972:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,972:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,984:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,989:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:28,990:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,992:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:28,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:29,136:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,140:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,141:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:34:29,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,146:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:29,150:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:29,159:INFO:Calculating mean and std
2025-05-27 20:34:29,160:INFO:Creating metrics dataframe
2025-05-27 20:34:29,162:INFO:Uploading results into container
2025-05-27 20:34:29,163:INFO:Uploading model into container now
2025-05-27 20:34:29,163:INFO:_master_model_container: 11
2025-05-27 20:34:29,163:INFO:_display_container: 2
2025-05-27 20:34:29,163:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 20:34:29,163:INFO:create_model() successfully completed......................................
2025-05-27 20:34:29,242:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:29,242:INFO:Creating metrics dataframe
2025-05-27 20:34:29,247:INFO:Initializing Extra Trees Classifier
2025-05-27 20:34:29,247:INFO:Total runtime is 0.28140946229298913 minutes
2025-05-27 20:34:29,247:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:29,247:INFO:Initializing create_model()
2025-05-27 20:34:29,247:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:29,247:INFO:Checking exceptions
2025-05-27 20:34:29,248:INFO:Importing libraries
2025-05-27 20:34:29,248:INFO:Copying training dataset
2025-05-27 20:34:29,254:INFO:Defining folds
2025-05-27 20:34:29,254:INFO:Declaring metric variables
2025-05-27 20:34:29,254:INFO:Importing untrained model
2025-05-27 20:34:29,255:INFO:Extra Trees Classifier Imported successfully
2025-05-27 20:34:29,255:INFO:Starting cross validation
2025-05-27 20:34:29,257:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:34:30,038:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,045:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,045:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,051:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,052:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,058:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,059:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,097:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,101:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,110:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,147:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,153:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,159:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,169:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,176:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,608:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,617:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:34:30,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:34:30,647:INFO:Calculating mean and std
2025-05-27 20:34:30,648:INFO:Creating metrics dataframe
2025-05-27 20:34:30,652:INFO:Uploading results into container
2025-05-27 20:34:30,653:INFO:Uploading model into container now
2025-05-27 20:34:30,654:INFO:_master_model_container: 12
2025-05-27 20:34:30,654:INFO:_display_container: 2
2025-05-27 20:34:30,655:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-27 20:34:30,656:INFO:create_model() successfully completed......................................
2025-05-27 20:34:30,783:INFO:SubProcess create_model() end ==================================
2025-05-27 20:34:30,784:INFO:Creating metrics dataframe
2025-05-27 20:34:30,789:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 20:34:30,789:INFO:Total runtime is 0.30711165269215907 minutes
2025-05-27 20:34:30,789:INFO:SubProcess create_model() called ==================================
2025-05-27 20:34:30,790:INFO:Initializing create_model()
2025-05-27 20:34:30,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f0c667cec50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f0c434f9b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:34:30,790:INFO:Checking exceptions
2025-05-27 20:34:30,790:INFO:Importing libraries
2025-05-27 20:34:30,790:INFO:Copying training dataset
2025-05-27 20:34:30,800:INFO:Defining folds
2025-05-27 20:34:30,800:INFO:Declaring metric variables
2025-05-27 20:34:30,800:INFO:Importing untrained model
2025-05-27 20:34:30,802:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 20:34:30,802:INFO:Starting cross validation
2025-05-27 20:34:30,806:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:39,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:35:39,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:35:39,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:35:39,914:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:35:40,506:INFO:PyCaret ClassificationExperiment
2025-05-27 20:35:40,507:INFO:Logging name: clf-default-name
2025-05-27 20:35:40,507:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 20:35:40,507:INFO:version 3.3.2
2025-05-27 20:35:40,507:INFO:Initializing setup()
2025-05-27 20:35:40,507:INFO:self.USI: 126b
2025-05-27 20:35:40,507:INFO:self._variable_keys: {'USI', 'X_test', 'fold_generator', 'fold_groups_param', 'X_train', 'gpu_param', 'data', 'idx', 'memory', 'gpu_n_jobs_param', 'is_multiclass', 'y_test', '_available_plots', 'exp_id', 'pipeline', 'fix_imbalance', '_ml_usecase', 'y', 'target_param', 'html_param', 'exp_name_log', 'n_jobs_param', 'seed', 'log_plots_param', 'logging_param', 'fold_shuffle_param', 'X', 'y_train'}
2025-05-27 20:35:40,507:INFO:Checking environment
2025-05-27 20:35:40,507:INFO:python_version: 3.10.17
2025-05-27 20:35:40,507:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 20:35:40,507:INFO:machine: x86_64
2025-05-27 20:35:40,509:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:35:40,509:INFO:Memory: svmem(total=16407515136, available=8845205504, percent=46.1, used=6250180608, free=1740345344, active=2506764288, inactive=10549153792, buffers=312467456, cached=8104521728, shared=962486272, slab=778334208)
2025-05-27 20:35:40,510:INFO:Physical Core: 4
2025-05-27 20:35:40,510:INFO:Logical Core: 8
2025-05-27 20:35:40,510:INFO:Checking libraries
2025-05-27 20:35:40,511:INFO:System:
2025-05-27 20:35:40,511:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 20:35:40,511:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 20:35:40,511:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:35:40,511:INFO:PyCaret required dependencies:
2025-05-27 20:35:40,532:INFO:                 pip: 25.1.1
2025-05-27 20:35:40,532:INFO:          setuptools: 65.5.0
2025-05-27 20:35:40,532:INFO:             pycaret: 3.3.2
2025-05-27 20:35:40,532:INFO:             IPython: 8.36.0
2025-05-27 20:35:40,532:INFO:          ipywidgets: 8.1.7
2025-05-27 20:35:40,532:INFO:                tqdm: 4.67.1
2025-05-27 20:35:40,533:INFO:               numpy: 1.26.4
2025-05-27 20:35:40,533:INFO:              pandas: 2.1.4
2025-05-27 20:35:40,533:INFO:              jinja2: 3.1.6
2025-05-27 20:35:40,533:INFO:               scipy: 1.11.4
2025-05-27 20:35:40,533:INFO:              joblib: 1.3.2
2025-05-27 20:35:40,533:INFO:             sklearn: 1.4.2
2025-05-27 20:35:40,533:INFO:                pyod: 2.0.5
2025-05-27 20:35:40,533:INFO:            imblearn: 0.13.0
2025-05-27 20:35:40,533:INFO:   category_encoders: 2.6.2
2025-05-27 20:35:40,533:INFO:            lightgbm: 4.6.0
2025-05-27 20:35:40,533:INFO:               numba: 0.61.2
2025-05-27 20:35:40,533:INFO:            requests: 2.32.3
2025-05-27 20:35:40,533:INFO:          matplotlib: 3.7.5
2025-05-27 20:35:40,533:INFO:          scikitplot: 0.3.7
2025-05-27 20:35:40,533:INFO:         yellowbrick: 1.5
2025-05-27 20:35:40,533:INFO:              plotly: 5.24.1
2025-05-27 20:35:40,533:INFO:    plotly-resampler: Not installed
2025-05-27 20:35:40,533:INFO:             kaleido: 0.2.1
2025-05-27 20:35:40,533:INFO:           schemdraw: 0.15
2025-05-27 20:35:40,533:INFO:         statsmodels: 0.14.4
2025-05-27 20:35:40,533:INFO:              sktime: 0.26.0
2025-05-27 20:35:40,533:INFO:               tbats: 1.1.3
2025-05-27 20:35:40,533:INFO:            pmdarima: 2.0.4
2025-05-27 20:35:40,533:INFO:              psutil: 7.0.0
2025-05-27 20:35:40,533:INFO:          markupsafe: 3.0.2
2025-05-27 20:35:40,533:INFO:             pickle5: Not installed
2025-05-27 20:35:40,533:INFO:         cloudpickle: 3.1.1
2025-05-27 20:35:40,533:INFO:         deprecation: 2.1.0
2025-05-27 20:35:40,533:INFO:              xxhash: 3.5.0
2025-05-27 20:35:40,534:INFO:           wurlitzer: 3.1.1
2025-05-27 20:35:40,534:INFO:PyCaret optional dependencies:
2025-05-27 20:35:40,919:INFO:                shap: Not installed
2025-05-27 20:35:40,919:INFO:           interpret: Not installed
2025-05-27 20:35:40,919:INFO:                umap: Not installed
2025-05-27 20:35:40,919:INFO:     ydata_profiling: Not installed
2025-05-27 20:35:40,919:INFO:  explainerdashboard: Not installed
2025-05-27 20:35:40,919:INFO:             autoviz: Not installed
2025-05-27 20:35:40,919:INFO:           fairlearn: Not installed
2025-05-27 20:35:40,919:INFO:          deepchecks: Not installed
2025-05-27 20:35:40,919:INFO:             xgboost: Not installed
2025-05-27 20:35:40,919:INFO:            catboost: Not installed
2025-05-27 20:35:40,919:INFO:              kmodes: Not installed
2025-05-27 20:35:40,920:INFO:             mlxtend: Not installed
2025-05-27 20:35:40,920:INFO:       statsforecast: Not installed
2025-05-27 20:35:40,920:INFO:        tune_sklearn: Not installed
2025-05-27 20:35:40,920:INFO:                 ray: Not installed
2025-05-27 20:35:40,920:INFO:            hyperopt: Not installed
2025-05-27 20:35:40,920:INFO:              optuna: Not installed
2025-05-27 20:35:40,920:INFO:               skopt: Not installed
2025-05-27 20:35:40,920:INFO:              mlflow: Not installed
2025-05-27 20:35:40,920:INFO:              gradio: Not installed
2025-05-27 20:35:40,920:INFO:             fastapi: 0.115.12
2025-05-27 20:35:40,920:INFO:             uvicorn: 0.34.2
2025-05-27 20:35:40,920:INFO:              m2cgen: Not installed
2025-05-27 20:35:40,920:INFO:           evidently: Not installed
2025-05-27 20:35:40,920:INFO:               fugue: Not installed
2025-05-27 20:35:40,920:INFO:           streamlit: Not installed
2025-05-27 20:35:40,921:INFO:             prophet: Not installed
2025-05-27 20:35:40,921:INFO:None
2025-05-27 20:35:40,921:INFO:Set up data.
2025-05-27 20:35:40,938:INFO:Set up folding strategy.
2025-05-27 20:35:40,938:INFO:Set up train/test split.
2025-05-27 20:35:40,947:INFO:Set up index.
2025-05-27 20:35:40,948:INFO:Assigning column types.
2025-05-27 20:35:40,951:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 20:35:40,997:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,000:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,031:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,032:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,079:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,107:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 20:35:41,157:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,233:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:35:41,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,261:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,262:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 20:35:41,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,410:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:41,412:INFO:Preparing preprocessing pipeline...
2025-05-27 20:35:41,413:INFO:Set up label encoding.
2025-05-27 20:35:41,413:INFO:Set up simple imputation.
2025-05-27 20:35:41,418:INFO:Set up encoding of ordinal features.
2025-05-27 20:35:41,427:INFO:Set up encoding of categorical features.
2025-05-27 20:35:41,578:INFO:Finished creating preprocessing pipeline.
2025-05-27 20:35:41,637:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 20:35:41,638:INFO:Creating final display dataframe.
2025-05-27 20:35:42,026:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           123
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                          mean
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                            10
19                     CPU Jobs                            -1
20                      Use GPU                         False
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          126b
2025-05-27 20:35:42,108:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:42,108:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:42,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:42,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:35:42,184:INFO:setup() successfully completed in 1.68s...............
2025-05-27 20:35:42,184:INFO:Initializing compare_models()
2025-05-27 20:35:42,184:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 20:35:42,184:INFO:Checking exceptions
2025-05-27 20:35:42,189:INFO:Preparing display monitor
2025-05-27 20:35:42,193:INFO:Initializing Logistic Regression
2025-05-27 20:35:42,193:INFO:Total runtime is 1.5417734781901042e-06 minutes
2025-05-27 20:35:42,193:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:42,193:INFO:Initializing create_model()
2025-05-27 20:35:42,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:42,193:INFO:Checking exceptions
2025-05-27 20:35:42,193:INFO:Importing libraries
2025-05-27 20:35:42,193:INFO:Copying training dataset
2025-05-27 20:35:42,199:INFO:Defining folds
2025-05-27 20:35:42,199:INFO:Declaring metric variables
2025-05-27 20:35:42,199:INFO:Importing untrained model
2025-05-27 20:35:42,199:INFO:Logistic Regression Imported successfully
2025-05-27 20:35:42,200:INFO:Starting cross validation
2025-05-27 20:35:42,202:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:46,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,230:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,258:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,290:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,296:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,297:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,298:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,303:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,303:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,305:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,308:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,311:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,327:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:46,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,356:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,364:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,410:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,415:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:46,470:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:46,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,182:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:47,231:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:47,231:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:35:47,233:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,237:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,241:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:47,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,290:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,309:INFO:Calculating mean and std
2025-05-27 20:35:47,310:INFO:Creating metrics dataframe
2025-05-27 20:35:47,313:INFO:Uploading results into container
2025-05-27 20:35:47,314:INFO:Uploading model into container now
2025-05-27 20:35:47,314:INFO:_master_model_container: 1
2025-05-27 20:35:47,314:INFO:_display_container: 2
2025-05-27 20:35:47,315:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 20:35:47,315:INFO:create_model() successfully completed......................................
2025-05-27 20:35:47,428:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:47,428:INFO:Creating metrics dataframe
2025-05-27 20:35:47,432:INFO:Initializing K Neighbors Classifier
2025-05-27 20:35:47,432:INFO:Total runtime is 0.0873257319132487 minutes
2025-05-27 20:35:47,432:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:47,433:INFO:Initializing create_model()
2025-05-27 20:35:47,433:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:47,433:INFO:Checking exceptions
2025-05-27 20:35:47,433:INFO:Importing libraries
2025-05-27 20:35:47,433:INFO:Copying training dataset
2025-05-27 20:35:47,441:INFO:Defining folds
2025-05-27 20:35:47,441:INFO:Declaring metric variables
2025-05-27 20:35:47,441:INFO:Importing untrained model
2025-05-27 20:35:47,441:INFO:K Neighbors Classifier Imported successfully
2025-05-27 20:35:47,442:INFO:Starting cross validation
2025-05-27 20:35:47,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:47,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,853:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,858:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,859:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,860:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,863:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,864:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,867:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,871:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,871:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,872:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,877:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,884:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,885:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,887:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,888:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:47,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,060:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,061:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,068:INFO:Calculating mean and std
2025-05-27 20:35:48,068:INFO:Creating metrics dataframe
2025-05-27 20:35:48,070:INFO:Uploading results into container
2025-05-27 20:35:48,071:INFO:Uploading model into container now
2025-05-27 20:35:48,071:INFO:_master_model_container: 2
2025-05-27 20:35:48,071:INFO:_display_container: 2
2025-05-27 20:35:48,071:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 20:35:48,071:INFO:create_model() successfully completed......................................
2025-05-27 20:35:48,153:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:48,153:INFO:Creating metrics dataframe
2025-05-27 20:35:48,157:INFO:Initializing Naive Bayes
2025-05-27 20:35:48,158:INFO:Total runtime is 0.09941727717717488 minutes
2025-05-27 20:35:48,158:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:48,158:INFO:Initializing create_model()
2025-05-27 20:35:48,158:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:48,158:INFO:Checking exceptions
2025-05-27 20:35:48,158:INFO:Importing libraries
2025-05-27 20:35:48,158:INFO:Copying training dataset
2025-05-27 20:35:48,165:INFO:Defining folds
2025-05-27 20:35:48,165:INFO:Declaring metric variables
2025-05-27 20:35:48,165:INFO:Importing untrained model
2025-05-27 20:35:48,166:INFO:Naive Bayes Imported successfully
2025-05-27 20:35:48,166:INFO:Starting cross validation
2025-05-27 20:35:48,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:48,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,503:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,508:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,518:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,519:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,532:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,532:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,549:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,554:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,675:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,683:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:48,687:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:48,701:INFO:Calculating mean and std
2025-05-27 20:35:48,702:INFO:Creating metrics dataframe
2025-05-27 20:35:48,704:INFO:Uploading results into container
2025-05-27 20:35:48,705:INFO:Uploading model into container now
2025-05-27 20:35:48,705:INFO:_master_model_container: 3
2025-05-27 20:35:48,705:INFO:_display_container: 2
2025-05-27 20:35:48,705:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 20:35:48,705:INFO:create_model() successfully completed......................................
2025-05-27 20:35:48,789:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:48,790:INFO:Creating metrics dataframe
2025-05-27 20:35:48,793:INFO:Initializing Decision Tree Classifier
2025-05-27 20:35:48,793:INFO:Total runtime is 0.11001306374867757 minutes
2025-05-27 20:35:48,794:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:48,794:INFO:Initializing create_model()
2025-05-27 20:35:48,794:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:48,794:INFO:Checking exceptions
2025-05-27 20:35:48,794:INFO:Importing libraries
2025-05-27 20:35:48,794:INFO:Copying training dataset
2025-05-27 20:35:48,800:INFO:Defining folds
2025-05-27 20:35:48,800:INFO:Declaring metric variables
2025-05-27 20:35:48,800:INFO:Importing untrained model
2025-05-27 20:35:48,801:INFO:Decision Tree Classifier Imported successfully
2025-05-27 20:35:48,801:INFO:Starting cross validation
2025-05-27 20:35:48,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:49,100:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,110:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,112:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,141:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,157:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,166:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,180:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,186:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,192:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,186:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,354:INFO:Calculating mean and std
2025-05-27 20:35:49,355:INFO:Creating metrics dataframe
2025-05-27 20:35:49,357:INFO:Uploading results into container
2025-05-27 20:35:49,357:INFO:Uploading model into container now
2025-05-27 20:35:49,358:INFO:_master_model_container: 4
2025-05-27 20:35:49,358:INFO:_display_container: 2
2025-05-27 20:35:49,358:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-27 20:35:49,358:INFO:create_model() successfully completed......................................
2025-05-27 20:35:49,445:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:49,445:INFO:Creating metrics dataframe
2025-05-27 20:35:49,449:INFO:Initializing SVM - Linear Kernel
2025-05-27 20:35:49,449:INFO:Total runtime is 0.12094324032465617 minutes
2025-05-27 20:35:49,449:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:49,450:INFO:Initializing create_model()
2025-05-27 20:35:49,450:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:49,450:INFO:Checking exceptions
2025-05-27 20:35:49,450:INFO:Importing libraries
2025-05-27 20:35:49,450:INFO:Copying training dataset
2025-05-27 20:35:49,457:INFO:Defining folds
2025-05-27 20:35:49,457:INFO:Declaring metric variables
2025-05-27 20:35:49,457:INFO:Importing untrained model
2025-05-27 20:35:49,457:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 20:35:49,458:INFO:Starting cross validation
2025-05-27 20:35:49,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:49,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,814:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,824:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,825:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,838:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,838:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,851:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,851:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,851:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,861:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,864:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,867:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,868:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,870:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,870:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,876:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,882:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,884:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,902:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:49,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,910:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:49,913:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:49,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,048:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,050:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,071:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,075:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,076:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,078:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,087:INFO:Calculating mean and std
2025-05-27 20:35:50,087:INFO:Creating metrics dataframe
2025-05-27 20:35:50,089:INFO:Uploading results into container
2025-05-27 20:35:50,090:INFO:Uploading model into container now
2025-05-27 20:35:50,090:INFO:_master_model_container: 5
2025-05-27 20:35:50,090:INFO:_display_container: 2
2025-05-27 20:35:50,091:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 20:35:50,091:INFO:create_model() successfully completed......................................
2025-05-27 20:35:50,175:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:50,175:INFO:Creating metrics dataframe
2025-05-27 20:35:50,179:INFO:Initializing Ridge Classifier
2025-05-27 20:35:50,180:INFO:Total runtime is 0.13311687707901002 minutes
2025-05-27 20:35:50,180:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:50,180:INFO:Initializing create_model()
2025-05-27 20:35:50,180:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:50,180:INFO:Checking exceptions
2025-05-27 20:35:50,180:INFO:Importing libraries
2025-05-27 20:35:50,180:INFO:Copying training dataset
2025-05-27 20:35:50,188:INFO:Defining folds
2025-05-27 20:35:50,188:INFO:Declaring metric variables
2025-05-27 20:35:50,188:INFO:Importing untrained model
2025-05-27 20:35:50,188:INFO:Ridge Classifier Imported successfully
2025-05-27 20:35:50,189:INFO:Starting cross validation
2025-05-27 20:35:50,191:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:50,470:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,488:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,500:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,503:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,504:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,516:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,517:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,518:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,520:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,523:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,524:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,526:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,665:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,669:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:50,670:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,671:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,676:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:50,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:50,687:INFO:Calculating mean and std
2025-05-27 20:35:50,688:INFO:Creating metrics dataframe
2025-05-27 20:35:50,690:INFO:Uploading results into container
2025-05-27 20:35:50,691:INFO:Uploading model into container now
2025-05-27 20:35:50,691:INFO:_master_model_container: 6
2025-05-27 20:35:50,691:INFO:_display_container: 2
2025-05-27 20:35:50,691:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-27 20:35:50,691:INFO:create_model() successfully completed......................................
2025-05-27 20:35:50,775:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:50,775:INFO:Creating metrics dataframe
2025-05-27 20:35:50,780:INFO:Initializing Random Forest Classifier
2025-05-27 20:35:50,780:INFO:Total runtime is 0.1431250850359599 minutes
2025-05-27 20:35:50,780:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:50,781:INFO:Initializing create_model()
2025-05-27 20:35:50,781:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:50,781:INFO:Checking exceptions
2025-05-27 20:35:50,781:INFO:Importing libraries
2025-05-27 20:35:50,781:INFO:Copying training dataset
2025-05-27 20:35:50,788:INFO:Defining folds
2025-05-27 20:35:50,788:INFO:Declaring metric variables
2025-05-27 20:35:50,788:INFO:Importing untrained model
2025-05-27 20:35:50,789:INFO:Random Forest Classifier Imported successfully
2025-05-27 20:35:50,790:INFO:Starting cross validation
2025-05-27 20:35:50,792:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:51,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,686:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,721:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,724:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:51,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,168:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,173:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,180:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,195:INFO:Calculating mean and std
2025-05-27 20:35:52,197:INFO:Creating metrics dataframe
2025-05-27 20:35:52,202:INFO:Uploading results into container
2025-05-27 20:35:52,204:INFO:Uploading model into container now
2025-05-27 20:35:52,205:INFO:_master_model_container: 7
2025-05-27 20:35:52,205:INFO:_display_container: 2
2025-05-27 20:35:52,207:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-27 20:35:52,207:INFO:create_model() successfully completed......................................
2025-05-27 20:35:52,306:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:52,306:INFO:Creating metrics dataframe
2025-05-27 20:35:52,310:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 20:35:52,311:INFO:Total runtime is 0.16863346894582112 minutes
2025-05-27 20:35:52,311:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:52,311:INFO:Initializing create_model()
2025-05-27 20:35:52,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:52,311:INFO:Checking exceptions
2025-05-27 20:35:52,311:INFO:Importing libraries
2025-05-27 20:35:52,311:INFO:Copying training dataset
2025-05-27 20:35:52,318:INFO:Defining folds
2025-05-27 20:35:52,319:INFO:Declaring metric variables
2025-05-27 20:35:52,319:INFO:Importing untrained model
2025-05-27 20:35:52,319:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 20:35:52,319:INFO:Starting cross validation
2025-05-27 20:35:52,322:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:52,531:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,539:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,543:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,572:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,640:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,643:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,647:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,653:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,666:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,669:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,766:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,772:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:35:52,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,818:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:52,820:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,820:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:52,834:INFO:Calculating mean and std
2025-05-27 20:35:52,835:INFO:Creating metrics dataframe
2025-05-27 20:35:52,837:INFO:Uploading results into container
2025-05-27 20:35:52,837:INFO:Uploading model into container now
2025-05-27 20:35:52,838:INFO:_master_model_container: 8
2025-05-27 20:35:52,838:INFO:_display_container: 2
2025-05-27 20:35:52,838:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 20:35:52,838:INFO:create_model() successfully completed......................................
2025-05-27 20:35:52,921:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:52,921:INFO:Creating metrics dataframe
2025-05-27 20:35:52,926:INFO:Initializing Ada Boost Classifier
2025-05-27 20:35:52,926:INFO:Total runtime is 0.1788889726003011 minutes
2025-05-27 20:35:52,926:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:52,926:INFO:Initializing create_model()
2025-05-27 20:35:52,927:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:52,927:INFO:Checking exceptions
2025-05-27 20:35:52,927:INFO:Importing libraries
2025-05-27 20:35:52,927:INFO:Copying training dataset
2025-05-27 20:35:52,934:INFO:Defining folds
2025-05-27 20:35:52,934:INFO:Declaring metric variables
2025-05-27 20:35:52,934:INFO:Importing untrained model
2025-05-27 20:35:52,934:INFO:Ada Boost Classifier Imported successfully
2025-05-27 20:35:52,935:INFO:Starting cross validation
2025-05-27 20:35:52,937:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:53,129:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,139:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,161:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,164:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,168:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,191:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,504:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,516:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,518:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,526:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,526:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,533:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,540:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,542:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,542:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,548:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,572:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,576:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,580:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,664:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:35:53,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,875:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,877:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:53,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,878:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,882:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,885:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:53,896:INFO:Calculating mean and std
2025-05-27 20:35:53,897:INFO:Creating metrics dataframe
2025-05-27 20:35:53,899:INFO:Uploading results into container
2025-05-27 20:35:53,900:INFO:Uploading model into container now
2025-05-27 20:35:53,900:INFO:_master_model_container: 9
2025-05-27 20:35:53,900:INFO:_display_container: 2
2025-05-27 20:35:53,900:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-27 20:35:53,900:INFO:create_model() successfully completed......................................
2025-05-27 20:35:53,972:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:53,972:INFO:Creating metrics dataframe
2025-05-27 20:35:53,976:INFO:Initializing Gradient Boosting Classifier
2025-05-27 20:35:53,976:INFO:Total runtime is 0.19639666477839152 minutes
2025-05-27 20:35:53,977:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:53,977:INFO:Initializing create_model()
2025-05-27 20:35:53,977:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:53,977:INFO:Checking exceptions
2025-05-27 20:35:53,977:INFO:Importing libraries
2025-05-27 20:35:53,977:INFO:Copying training dataset
2025-05-27 20:35:53,985:INFO:Defining folds
2025-05-27 20:35:53,985:INFO:Declaring metric variables
2025-05-27 20:35:53,985:INFO:Importing untrained model
2025-05-27 20:35:53,986:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 20:35:53,986:INFO:Starting cross validation
2025-05-27 20:35:53,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:56,726:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,737:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,755:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,758:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,765:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,768:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,771:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,771:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,777:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,792:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,795:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,797:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,798:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,800:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,805:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,806:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,831:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,845:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,874:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:56,875:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:56,883:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,620:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:58,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,625:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:58,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,648:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:58,664:INFO:Calculating mean and std
2025-05-27 20:35:58,665:INFO:Creating metrics dataframe
2025-05-27 20:35:58,667:INFO:Uploading results into container
2025-05-27 20:35:58,668:INFO:Uploading model into container now
2025-05-27 20:35:58,668:INFO:_master_model_container: 10
2025-05-27 20:35:58,668:INFO:_display_container: 2
2025-05-27 20:35:58,669:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 20:35:58,669:INFO:create_model() successfully completed......................................
2025-05-27 20:35:58,753:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:58,753:INFO:Creating metrics dataframe
2025-05-27 20:35:58,757:INFO:Initializing Linear Discriminant Analysis
2025-05-27 20:35:58,757:INFO:Total runtime is 0.27607897520065305 minutes
2025-05-27 20:35:58,758:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:58,758:INFO:Initializing create_model()
2025-05-27 20:35:58,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:58,758:INFO:Checking exceptions
2025-05-27 20:35:58,758:INFO:Importing libraries
2025-05-27 20:35:58,758:INFO:Copying training dataset
2025-05-27 20:35:58,765:INFO:Defining folds
2025-05-27 20:35:58,765:INFO:Declaring metric variables
2025-05-27 20:35:58,765:INFO:Importing untrained model
2025-05-27 20:35:58,765:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 20:35:58,766:INFO:Starting cross validation
2025-05-27 20:35:58,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:35:59,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,058:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,064:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,065:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,065:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,067:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,067:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,070:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,071:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,077:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,079:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,080:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,081:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,083:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,084:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,088:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,098:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,100:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,246:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,248:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,250:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:35:59,251:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,252:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,253:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:35:59,255:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,255:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,258:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:35:59,270:INFO:Calculating mean and std
2025-05-27 20:35:59,270:INFO:Creating metrics dataframe
2025-05-27 20:35:59,272:INFO:Uploading results into container
2025-05-27 20:35:59,273:INFO:Uploading model into container now
2025-05-27 20:35:59,273:INFO:_master_model_container: 11
2025-05-27 20:35:59,273:INFO:_display_container: 2
2025-05-27 20:35:59,274:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 20:35:59,274:INFO:create_model() successfully completed......................................
2025-05-27 20:35:59,357:INFO:SubProcess create_model() end ==================================
2025-05-27 20:35:59,358:INFO:Creating metrics dataframe
2025-05-27 20:35:59,362:INFO:Initializing Extra Trees Classifier
2025-05-27 20:35:59,362:INFO:Total runtime is 0.2861628174781799 minutes
2025-05-27 20:35:59,363:INFO:SubProcess create_model() called ==================================
2025-05-27 20:35:59,363:INFO:Initializing create_model()
2025-05-27 20:35:59,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:35:59,363:INFO:Checking exceptions
2025-05-27 20:35:59,363:INFO:Importing libraries
2025-05-27 20:35:59,363:INFO:Copying training dataset
2025-05-27 20:35:59,370:INFO:Defining folds
2025-05-27 20:35:59,370:INFO:Declaring metric variables
2025-05-27 20:35:59,370:INFO:Importing untrained model
2025-05-27 20:35:59,371:INFO:Extra Trees Classifier Imported successfully
2025-05-27 20:35:59,371:INFO:Starting cross validation
2025-05-27 20:35:59,374:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:36:00,193:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,195:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,202:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,208:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,210:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,211:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,212:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,217:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,218:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,221:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,224:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,225:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,227:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,227:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,233:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,234:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,239:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,240:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,242:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,247:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,257:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,263:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,675:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,677:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:36:00,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:36:00,694:INFO:Calculating mean and std
2025-05-27 20:36:00,694:INFO:Creating metrics dataframe
2025-05-27 20:36:00,696:INFO:Uploading results into container
2025-05-27 20:36:00,697:INFO:Uploading model into container now
2025-05-27 20:36:00,697:INFO:_master_model_container: 12
2025-05-27 20:36:00,697:INFO:_display_container: 2
2025-05-27 20:36:00,698:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-27 20:36:00,698:INFO:create_model() successfully completed......................................
2025-05-27 20:36:00,783:INFO:SubProcess create_model() end ==================================
2025-05-27 20:36:00,783:INFO:Creating metrics dataframe
2025-05-27 20:36:00,787:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 20:36:00,787:INFO:Total runtime is 0.3099124987920125 minutes
2025-05-27 20:36:00,788:INFO:SubProcess create_model() called ==================================
2025-05-27 20:36:00,788:INFO:Initializing create_model()
2025-05-27 20:36:00,788:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fcf46bb2c50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fcf1f909b70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:36:00,788:INFO:Checking exceptions
2025-05-27 20:36:00,788:INFO:Importing libraries
2025-05-27 20:36:00,788:INFO:Copying training dataset
2025-05-27 20:36:00,795:INFO:Defining folds
2025-05-27 20:36:00,795:INFO:Declaring metric variables
2025-05-27 20:36:00,795:INFO:Importing untrained model
2025-05-27 20:36:00,796:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 20:36:00,796:INFO:Starting cross validation
2025-05-27 20:36:00,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:11,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:38:11,601:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:38:11,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:38:11,602:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:38:12,201:INFO:PyCaret ClassificationExperiment
2025-05-27 20:38:12,201:INFO:Logging name: clf-default-name
2025-05-27 20:38:12,201:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 20:38:12,201:INFO:version 3.3.2
2025-05-27 20:38:12,201:INFO:Initializing setup()
2025-05-27 20:38:12,201:INFO:self.USI: 1cdc
2025-05-27 20:38:12,201:INFO:self._variable_keys: {'y_train', 'y', 'USI', 'exp_name_log', 'seed', 'fold_groups_param', 'logging_param', 'n_jobs_param', 'memory', 'log_plots_param', 'y_test', 'fold_shuffle_param', 'pipeline', 'fold_generator', 'target_param', 'data', 'fix_imbalance', 'exp_id', 'gpu_param', 'X', 'idx', 'X_test', 'X_train', '_available_plots', 'is_multiclass', 'html_param', '_ml_usecase', 'gpu_n_jobs_param'}
2025-05-27 20:38:12,201:INFO:Checking environment
2025-05-27 20:38:12,201:INFO:python_version: 3.10.17
2025-05-27 20:38:12,201:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 20:38:12,201:INFO:machine: x86_64
2025-05-27 20:38:12,203:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:38:12,203:INFO:Memory: svmem(total=16407515136, available=8801935360, percent=46.4, used=6292541440, free=1684385792, active=2515902464, inactive=10582368256, buffers=313286656, cached=8117301248, shared=963395584, slab=779239424)
2025-05-27 20:38:12,204:INFO:Physical Core: 4
2025-05-27 20:38:12,204:INFO:Logical Core: 8
2025-05-27 20:38:12,204:INFO:Checking libraries
2025-05-27 20:38:12,204:INFO:System:
2025-05-27 20:38:12,204:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 20:38:12,204:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 20:38:12,204:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:38:12,204:INFO:PyCaret required dependencies:
2025-05-27 20:38:12,225:INFO:                 pip: 25.1.1
2025-05-27 20:38:12,225:INFO:          setuptools: 65.5.0
2025-05-27 20:38:12,225:INFO:             pycaret: 3.3.2
2025-05-27 20:38:12,225:INFO:             IPython: 8.36.0
2025-05-27 20:38:12,225:INFO:          ipywidgets: 8.1.7
2025-05-27 20:38:12,225:INFO:                tqdm: 4.67.1
2025-05-27 20:38:12,225:INFO:               numpy: 1.26.4
2025-05-27 20:38:12,225:INFO:              pandas: 2.1.4
2025-05-27 20:38:12,225:INFO:              jinja2: 3.1.6
2025-05-27 20:38:12,225:INFO:               scipy: 1.11.4
2025-05-27 20:38:12,225:INFO:              joblib: 1.3.2
2025-05-27 20:38:12,225:INFO:             sklearn: 1.4.2
2025-05-27 20:38:12,225:INFO:                pyod: 2.0.5
2025-05-27 20:38:12,225:INFO:            imblearn: 0.13.0
2025-05-27 20:38:12,225:INFO:   category_encoders: 2.6.2
2025-05-27 20:38:12,225:INFO:            lightgbm: 4.6.0
2025-05-27 20:38:12,225:INFO:               numba: 0.61.2
2025-05-27 20:38:12,225:INFO:            requests: 2.32.3
2025-05-27 20:38:12,226:INFO:          matplotlib: 3.7.5
2025-05-27 20:38:12,226:INFO:          scikitplot: 0.3.7
2025-05-27 20:38:12,226:INFO:         yellowbrick: 1.5
2025-05-27 20:38:12,226:INFO:              plotly: 5.24.1
2025-05-27 20:38:12,226:INFO:    plotly-resampler: Not installed
2025-05-27 20:38:12,226:INFO:             kaleido: 0.2.1
2025-05-27 20:38:12,226:INFO:           schemdraw: 0.15
2025-05-27 20:38:12,226:INFO:         statsmodels: 0.14.4
2025-05-27 20:38:12,226:INFO:              sktime: 0.26.0
2025-05-27 20:38:12,226:INFO:               tbats: 1.1.3
2025-05-27 20:38:12,226:INFO:            pmdarima: 2.0.4
2025-05-27 20:38:12,226:INFO:              psutil: 7.0.0
2025-05-27 20:38:12,226:INFO:          markupsafe: 3.0.2
2025-05-27 20:38:12,226:INFO:             pickle5: Not installed
2025-05-27 20:38:12,226:INFO:         cloudpickle: 3.1.1
2025-05-27 20:38:12,226:INFO:         deprecation: 2.1.0
2025-05-27 20:38:12,226:INFO:              xxhash: 3.5.0
2025-05-27 20:38:12,226:INFO:           wurlitzer: 3.1.1
2025-05-27 20:38:12,226:INFO:PyCaret optional dependencies:
2025-05-27 20:38:12,610:INFO:                shap: Not installed
2025-05-27 20:38:12,610:INFO:           interpret: Not installed
2025-05-27 20:38:12,610:INFO:                umap: Not installed
2025-05-27 20:38:12,610:INFO:     ydata_profiling: Not installed
2025-05-27 20:38:12,610:INFO:  explainerdashboard: Not installed
2025-05-27 20:38:12,610:INFO:             autoviz: Not installed
2025-05-27 20:38:12,610:INFO:           fairlearn: Not installed
2025-05-27 20:38:12,610:INFO:          deepchecks: Not installed
2025-05-27 20:38:12,610:INFO:             xgboost: Not installed
2025-05-27 20:38:12,610:INFO:            catboost: Not installed
2025-05-27 20:38:12,610:INFO:              kmodes: Not installed
2025-05-27 20:38:12,610:INFO:             mlxtend: Not installed
2025-05-27 20:38:12,610:INFO:       statsforecast: Not installed
2025-05-27 20:38:12,610:INFO:        tune_sklearn: Not installed
2025-05-27 20:38:12,611:INFO:                 ray: Not installed
2025-05-27 20:38:12,611:INFO:            hyperopt: Not installed
2025-05-27 20:38:12,611:INFO:              optuna: Not installed
2025-05-27 20:38:12,611:INFO:               skopt: Not installed
2025-05-27 20:38:12,611:INFO:              mlflow: Not installed
2025-05-27 20:38:12,611:INFO:              gradio: Not installed
2025-05-27 20:38:12,611:INFO:             fastapi: 0.115.12
2025-05-27 20:38:12,611:INFO:             uvicorn: 0.34.2
2025-05-27 20:38:12,611:INFO:              m2cgen: Not installed
2025-05-27 20:38:12,611:INFO:           evidently: Not installed
2025-05-27 20:38:12,611:INFO:               fugue: Not installed
2025-05-27 20:38:12,611:INFO:           streamlit: Not installed
2025-05-27 20:38:12,611:INFO:             prophet: Not installed
2025-05-27 20:38:12,611:INFO:None
2025-05-27 20:38:12,611:INFO:Set up data.
2025-05-27 20:38:12,623:INFO:Set up folding strategy.
2025-05-27 20:38:12,623:INFO:Set up train/test split.
2025-05-27 20:38:12,632:INFO:Set up index.
2025-05-27 20:38:12,632:INFO:Assigning column types.
2025-05-27 20:38:12,636:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 20:38:12,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,686:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,719:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,719:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,766:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,767:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,796:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,796:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 20:38:12,844:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,922:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:38:12,951:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,951:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:12,951:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 20:38:13,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,105:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,107:INFO:Preparing preprocessing pipeline...
2025-05-27 20:38:13,108:INFO:Set up label encoding.
2025-05-27 20:38:13,109:INFO:Set up simple imputation.
2025-05-27 20:38:13,114:INFO:Set up encoding of ordinal features.
2025-05-27 20:38:13,122:INFO:Set up encoding of categorical features.
2025-05-27 20:38:13,274:INFO:Finished creating preprocessing pipeline.
2025-05-27 20:38:13,333:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 20:38:13,333:INFO:Creating final display dataframe.
2025-05-27 20:38:13,718:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           123
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                          mean
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                            10
19                     CPU Jobs                            -1
20                      Use GPU                         False
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          1cdc
2025-05-27 20:38:13,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:38:13,882:INFO:setup() successfully completed in 1.68s...............
2025-05-27 20:38:13,882:INFO:Initializing compare_models()
2025-05-27 20:38:13,882:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 20:38:13,882:INFO:Checking exceptions
2025-05-27 20:38:13,888:INFO:Preparing display monitor
2025-05-27 20:38:13,891:INFO:Initializing Logistic Regression
2025-05-27 20:38:13,891:INFO:Total runtime is 1.6768773396809896e-06 minutes
2025-05-27 20:38:13,891:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:13,892:INFO:Initializing create_model()
2025-05-27 20:38:13,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:13,892:INFO:Checking exceptions
2025-05-27 20:38:13,892:INFO:Importing libraries
2025-05-27 20:38:13,892:INFO:Copying training dataset
2025-05-27 20:38:13,897:INFO:Defining folds
2025-05-27 20:38:13,897:INFO:Declaring metric variables
2025-05-27 20:38:13,897:INFO:Importing untrained model
2025-05-27 20:38:13,898:INFO:Logistic Regression Imported successfully
2025-05-27 20:38:13,898:INFO:Starting cross validation
2025-05-27 20:38:13,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:17,850:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,880:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,898:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,913:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:17,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,946:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:17,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:17,962:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,969:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,978:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:17,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,990:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:17,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:17,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,002:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:18,010:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,019:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,034:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,039:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,048:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,051:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:18,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,059:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,077:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,108:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,166:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,181:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,189:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,728:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:18,735:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:38:18,773:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:18,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,785:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:18,797:INFO:Calculating mean and std
2025-05-27 20:38:18,798:INFO:Creating metrics dataframe
2025-05-27 20:38:18,801:INFO:Uploading results into container
2025-05-27 20:38:18,802:INFO:Uploading model into container now
2025-05-27 20:38:18,802:INFO:_master_model_container: 1
2025-05-27 20:38:18,802:INFO:_display_container: 2
2025-05-27 20:38:18,803:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 20:38:18,803:INFO:create_model() successfully completed......................................
2025-05-27 20:38:18,916:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:18,916:INFO:Creating metrics dataframe
2025-05-27 20:38:18,920:INFO:Initializing K Neighbors Classifier
2025-05-27 20:38:18,920:INFO:Total runtime is 0.08381747404734294 minutes
2025-05-27 20:38:18,920:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:18,921:INFO:Initializing create_model()
2025-05-27 20:38:18,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:18,921:INFO:Checking exceptions
2025-05-27 20:38:18,921:INFO:Importing libraries
2025-05-27 20:38:18,921:INFO:Copying training dataset
2025-05-27 20:38:18,927:INFO:Defining folds
2025-05-27 20:38:18,927:INFO:Declaring metric variables
2025-05-27 20:38:18,927:INFO:Importing untrained model
2025-05-27 20:38:18,928:INFO:K Neighbors Classifier Imported successfully
2025-05-27 20:38:18,928:INFO:Starting cross validation
2025-05-27 20:38:18,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:19,298:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,304:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,306:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,307:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,311:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,312:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,317:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,319:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,324:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,509:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,517:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,518:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,530:INFO:Calculating mean and std
2025-05-27 20:38:19,531:INFO:Creating metrics dataframe
2025-05-27 20:38:19,533:INFO:Uploading results into container
2025-05-27 20:38:19,533:INFO:Uploading model into container now
2025-05-27 20:38:19,533:INFO:_master_model_container: 2
2025-05-27 20:38:19,533:INFO:_display_container: 2
2025-05-27 20:38:19,534:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 20:38:19,534:INFO:create_model() successfully completed......................................
2025-05-27 20:38:19,613:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:19,613:INFO:Creating metrics dataframe
2025-05-27 20:38:19,617:INFO:Initializing Naive Bayes
2025-05-27 20:38:19,617:INFO:Total runtime is 0.09543741544087728 minutes
2025-05-27 20:38:19,617:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:19,618:INFO:Initializing create_model()
2025-05-27 20:38:19,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:19,618:INFO:Checking exceptions
2025-05-27 20:38:19,618:INFO:Importing libraries
2025-05-27 20:38:19,618:INFO:Copying training dataset
2025-05-27 20:38:19,625:INFO:Defining folds
2025-05-27 20:38:19,625:INFO:Declaring metric variables
2025-05-27 20:38:19,625:INFO:Importing untrained model
2025-05-27 20:38:19,625:INFO:Naive Bayes Imported successfully
2025-05-27 20:38:19,625:INFO:Starting cross validation
2025-05-27 20:38:19,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:19,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,931:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,934:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,937:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,938:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,938:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,947:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,947:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,950:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,951:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,953:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:19,963:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:19,965:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:20,129:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:20,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,146:INFO:Calculating mean and std
2025-05-27 20:38:20,147:INFO:Creating metrics dataframe
2025-05-27 20:38:20,149:INFO:Uploading results into container
2025-05-27 20:38:20,149:INFO:Uploading model into container now
2025-05-27 20:38:20,150:INFO:_master_model_container: 3
2025-05-27 20:38:20,150:INFO:_display_container: 2
2025-05-27 20:38:20,150:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 20:38:20,150:INFO:create_model() successfully completed......................................
2025-05-27 20:38:20,234:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:20,234:INFO:Creating metrics dataframe
2025-05-27 20:38:20,238:INFO:Initializing Decision Tree Classifier
2025-05-27 20:38:20,239:INFO:Total runtime is 0.1057931661605835 minutes
2025-05-27 20:38:20,239:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:20,239:INFO:Initializing create_model()
2025-05-27 20:38:20,239:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:20,239:INFO:Checking exceptions
2025-05-27 20:38:20,240:INFO:Importing libraries
2025-05-27 20:38:20,240:INFO:Copying training dataset
2025-05-27 20:38:20,246:INFO:Defining folds
2025-05-27 20:38:20,246:INFO:Declaring metric variables
2025-05-27 20:38:20,246:INFO:Importing untrained model
2025-05-27 20:38:20,247:INFO:Decision Tree Classifier Imported successfully
2025-05-27 20:38:20,247:INFO:Starting cross validation
2025-05-27 20:38:20,250:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:20,549:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,550:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,562:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,562:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,563:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,574:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,574:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,576:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,580:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,582:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,583:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,590:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,602:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,747:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,752:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,755:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,759:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:20,772:INFO:Calculating mean and std
2025-05-27 20:38:20,773:INFO:Creating metrics dataframe
2025-05-27 20:38:20,775:INFO:Uploading results into container
2025-05-27 20:38:20,775:INFO:Uploading model into container now
2025-05-27 20:38:20,776:INFO:_master_model_container: 4
2025-05-27 20:38:20,776:INFO:_display_container: 2
2025-05-27 20:38:20,776:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-27 20:38:20,776:INFO:create_model() successfully completed......................................
2025-05-27 20:38:20,861:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:20,861:INFO:Creating metrics dataframe
2025-05-27 20:38:20,865:INFO:Initializing SVM - Linear Kernel
2025-05-27 20:38:20,866:INFO:Total runtime is 0.11624339818954468 minutes
2025-05-27 20:38:20,866:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:20,866:INFO:Initializing create_model()
2025-05-27 20:38:20,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:20,866:INFO:Checking exceptions
2025-05-27 20:38:20,866:INFO:Importing libraries
2025-05-27 20:38:20,867:INFO:Copying training dataset
2025-05-27 20:38:20,873:INFO:Defining folds
2025-05-27 20:38:20,874:INFO:Declaring metric variables
2025-05-27 20:38:20,874:INFO:Importing untrained model
2025-05-27 20:38:20,874:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 20:38:20,875:INFO:Starting cross validation
2025-05-27 20:38:20,877:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:21,225:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,228:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,235:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,238:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,241:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,258:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,261:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,291:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,291:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,295:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,295:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,307:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,314:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,316:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,324:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,332:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,344:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,483:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,488:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,512:INFO:Calculating mean and std
2025-05-27 20:38:21,513:INFO:Creating metrics dataframe
2025-05-27 20:38:21,515:INFO:Uploading results into container
2025-05-27 20:38:21,515:INFO:Uploading model into container now
2025-05-27 20:38:21,516:INFO:_master_model_container: 5
2025-05-27 20:38:21,516:INFO:_display_container: 2
2025-05-27 20:38:21,516:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 20:38:21,516:INFO:create_model() successfully completed......................................
2025-05-27 20:38:21,601:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:21,601:INFO:Creating metrics dataframe
2025-05-27 20:38:21,605:INFO:Initializing Ridge Classifier
2025-05-27 20:38:21,605:INFO:Total runtime is 0.12857340574264528 minutes
2025-05-27 20:38:21,606:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:21,606:INFO:Initializing create_model()
2025-05-27 20:38:21,606:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:21,606:INFO:Checking exceptions
2025-05-27 20:38:21,606:INFO:Importing libraries
2025-05-27 20:38:21,606:INFO:Copying training dataset
2025-05-27 20:38:21,613:INFO:Defining folds
2025-05-27 20:38:21,613:INFO:Declaring metric variables
2025-05-27 20:38:21,613:INFO:Importing untrained model
2025-05-27 20:38:21,614:INFO:Ridge Classifier Imported successfully
2025-05-27 20:38:21,614:INFO:Starting cross validation
2025-05-27 20:38:21,616:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:21,902:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,914:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,917:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,926:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,927:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,930:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,931:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,934:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,935:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,937:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,938:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:21,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:21,957:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:21,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,097:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:22,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:22,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:22,106:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:22,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:22,121:INFO:Calculating mean and std
2025-05-27 20:38:22,122:INFO:Creating metrics dataframe
2025-05-27 20:38:22,124:INFO:Uploading results into container
2025-05-27 20:38:22,124:INFO:Uploading model into container now
2025-05-27 20:38:22,125:INFO:_master_model_container: 6
2025-05-27 20:38:22,125:INFO:_display_container: 2
2025-05-27 20:38:22,125:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-27 20:38:22,125:INFO:create_model() successfully completed......................................
2025-05-27 20:38:22,209:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:22,209:INFO:Creating metrics dataframe
2025-05-27 20:38:22,214:INFO:Initializing Random Forest Classifier
2025-05-27 20:38:22,214:INFO:Total runtime is 0.13871510028839112 minutes
2025-05-27 20:38:22,214:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:22,214:INFO:Initializing create_model()
2025-05-27 20:38:22,215:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:22,215:INFO:Checking exceptions
2025-05-27 20:38:22,215:INFO:Importing libraries
2025-05-27 20:38:22,215:INFO:Copying training dataset
2025-05-27 20:38:22,221:INFO:Defining folds
2025-05-27 20:38:22,222:INFO:Declaring metric variables
2025-05-27 20:38:22,222:INFO:Importing untrained model
2025-05-27 20:38:22,222:INFO:Random Forest Classifier Imported successfully
2025-05-27 20:38:22,223:INFO:Starting cross validation
2025-05-27 20:38:22,225:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:23,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,060:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,067:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,098:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,108:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,110:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,122:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,132:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,137:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,137:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,138:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,166:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,641:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:23,663:INFO:Calculating mean and std
2025-05-27 20:38:23,665:INFO:Creating metrics dataframe
2025-05-27 20:38:23,671:INFO:Uploading results into container
2025-05-27 20:38:23,672:INFO:Uploading model into container now
2025-05-27 20:38:23,673:INFO:_master_model_container: 7
2025-05-27 20:38:23,673:INFO:_display_container: 2
2025-05-27 20:38:23,675:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-27 20:38:23,675:INFO:create_model() successfully completed......................................
2025-05-27 20:38:23,771:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:23,771:INFO:Creating metrics dataframe
2025-05-27 20:38:23,775:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 20:38:23,776:INFO:Total runtime is 0.16474351485570274 minutes
2025-05-27 20:38:23,776:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:23,776:INFO:Initializing create_model()
2025-05-27 20:38:23,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:23,776:INFO:Checking exceptions
2025-05-27 20:38:23,776:INFO:Importing libraries
2025-05-27 20:38:23,777:INFO:Copying training dataset
2025-05-27 20:38:23,783:INFO:Defining folds
2025-05-27 20:38:23,783:INFO:Declaring metric variables
2025-05-27 20:38:23,784:INFO:Importing untrained model
2025-05-27 20:38:23,784:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 20:38:23,785:INFO:Starting cross validation
2025-05-27 20:38:23,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:24,000:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,008:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,018:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,020:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,029:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,034:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,042:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,084:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,088:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,093:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,094:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,100:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,101:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,112:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,118:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,136:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,224:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,225:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:38:24,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,294:INFO:Calculating mean and std
2025-05-27 20:38:24,294:INFO:Creating metrics dataframe
2025-05-27 20:38:24,296:INFO:Uploading results into container
2025-05-27 20:38:24,297:INFO:Uploading model into container now
2025-05-27 20:38:24,297:INFO:_master_model_container: 8
2025-05-27 20:38:24,297:INFO:_display_container: 2
2025-05-27 20:38:24,298:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 20:38:24,298:INFO:create_model() successfully completed......................................
2025-05-27 20:38:24,378:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:24,378:INFO:Creating metrics dataframe
2025-05-27 20:38:24,382:INFO:Initializing Ada Boost Classifier
2025-05-27 20:38:24,382:INFO:Total runtime is 0.17485669453938804 minutes
2025-05-27 20:38:24,383:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:24,383:INFO:Initializing create_model()
2025-05-27 20:38:24,383:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:24,383:INFO:Checking exceptions
2025-05-27 20:38:24,383:INFO:Importing libraries
2025-05-27 20:38:24,383:INFO:Copying training dataset
2025-05-27 20:38:24,390:INFO:Defining folds
2025-05-27 20:38:24,390:INFO:Declaring metric variables
2025-05-27 20:38:24,390:INFO:Importing untrained model
2025-05-27 20:38:24,391:INFO:Ada Boost Classifier Imported successfully
2025-05-27 20:38:24,391:INFO:Starting cross validation
2025-05-27 20:38:24,393:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:24,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,608:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:24,927:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,930:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,932:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,938:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,947:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,950:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,953:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,957:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,963:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,964:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,967:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,967:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,969:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:24,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,979:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,985:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:24,991:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,070:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:25,079:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:38:25,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:25,269:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:25,279:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:25,297:INFO:Calculating mean and std
2025-05-27 20:38:25,298:INFO:Creating metrics dataframe
2025-05-27 20:38:25,299:INFO:Uploading results into container
2025-05-27 20:38:25,300:INFO:Uploading model into container now
2025-05-27 20:38:25,300:INFO:_master_model_container: 9
2025-05-27 20:38:25,300:INFO:_display_container: 2
2025-05-27 20:38:25,301:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-27 20:38:25,301:INFO:create_model() successfully completed......................................
2025-05-27 20:38:25,380:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:25,380:INFO:Creating metrics dataframe
2025-05-27 20:38:25,384:INFO:Initializing Gradient Boosting Classifier
2025-05-27 20:38:25,384:INFO:Total runtime is 0.19155588944753013 minutes
2025-05-27 20:38:25,385:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:25,385:INFO:Initializing create_model()
2025-05-27 20:38:25,385:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:25,385:INFO:Checking exceptions
2025-05-27 20:38:25,385:INFO:Importing libraries
2025-05-27 20:38:25,385:INFO:Copying training dataset
2025-05-27 20:38:25,391:INFO:Defining folds
2025-05-27 20:38:25,391:INFO:Declaring metric variables
2025-05-27 20:38:25,392:INFO:Importing untrained model
2025-05-27 20:38:25,392:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 20:38:25,392:INFO:Starting cross validation
2025-05-27 20:38:25,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:28,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,094:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,101:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,118:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,135:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,137:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,138:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,140:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,144:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,144:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,145:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,149:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,150:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,154:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,160:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,167:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,170:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,173:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:28,175:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,176:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,178:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,182:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:28,182:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,021:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,023:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,027:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,032:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,044:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,050:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,064:INFO:Calculating mean and std
2025-05-27 20:38:30,065:INFO:Creating metrics dataframe
2025-05-27 20:38:30,067:INFO:Uploading results into container
2025-05-27 20:38:30,067:INFO:Uploading model into container now
2025-05-27 20:38:30,068:INFO:_master_model_container: 10
2025-05-27 20:38:30,068:INFO:_display_container: 2
2025-05-27 20:38:30,068:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 20:38:30,068:INFO:create_model() successfully completed......................................
2025-05-27 20:38:30,149:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:30,149:INFO:Creating metrics dataframe
2025-05-27 20:38:30,153:INFO:Initializing Linear Discriminant Analysis
2025-05-27 20:38:30,154:INFO:Total runtime is 0.2710420489311218 minutes
2025-05-27 20:38:30,154:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:30,154:INFO:Initializing create_model()
2025-05-27 20:38:30,154:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:30,154:INFO:Checking exceptions
2025-05-27 20:38:30,154:INFO:Importing libraries
2025-05-27 20:38:30,154:INFO:Copying training dataset
2025-05-27 20:38:30,161:INFO:Defining folds
2025-05-27 20:38:30,161:INFO:Declaring metric variables
2025-05-27 20:38:30,161:INFO:Importing untrained model
2025-05-27 20:38:30,161:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 20:38:30,162:INFO:Starting cross validation
2025-05-27 20:38:30,164:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:30,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,453:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,460:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,464:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,467:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,467:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,481:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,487:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,501:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,508:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,523:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,529:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,533:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,651:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:38:30,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,661:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:30,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:30,679:INFO:Calculating mean and std
2025-05-27 20:38:30,679:INFO:Creating metrics dataframe
2025-05-27 20:38:30,681:INFO:Uploading results into container
2025-05-27 20:38:30,682:INFO:Uploading model into container now
2025-05-27 20:38:30,682:INFO:_master_model_container: 11
2025-05-27 20:38:30,682:INFO:_display_container: 2
2025-05-27 20:38:30,682:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 20:38:30,682:INFO:create_model() successfully completed......................................
2025-05-27 20:38:30,767:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:30,767:INFO:Creating metrics dataframe
2025-05-27 20:38:30,771:INFO:Initializing Extra Trees Classifier
2025-05-27 20:38:30,771:INFO:Total runtime is 0.2813367247581482 minutes
2025-05-27 20:38:30,771:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:30,772:INFO:Initializing create_model()
2025-05-27 20:38:30,772:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:30,772:INFO:Checking exceptions
2025-05-27 20:38:30,772:INFO:Importing libraries
2025-05-27 20:38:30,772:INFO:Copying training dataset
2025-05-27 20:38:30,779:INFO:Defining folds
2025-05-27 20:38:30,779:INFO:Declaring metric variables
2025-05-27 20:38:30,779:INFO:Importing untrained model
2025-05-27 20:38:30,779:INFO:Extra Trees Classifier Imported successfully
2025-05-27 20:38:30,780:INFO:Starting cross validation
2025-05-27 20:38:30,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:38:31,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,616:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,617:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,621:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,633:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,648:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,655:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,661:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,689:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,692:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:31,696:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,137:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,141:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:38:32,144:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:38:32,160:INFO:Calculating mean and std
2025-05-27 20:38:32,162:INFO:Creating metrics dataframe
2025-05-27 20:38:32,169:INFO:Uploading results into container
2025-05-27 20:38:32,171:INFO:Uploading model into container now
2025-05-27 20:38:32,172:INFO:_master_model_container: 12
2025-05-27 20:38:32,172:INFO:_display_container: 2
2025-05-27 20:38:32,173:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-27 20:38:32,174:INFO:create_model() successfully completed......................................
2025-05-27 20:38:32,313:INFO:SubProcess create_model() end ==================================
2025-05-27 20:38:32,313:INFO:Creating metrics dataframe
2025-05-27 20:38:32,318:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 20:38:32,318:INFO:Total runtime is 0.3071220636367798 minutes
2025-05-27 20:38:32,319:INFO:SubProcess create_model() called ==================================
2025-05-27 20:38:32,319:INFO:Initializing create_model()
2025-05-27 20:38:32,319:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f396e05ac50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f394ad6db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:38:32,319:INFO:Checking exceptions
2025-05-27 20:38:32,319:INFO:Importing libraries
2025-05-27 20:38:32,319:INFO:Copying training dataset
2025-05-27 20:38:32,328:INFO:Defining folds
2025-05-27 20:38:32,328:INFO:Declaring metric variables
2025-05-27 20:38:32,329:INFO:Importing untrained model
2025-05-27 20:38:32,330:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 20:38:32,331:INFO:Starting cross validation
2025-05-27 20:38:32,335:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:32,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:44:32,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:44:32,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:44:32,983:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 20:44:33,574:INFO:PyCaret ClassificationExperiment
2025-05-27 20:44:33,574:INFO:Logging name: clf-default-name
2025-05-27 20:44:33,575:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 20:44:33,575:INFO:version 3.3.2
2025-05-27 20:44:33,575:INFO:Initializing setup()
2025-05-27 20:44:33,575:INFO:self.USI: 90ee
2025-05-27 20:44:33,575:INFO:self._variable_keys: {'y_test', 'fold_generator', 'pipeline', 'exp_name_log', '_ml_usecase', 'X_train', 'memory', 'logging_param', 'seed', 'X_test', 'fix_imbalance', '_available_plots', 'n_jobs_param', 'html_param', 'fold_shuffle_param', 'idx', 'y_train', 'data', 'gpu_n_jobs_param', 'X', 'fold_groups_param', 'is_multiclass', 'log_plots_param', 'exp_id', 'gpu_param', 'target_param', 'USI', 'y'}
2025-05-27 20:44:33,575:INFO:Checking environment
2025-05-27 20:44:33,575:INFO:python_version: 3.10.17
2025-05-27 20:44:33,575:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 20:44:33,575:INFO:machine: x86_64
2025-05-27 20:44:33,577:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:44:33,577:INFO:Memory: svmem(total=16407515136, available=8729300992, percent=46.8, used=6367768576, free=1605500928, active=2518249472, inactive=10657255424, buffers=314490880, cached=8119754752, shared=960802816, slab=781234176)
2025-05-27 20:44:33,578:INFO:Physical Core: 4
2025-05-27 20:44:33,578:INFO:Logical Core: 8
2025-05-27 20:44:33,578:INFO:Checking libraries
2025-05-27 20:44:33,578:INFO:System:
2025-05-27 20:44:33,578:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 20:44:33,579:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 20:44:33,579:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 20:44:33,579:INFO:PyCaret required dependencies:
2025-05-27 20:44:33,607:INFO:                 pip: 25.1.1
2025-05-27 20:44:33,607:INFO:          setuptools: 65.5.0
2025-05-27 20:44:33,607:INFO:             pycaret: 3.3.2
2025-05-27 20:44:33,607:INFO:             IPython: 8.36.0
2025-05-27 20:44:33,607:INFO:          ipywidgets: 8.1.7
2025-05-27 20:44:33,607:INFO:                tqdm: 4.67.1
2025-05-27 20:44:33,607:INFO:               numpy: 1.26.4
2025-05-27 20:44:33,607:INFO:              pandas: 2.1.4
2025-05-27 20:44:33,607:INFO:              jinja2: 3.1.6
2025-05-27 20:44:33,607:INFO:               scipy: 1.11.4
2025-05-27 20:44:33,607:INFO:              joblib: 1.3.2
2025-05-27 20:44:33,607:INFO:             sklearn: 1.4.2
2025-05-27 20:44:33,607:INFO:                pyod: 2.0.5
2025-05-27 20:44:33,607:INFO:            imblearn: 0.13.0
2025-05-27 20:44:33,607:INFO:   category_encoders: 2.6.2
2025-05-27 20:44:33,607:INFO:            lightgbm: 4.6.0
2025-05-27 20:44:33,607:INFO:               numba: 0.61.2
2025-05-27 20:44:33,608:INFO:            requests: 2.32.3
2025-05-27 20:44:33,608:INFO:          matplotlib: 3.7.5
2025-05-27 20:44:33,608:INFO:          scikitplot: 0.3.7
2025-05-27 20:44:33,608:INFO:         yellowbrick: 1.5
2025-05-27 20:44:33,608:INFO:              plotly: 5.24.1
2025-05-27 20:44:33,608:INFO:    plotly-resampler: Not installed
2025-05-27 20:44:33,608:INFO:             kaleido: 0.2.1
2025-05-27 20:44:33,608:INFO:           schemdraw: 0.15
2025-05-27 20:44:33,608:INFO:         statsmodels: 0.14.4
2025-05-27 20:44:33,608:INFO:              sktime: 0.26.0
2025-05-27 20:44:33,608:INFO:               tbats: 1.1.3
2025-05-27 20:44:33,608:INFO:            pmdarima: 2.0.4
2025-05-27 20:44:33,608:INFO:              psutil: 7.0.0
2025-05-27 20:44:33,608:INFO:          markupsafe: 3.0.2
2025-05-27 20:44:33,608:INFO:             pickle5: Not installed
2025-05-27 20:44:33,608:INFO:         cloudpickle: 3.1.1
2025-05-27 20:44:33,609:INFO:         deprecation: 2.1.0
2025-05-27 20:44:33,609:INFO:              xxhash: 3.5.0
2025-05-27 20:44:33,609:INFO:           wurlitzer: 3.1.1
2025-05-27 20:44:33,609:INFO:PyCaret optional dependencies:
2025-05-27 20:44:34,000:INFO:                shap: Not installed
2025-05-27 20:44:34,000:INFO:           interpret: Not installed
2025-05-27 20:44:34,000:INFO:                umap: Not installed
2025-05-27 20:44:34,000:INFO:     ydata_profiling: Not installed
2025-05-27 20:44:34,000:INFO:  explainerdashboard: Not installed
2025-05-27 20:44:34,000:INFO:             autoviz: Not installed
2025-05-27 20:44:34,001:INFO:           fairlearn: Not installed
2025-05-27 20:44:34,001:INFO:          deepchecks: Not installed
2025-05-27 20:44:34,001:INFO:             xgboost: Not installed
2025-05-27 20:44:34,001:INFO:            catboost: Not installed
2025-05-27 20:44:34,001:INFO:              kmodes: Not installed
2025-05-27 20:44:34,001:INFO:             mlxtend: Not installed
2025-05-27 20:44:34,001:INFO:       statsforecast: Not installed
2025-05-27 20:44:34,001:INFO:        tune_sklearn: Not installed
2025-05-27 20:44:34,001:INFO:                 ray: Not installed
2025-05-27 20:44:34,001:INFO:            hyperopt: Not installed
2025-05-27 20:44:34,001:INFO:              optuna: Not installed
2025-05-27 20:44:34,001:INFO:               skopt: Not installed
2025-05-27 20:44:34,001:INFO:              mlflow: Not installed
2025-05-27 20:44:34,001:INFO:              gradio: Not installed
2025-05-27 20:44:34,001:INFO:             fastapi: 0.115.12
2025-05-27 20:44:34,001:INFO:             uvicorn: 0.34.2
2025-05-27 20:44:34,002:INFO:              m2cgen: Not installed
2025-05-27 20:44:34,002:INFO:           evidently: Not installed
2025-05-27 20:44:34,002:INFO:               fugue: Not installed
2025-05-27 20:44:34,002:INFO:           streamlit: Not installed
2025-05-27 20:44:34,002:INFO:             prophet: Not installed
2025-05-27 20:44:34,002:INFO:None
2025-05-27 20:44:34,002:INFO:Set up data.
2025-05-27 20:44:34,015:INFO:Set up folding strategy.
2025-05-27 20:44:34,015:INFO:Set up train/test split.
2025-05-27 20:44:34,024:INFO:Set up index.
2025-05-27 20:44:34,024:INFO:Assigning column types.
2025-05-27 20:44:34,028:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 20:44:34,075:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,078:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,111:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,111:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,157:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,158:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,187:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,187:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 20:44:34,236:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,313:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 20:44:34,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,342:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 20:44:34,418:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,419:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:34,497:INFO:Preparing preprocessing pipeline...
2025-05-27 20:44:34,498:INFO:Set up label encoding.
2025-05-27 20:44:34,498:INFO:Set up simple imputation.
2025-05-27 20:44:34,503:INFO:Set up encoding of ordinal features.
2025-05-27 20:44:34,512:INFO:Set up encoding of categorical features.
2025-05-27 20:44:34,662:INFO:Finished creating preprocessing pipeline.
2025-05-27 20:44:34,720:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 20:44:34,720:INFO:Creating final display dataframe.
2025-05-27 20:44:35,106:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           123
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                          mean
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                            10
19                     CPU Jobs                            -1
20                      Use GPU                         False
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          90ee
2025-05-27 20:44:35,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:35,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:35,265:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:35,265:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 20:44:35,267:INFO:setup() successfully completed in 1.69s...............
2025-05-27 20:44:35,267:INFO:Initializing compare_models()
2025-05-27 20:44:35,267:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 20:44:35,267:INFO:Checking exceptions
2025-05-27 20:44:35,272:INFO:Preparing display monitor
2025-05-27 20:44:35,275:INFO:Initializing Logistic Regression
2025-05-27 20:44:35,275:INFO:Total runtime is 1.4901161193847656e-06 minutes
2025-05-27 20:44:35,275:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:35,275:INFO:Initializing create_model()
2025-05-27 20:44:35,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:35,275:INFO:Checking exceptions
2025-05-27 20:44:35,276:INFO:Importing libraries
2025-05-27 20:44:35,276:INFO:Copying training dataset
2025-05-27 20:44:35,282:INFO:Defining folds
2025-05-27 20:44:35,282:INFO:Declaring metric variables
2025-05-27 20:44:35,283:INFO:Importing untrained model
2025-05-27 20:44:35,283:INFO:Logistic Regression Imported successfully
2025-05-27 20:44:35,283:INFO:Starting cross validation
2025-05-27 20:44:35,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:39,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,662:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,669:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,696:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,704:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,704:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,710:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,710:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,768:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,773:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,774:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,786:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,793:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,795:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,799:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,800:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,804:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,819:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,904:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:39,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,971:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:39,979:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,979:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:39,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:40,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 20:44:40,513:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:40,515:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,518:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,522:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,530:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:40,532:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:40,546:INFO:Calculating mean and std
2025-05-27 20:44:40,547:INFO:Creating metrics dataframe
2025-05-27 20:44:40,550:INFO:Uploading results into container
2025-05-27 20:44:40,551:INFO:Uploading model into container now
2025-05-27 20:44:40,551:INFO:_master_model_container: 1
2025-05-27 20:44:40,551:INFO:_display_container: 2
2025-05-27 20:44:40,552:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 20:44:40,552:INFO:create_model() successfully completed......................................
2025-05-27 20:44:40,651:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:40,651:INFO:Creating metrics dataframe
2025-05-27 20:44:40,654:INFO:Initializing K Neighbors Classifier
2025-05-27 20:44:40,654:INFO:Total runtime is 0.08966012398401896 minutes
2025-05-27 20:44:40,655:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:40,655:INFO:Initializing create_model()
2025-05-27 20:44:40,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:40,655:INFO:Checking exceptions
2025-05-27 20:44:40,655:INFO:Importing libraries
2025-05-27 20:44:40,655:INFO:Copying training dataset
2025-05-27 20:44:40,662:INFO:Defining folds
2025-05-27 20:44:40,662:INFO:Declaring metric variables
2025-05-27 20:44:40,662:INFO:Importing untrained model
2025-05-27 20:44:40,662:INFO:K Neighbors Classifier Imported successfully
2025-05-27 20:44:40,662:INFO:Starting cross validation
2025-05-27 20:44:40,665:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:41,042:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,048:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,060:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,062:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,076:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,085:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,093:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,107:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,126:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,136:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,357:INFO:Calculating mean and std
2025-05-27 20:44:41,358:INFO:Creating metrics dataframe
2025-05-27 20:44:41,360:INFO:Uploading results into container
2025-05-27 20:44:41,361:INFO:Uploading model into container now
2025-05-27 20:44:41,361:INFO:_master_model_container: 2
2025-05-27 20:44:41,361:INFO:_display_container: 2
2025-05-27 20:44:41,361:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 20:44:41,361:INFO:create_model() successfully completed......................................
2025-05-27 20:44:41,466:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:41,466:INFO:Creating metrics dataframe
2025-05-27 20:44:41,471:INFO:Initializing Naive Bayes
2025-05-27 20:44:41,472:INFO:Total runtime is 0.10327795346577961 minutes
2025-05-27 20:44:41,472:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:41,472:INFO:Initializing create_model()
2025-05-27 20:44:41,472:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:41,472:INFO:Checking exceptions
2025-05-27 20:44:41,472:INFO:Importing libraries
2025-05-27 20:44:41,472:INFO:Copying training dataset
2025-05-27 20:44:41,480:INFO:Defining folds
2025-05-27 20:44:41,480:INFO:Declaring metric variables
2025-05-27 20:44:41,481:INFO:Importing untrained model
2025-05-27 20:44:41,481:INFO:Naive Bayes Imported successfully
2025-05-27 20:44:41,481:INFO:Starting cross validation
2025-05-27 20:44:41,484:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:41,928:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,934:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,935:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,938:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,946:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,949:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,964:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,967:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,969:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,972:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,978:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,984:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,991:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,991:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:41,992:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:41,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,133:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:42,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,146:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:42,150:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,165:INFO:Calculating mean and std
2025-05-27 20:44:42,166:INFO:Creating metrics dataframe
2025-05-27 20:44:42,168:INFO:Uploading results into container
2025-05-27 20:44:42,168:INFO:Uploading model into container now
2025-05-27 20:44:42,168:INFO:_master_model_container: 3
2025-05-27 20:44:42,168:INFO:_display_container: 2
2025-05-27 20:44:42,169:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 20:44:42,169:INFO:create_model() successfully completed......................................
2025-05-27 20:44:42,243:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:42,243:INFO:Creating metrics dataframe
2025-05-27 20:44:42,247:INFO:Initializing Decision Tree Classifier
2025-05-27 20:44:42,247:INFO:Total runtime is 0.11620672543843587 minutes
2025-05-27 20:44:42,248:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:42,248:INFO:Initializing create_model()
2025-05-27 20:44:42,248:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:42,248:INFO:Checking exceptions
2025-05-27 20:44:42,248:INFO:Importing libraries
2025-05-27 20:44:42,248:INFO:Copying training dataset
2025-05-27 20:44:42,255:INFO:Defining folds
2025-05-27 20:44:42,255:INFO:Declaring metric variables
2025-05-27 20:44:42,255:INFO:Importing untrained model
2025-05-27 20:44:42,255:INFO:Decision Tree Classifier Imported successfully
2025-05-27 20:44:42,256:INFO:Starting cross validation
2025-05-27 20:44:42,258:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:42,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,611:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,616:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,625:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,626:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,639:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,642:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,646:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,652:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,662:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,668:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,673:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,688:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,691:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,695:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,804:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:42,822:INFO:Calculating mean and std
2025-05-27 20:44:42,823:INFO:Creating metrics dataframe
2025-05-27 20:44:42,825:INFO:Uploading results into container
2025-05-27 20:44:42,825:INFO:Uploading model into container now
2025-05-27 20:44:42,825:INFO:_master_model_container: 4
2025-05-27 20:44:42,825:INFO:_display_container: 2
2025-05-27 20:44:42,826:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-05-27 20:44:42,826:INFO:create_model() successfully completed......................................
2025-05-27 20:44:42,897:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:42,897:INFO:Creating metrics dataframe
2025-05-27 20:44:42,901:INFO:Initializing SVM - Linear Kernel
2025-05-27 20:44:42,901:INFO:Total runtime is 0.1271089474360148 minutes
2025-05-27 20:44:42,902:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:42,902:INFO:Initializing create_model()
2025-05-27 20:44:42,902:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:42,902:INFO:Checking exceptions
2025-05-27 20:44:42,902:INFO:Importing libraries
2025-05-27 20:44:42,902:INFO:Copying training dataset
2025-05-27 20:44:42,909:INFO:Defining folds
2025-05-27 20:44:42,909:INFO:Declaring metric variables
2025-05-27 20:44:42,909:INFO:Importing untrained model
2025-05-27 20:44:42,909:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 20:44:42,910:INFO:Starting cross validation
2025-05-27 20:44:42,912:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:43,297:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,306:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,307:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,312:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,318:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,326:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,330:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,333:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,335:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,361:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,363:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,383:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,390:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,414:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,417:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,423:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,426:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,439:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,443:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,536:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,542:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,545:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,562:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,569:INFO:Calculating mean and std
2025-05-27 20:44:43,570:INFO:Creating metrics dataframe
2025-05-27 20:44:43,572:INFO:Uploading results into container
2025-05-27 20:44:43,572:INFO:Uploading model into container now
2025-05-27 20:44:43,573:INFO:_master_model_container: 5
2025-05-27 20:44:43,573:INFO:_display_container: 2
2025-05-27 20:44:43,573:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 20:44:43,573:INFO:create_model() successfully completed......................................
2025-05-27 20:44:43,645:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:43,645:INFO:Creating metrics dataframe
2025-05-27 20:44:43,649:INFO:Initializing Ridge Classifier
2025-05-27 20:44:43,649:INFO:Total runtime is 0.13957528273264566 minutes
2025-05-27 20:44:43,650:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:43,650:INFO:Initializing create_model()
2025-05-27 20:44:43,650:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:43,650:INFO:Checking exceptions
2025-05-27 20:44:43,650:INFO:Importing libraries
2025-05-27 20:44:43,650:INFO:Copying training dataset
2025-05-27 20:44:43,658:INFO:Defining folds
2025-05-27 20:44:43,659:INFO:Declaring metric variables
2025-05-27 20:44:43,659:INFO:Importing untrained model
2025-05-27 20:44:43,659:INFO:Ridge Classifier Imported successfully
2025-05-27 20:44:43,660:INFO:Starting cross validation
2025-05-27 20:44:43,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:43,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,946:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,952:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,953:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,960:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,963:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,964:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,971:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,980:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:43,982:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,986:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,986:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,987:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,991:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:43,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:43,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:44,001:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,004:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,006:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,009:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:44,011:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,011:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,014:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,016:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,023:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,026:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,026:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,029:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,194:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:44,196:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,202:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,206:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:44,211:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,218:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:44,220:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:44,232:INFO:Calculating mean and std
2025-05-27 20:44:44,233:INFO:Creating metrics dataframe
2025-05-27 20:44:44,235:INFO:Uploading results into container
2025-05-27 20:44:44,236:INFO:Uploading model into container now
2025-05-27 20:44:44,236:INFO:_master_model_container: 6
2025-05-27 20:44:44,237:INFO:_display_container: 2
2025-05-27 20:44:44,237:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-05-27 20:44:44,237:INFO:create_model() successfully completed......................................
2025-05-27 20:44:44,347:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:44,348:INFO:Creating metrics dataframe
2025-05-27 20:44:44,355:INFO:Initializing Random Forest Classifier
2025-05-27 20:44:44,355:INFO:Total runtime is 0.15133495330810545 minutes
2025-05-27 20:44:44,355:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:44,356:INFO:Initializing create_model()
2025-05-27 20:44:44,356:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:44,356:INFO:Checking exceptions
2025-05-27 20:44:44,356:INFO:Importing libraries
2025-05-27 20:44:44,356:INFO:Copying training dataset
2025-05-27 20:44:44,366:INFO:Defining folds
2025-05-27 20:44:44,366:INFO:Declaring metric variables
2025-05-27 20:44:44,366:INFO:Importing untrained model
2025-05-27 20:44:44,368:INFO:Random Forest Classifier Imported successfully
2025-05-27 20:44:44,368:INFO:Starting cross validation
2025-05-27 20:44:44,370:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:45,744:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,760:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,766:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,774:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,794:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,795:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,801:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,802:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,824:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,829:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,835:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,846:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,853:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,860:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,895:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,901:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,914:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:45,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,301:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,306:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,311:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,357:INFO:Calculating mean and std
2025-05-27 20:44:46,358:INFO:Creating metrics dataframe
2025-05-27 20:44:46,360:INFO:Uploading results into container
2025-05-27 20:44:46,360:INFO:Uploading model into container now
2025-05-27 20:44:46,360:INFO:_master_model_container: 7
2025-05-27 20:44:46,361:INFO:_display_container: 2
2025-05-27 20:44:46,361:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-05-27 20:44:46,361:INFO:create_model() successfully completed......................................
2025-05-27 20:44:46,433:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:46,433:INFO:Creating metrics dataframe
2025-05-27 20:44:46,437:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 20:44:46,437:INFO:Total runtime is 0.18604039351145424 minutes
2025-05-27 20:44:46,438:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:46,438:INFO:Initializing create_model()
2025-05-27 20:44:46,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:46,438:INFO:Checking exceptions
2025-05-27 20:44:46,438:INFO:Importing libraries
2025-05-27 20:44:46,438:INFO:Copying training dataset
2025-05-27 20:44:46,445:INFO:Defining folds
2025-05-27 20:44:46,445:INFO:Declaring metric variables
2025-05-27 20:44:46,445:INFO:Importing untrained model
2025-05-27 20:44:46,445:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 20:44:46,446:INFO:Starting cross validation
2025-05-27 20:44:46,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:46,722:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,731:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,734:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,761:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,835:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,839:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,846:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,848:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,850:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,852:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,852:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,855:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,856:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,858:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,859:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,860:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,862:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,864:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,865:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,865:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,866:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,867:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,871:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,874:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,874:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,875:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,880:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,886:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:46,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,918:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:46,989:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:46,990:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 20:44:47,034:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,036:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,036:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,038:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,039:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,041:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,043:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,044:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,055:INFO:Calculating mean and std
2025-05-27 20:44:47,056:INFO:Creating metrics dataframe
2025-05-27 20:44:47,057:INFO:Uploading results into container
2025-05-27 20:44:47,058:INFO:Uploading model into container now
2025-05-27 20:44:47,058:INFO:_master_model_container: 8
2025-05-27 20:44:47,058:INFO:_display_container: 2
2025-05-27 20:44:47,058:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 20:44:47,059:INFO:create_model() successfully completed......................................
2025-05-27 20:44:47,131:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:47,131:INFO:Creating metrics dataframe
2025-05-27 20:44:47,137:INFO:Initializing Ada Boost Classifier
2025-05-27 20:44:47,137:INFO:Total runtime is 0.19770806630452473 minutes
2025-05-27 20:44:47,138:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:47,138:INFO:Initializing create_model()
2025-05-27 20:44:47,138:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:47,138:INFO:Checking exceptions
2025-05-27 20:44:47,138:INFO:Importing libraries
2025-05-27 20:44:47,138:INFO:Copying training dataset
2025-05-27 20:44:47,150:INFO:Defining folds
2025-05-27 20:44:47,151:INFO:Declaring metric variables
2025-05-27 20:44:47,151:INFO:Importing untrained model
2025-05-27 20:44:47,151:INFO:Ada Boost Classifier Imported successfully
2025-05-27 20:44:47,151:INFO:Starting cross validation
2025-05-27 20:44:47,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:47,424:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,426:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,458:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,465:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,472:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:47,812:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,816:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,872:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,885:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,887:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,890:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,895:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,895:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,898:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,901:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,906:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,907:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,909:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,917:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:47,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,933:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:47,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,031:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:48,073:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 20:44:48,243:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:48,245:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,249:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,252:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:48,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,279:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,283:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:48,292:INFO:Calculating mean and std
2025-05-27 20:44:48,293:INFO:Creating metrics dataframe
2025-05-27 20:44:48,295:INFO:Uploading results into container
2025-05-27 20:44:48,295:INFO:Uploading model into container now
2025-05-27 20:44:48,296:INFO:_master_model_container: 9
2025-05-27 20:44:48,296:INFO:_display_container: 2
2025-05-27 20:44:48,296:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-05-27 20:44:48,296:INFO:create_model() successfully completed......................................
2025-05-27 20:44:48,366:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:48,367:INFO:Creating metrics dataframe
2025-05-27 20:44:48,371:INFO:Initializing Gradient Boosting Classifier
2025-05-27 20:44:48,371:INFO:Total runtime is 0.21826613744099935 minutes
2025-05-27 20:44:48,371:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:48,371:INFO:Initializing create_model()
2025-05-27 20:44:48,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:48,372:INFO:Checking exceptions
2025-05-27 20:44:48,372:INFO:Importing libraries
2025-05-27 20:44:48,372:INFO:Copying training dataset
2025-05-27 20:44:48,378:INFO:Defining folds
2025-05-27 20:44:48,378:INFO:Declaring metric variables
2025-05-27 20:44:48,378:INFO:Importing untrained model
2025-05-27 20:44:48,379:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 20:44:48,379:INFO:Starting cross validation
2025-05-27 20:44:48,381:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:51,286:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,290:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,296:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,302:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,328:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,331:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,375:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,381:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,433:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,437:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,440:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,442:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,446:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,452:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,496:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,505:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,536:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,538:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,545:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:51,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,600:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:51,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,298:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,303:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,306:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,336:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,340:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,355:INFO:Calculating mean and std
2025-05-27 20:44:53,356:INFO:Creating metrics dataframe
2025-05-27 20:44:53,358:INFO:Uploading results into container
2025-05-27 20:44:53,358:INFO:Uploading model into container now
2025-05-27 20:44:53,359:INFO:_master_model_container: 10
2025-05-27 20:44:53,359:INFO:_display_container: 2
2025-05-27 20:44:53,359:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 20:44:53,359:INFO:create_model() successfully completed......................................
2025-05-27 20:44:53,430:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:53,430:INFO:Creating metrics dataframe
2025-05-27 20:44:53,434:INFO:Initializing Linear Discriminant Analysis
2025-05-27 20:44:53,434:INFO:Total runtime is 0.302657683690389 minutes
2025-05-27 20:44:53,435:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:53,435:INFO:Initializing create_model()
2025-05-27 20:44:53,435:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:53,435:INFO:Checking exceptions
2025-05-27 20:44:53,435:INFO:Importing libraries
2025-05-27 20:44:53,435:INFO:Copying training dataset
2025-05-27 20:44:53,442:INFO:Defining folds
2025-05-27 20:44:53,443:INFO:Declaring metric variables
2025-05-27 20:44:53,443:INFO:Importing untrained model
2025-05-27 20:44:53,443:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 20:44:53,443:INFO:Starting cross validation
2025-05-27 20:44:53,445:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:53,735:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,735:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,738:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,742:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,744:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,747:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,748:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,748:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,749:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,751:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,752:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,752:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,753:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,754:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,755:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,758:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,759:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,761:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,761:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,764:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,764:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,765:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,770:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,770:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,776:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,914:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,917:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 20:44:53,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,923:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,924:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:53,926:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:53,940:INFO:Calculating mean and std
2025-05-27 20:44:53,941:INFO:Creating metrics dataframe
2025-05-27 20:44:53,943:INFO:Uploading results into container
2025-05-27 20:44:53,944:INFO:Uploading model into container now
2025-05-27 20:44:53,944:INFO:_master_model_container: 11
2025-05-27 20:44:53,944:INFO:_display_container: 2
2025-05-27 20:44:53,944:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 20:44:53,944:INFO:create_model() successfully completed......................................
2025-05-27 20:44:54,016:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:54,016:INFO:Creating metrics dataframe
2025-05-27 20:44:54,020:INFO:Initializing Extra Trees Classifier
2025-05-27 20:44:54,020:INFO:Total runtime is 0.3124174356460571 minutes
2025-05-27 20:44:54,020:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:54,020:INFO:Initializing create_model()
2025-05-27 20:44:54,020:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:54,021:INFO:Checking exceptions
2025-05-27 20:44:54,021:INFO:Importing libraries
2025-05-27 20:44:54,021:INFO:Copying training dataset
2025-05-27 20:44:54,027:INFO:Defining folds
2025-05-27 20:44:54,027:INFO:Declaring metric variables
2025-05-27 20:44:54,027:INFO:Importing untrained model
2025-05-27 20:44:54,028:INFO:Extra Trees Classifier Imported successfully
2025-05-27 20:44:54,028:INFO:Starting cross validation
2025-05-27 20:44:54,030:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 20:44:54,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,835:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,850:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,851:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,856:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,857:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,857:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,858:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,863:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,863:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,863:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,864:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,869:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,870:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,875:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,881:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,887:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,894:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,900:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,922:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:54,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,293:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,319:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,320:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 20:44:55,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 20:44:55,336:INFO:Calculating mean and std
2025-05-27 20:44:55,338:INFO:Creating metrics dataframe
2025-05-27 20:44:55,343:INFO:Uploading results into container
2025-05-27 20:44:55,344:INFO:Uploading model into container now
2025-05-27 20:44:55,345:INFO:_master_model_container: 12
2025-05-27 20:44:55,346:INFO:_display_container: 2
2025-05-27 20:44:55,347:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-05-27 20:44:55,347:INFO:create_model() successfully completed......................................
2025-05-27 20:44:55,434:INFO:SubProcess create_model() end ==================================
2025-05-27 20:44:55,434:INFO:Creating metrics dataframe
2025-05-27 20:44:55,438:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 20:44:55,438:INFO:Total runtime is 0.33605140844980874 minutes
2025-05-27 20:44:55,438:INFO:SubProcess create_model() called ==================================
2025-05-27 20:44:55,438:INFO:Initializing create_model()
2025-05-27 20:44:55,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f11d7ab2c50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f11b479db70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 20:44:55,439:INFO:Checking exceptions
2025-05-27 20:44:55,439:INFO:Importing libraries
2025-05-27 20:44:55,439:INFO:Copying training dataset
2025-05-27 20:44:55,445:INFO:Defining folds
2025-05-27 20:44:55,445:INFO:Declaring metric variables
2025-05-27 20:44:55,445:INFO:Importing untrained model
2025-05-27 20:44:55,446:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 20:44:55,447:INFO:Starting cross validation
2025-05-27 20:44:55,449:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-05-27 21:24:12,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:12,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:12,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:12,969:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:16,169:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 21:24:50,738:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:50,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:50,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:50,739:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:24:53,230:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 21:25:26,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:25:26,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:25:26,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:25:26,490:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:25:29,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 21:25:29,176:INFO:PyCaret ClassificationExperiment
2025-05-27 21:25:29,176:INFO:Logging name: clf-default-name
2025-05-27 21:25:29,176:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 21:25:29,176:INFO:version 3.3.2
2025-05-27 21:25:29,176:INFO:Initializing setup()
2025-05-27 21:25:29,176:INFO:self.USI: 970c
2025-05-27 21:25:29,176:INFO:self._variable_keys: {'_available_plots', '_ml_usecase', 'X', 'fold_generator', 'data', 'idx', 'seed', 'gpu_n_jobs_param', 'y_train', 'fold_shuffle_param', 'logging_param', 'y_test', 'pipeline', 'exp_id', 'n_jobs_param', 'fold_groups_param', 'X_test', 'USI', 'y', 'html_param', 'exp_name_log', 'log_plots_param', 'gpu_param', 'fix_imbalance', 'X_train', 'memory', 'is_multiclass', 'target_param'}
2025-05-27 21:25:29,176:INFO:Checking environment
2025-05-27 21:25:29,176:INFO:python_version: 3.10.17
2025-05-27 21:25:29,176:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 21:25:29,176:INFO:machine: x86_64
2025-05-27 21:25:29,179:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:25:29,179:INFO:Memory: svmem(total=16407515136, available=7794311168, percent=52.5, used=7258828800, free=2562961408, active=1433088000, inactive=11372957696, buffers=93192192, cached=6492532736, shared=1004732416, slab=670687232)
2025-05-27 21:25:29,180:INFO:Physical Core: 4
2025-05-27 21:25:29,180:INFO:Logical Core: 8
2025-05-27 21:25:29,180:INFO:Checking libraries
2025-05-27 21:25:29,180:INFO:System:
2025-05-27 21:25:29,180:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 21:25:29,180:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 21:25:29,180:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:25:29,180:INFO:PyCaret required dependencies:
2025-05-27 21:25:29,208:INFO:                 pip: 25.1.1
2025-05-27 21:25:29,208:INFO:          setuptools: 65.5.0
2025-05-27 21:25:29,208:INFO:             pycaret: 3.3.2
2025-05-27 21:25:29,208:INFO:             IPython: 8.36.0
2025-05-27 21:25:29,208:INFO:          ipywidgets: 8.1.7
2025-05-27 21:25:29,208:INFO:                tqdm: 4.67.1
2025-05-27 21:25:29,208:INFO:               numpy: 1.26.4
2025-05-27 21:25:29,208:INFO:              pandas: 2.1.4
2025-05-27 21:25:29,208:INFO:              jinja2: 3.1.6
2025-05-27 21:25:29,208:INFO:               scipy: 1.11.4
2025-05-27 21:25:29,208:INFO:              joblib: 1.3.2
2025-05-27 21:25:29,208:INFO:             sklearn: 1.4.2
2025-05-27 21:25:29,208:INFO:                pyod: 2.0.5
2025-05-27 21:25:29,208:INFO:            imblearn: 0.13.0
2025-05-27 21:25:29,208:INFO:   category_encoders: 2.6.2
2025-05-27 21:25:29,208:INFO:            lightgbm: 4.6.0
2025-05-27 21:25:29,208:INFO:               numba: 0.61.2
2025-05-27 21:25:29,208:INFO:            requests: 2.32.3
2025-05-27 21:25:29,208:INFO:          matplotlib: 3.7.5
2025-05-27 21:25:29,208:INFO:          scikitplot: 0.3.7
2025-05-27 21:25:29,209:INFO:         yellowbrick: 1.5
2025-05-27 21:25:29,209:INFO:              plotly: 5.24.1
2025-05-27 21:25:29,209:INFO:    plotly-resampler: Not installed
2025-05-27 21:25:29,209:INFO:             kaleido: 0.2.1
2025-05-27 21:25:29,209:INFO:           schemdraw: 0.15
2025-05-27 21:25:29,209:INFO:         statsmodels: 0.14.4
2025-05-27 21:25:29,209:INFO:              sktime: 0.26.0
2025-05-27 21:25:29,209:INFO:               tbats: 1.1.3
2025-05-27 21:25:29,209:INFO:            pmdarima: 2.0.4
2025-05-27 21:25:29,209:INFO:              psutil: 7.0.0
2025-05-27 21:25:29,209:INFO:          markupsafe: 3.0.2
2025-05-27 21:25:29,209:INFO:             pickle5: Not installed
2025-05-27 21:25:29,209:INFO:         cloudpickle: 3.1.1
2025-05-27 21:25:29,209:INFO:         deprecation: 2.1.0
2025-05-27 21:25:29,209:INFO:              xxhash: 3.5.0
2025-05-27 21:25:29,209:INFO:           wurlitzer: 3.1.1
2025-05-27 21:25:29,209:INFO:PyCaret optional dependencies:
2025-05-27 21:25:29,590:INFO:                shap: Not installed
2025-05-27 21:25:29,590:INFO:           interpret: Not installed
2025-05-27 21:25:29,590:INFO:                umap: Not installed
2025-05-27 21:25:29,590:INFO:     ydata_profiling: Not installed
2025-05-27 21:25:29,590:INFO:  explainerdashboard: Not installed
2025-05-27 21:25:29,590:INFO:             autoviz: Not installed
2025-05-27 21:25:29,590:INFO:           fairlearn: Not installed
2025-05-27 21:25:29,590:INFO:          deepchecks: Not installed
2025-05-27 21:25:29,590:INFO:             xgboost: Not installed
2025-05-27 21:25:29,590:INFO:            catboost: Not installed
2025-05-27 21:25:29,590:INFO:              kmodes: Not installed
2025-05-27 21:25:29,590:INFO:             mlxtend: Not installed
2025-05-27 21:25:29,590:INFO:       statsforecast: Not installed
2025-05-27 21:25:29,590:INFO:        tune_sklearn: Not installed
2025-05-27 21:25:29,591:INFO:                 ray: Not installed
2025-05-27 21:25:29,591:INFO:            hyperopt: Not installed
2025-05-27 21:25:29,591:INFO:              optuna: Not installed
2025-05-27 21:25:29,591:INFO:               skopt: Not installed
2025-05-27 21:25:29,591:INFO:              mlflow: Not installed
2025-05-27 21:25:29,591:INFO:              gradio: Not installed
2025-05-27 21:25:29,591:INFO:             fastapi: 0.115.12
2025-05-27 21:25:29,591:INFO:             uvicorn: 0.34.2
2025-05-27 21:25:29,591:INFO:              m2cgen: Not installed
2025-05-27 21:25:29,591:INFO:           evidently: Not installed
2025-05-27 21:25:29,591:INFO:               fugue: Not installed
2025-05-27 21:25:29,591:INFO:           streamlit: Not installed
2025-05-27 21:25:29,591:INFO:             prophet: Not installed
2025-05-27 21:25:29,591:INFO:None
2025-05-27 21:25:29,591:INFO:Set up GPU usage.
2025-05-27 21:25:29,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:25:29,591:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-27 21:25:29,591:INFO:Set up data.
2025-05-27 21:25:29,613:INFO:Set up folding strategy.
2025-05-27 21:25:29,613:INFO:Set up train/test split.
2025-05-27 21:25:29,627:INFO:Set up index.
2025-05-27 21:25:29,627:INFO:Assigning column types.
2025-05-27 21:26:41,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:26:41,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:26:41,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:26:41,181:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:26:43,653:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 21:26:43,655:INFO:PyCaret ClassificationExperiment
2025-05-27 21:26:43,655:INFO:Logging name: clf-default-name
2025-05-27 21:26:43,655:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 21:26:43,655:INFO:version 3.3.2
2025-05-27 21:26:43,655:INFO:Initializing setup()
2025-05-27 21:26:43,655:INFO:self.USI: 01df
2025-05-27 21:26:43,655:INFO:self._variable_keys: {'data', 'X_test', 'X_train', 'target_param', 'fold_shuffle_param', '_ml_usecase', 'n_jobs_param', 'gpu_n_jobs_param', 'y_train', 'logging_param', 'fold_generator', 'seed', 'USI', 'log_plots_param', 'exp_id', 'memory', 'gpu_param', 'fold_groups_param', 'html_param', 'y_test', 'pipeline', 'X', 'y', 'is_multiclass', 'exp_name_log', 'idx', 'fix_imbalance', '_available_plots'}
2025-05-27 21:26:43,655:INFO:Checking environment
2025-05-27 21:26:43,655:INFO:python_version: 3.10.17
2025-05-27 21:26:43,655:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 21:26:43,655:INFO:machine: x86_64
2025-05-27 21:26:43,657:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:26:43,657:INFO:Memory: svmem(total=16407515136, available=8051720192, percent=50.9, used=7015841792, free=2809016320, active=1456726016, inactive=11112513536, buffers=93687808, cached=6488969216, shared=990310400, slab=670982144)
2025-05-27 21:26:43,658:INFO:Physical Core: 4
2025-05-27 21:26:43,658:INFO:Logical Core: 8
2025-05-27 21:26:43,658:INFO:Checking libraries
2025-05-27 21:26:43,658:INFO:System:
2025-05-27 21:26:43,658:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 21:26:43,658:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 21:26:43,658:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:26:43,658:INFO:PyCaret required dependencies:
2025-05-27 21:26:43,679:INFO:                 pip: 25.1.1
2025-05-27 21:26:43,679:INFO:          setuptools: 65.5.0
2025-05-27 21:26:43,679:INFO:             pycaret: 3.3.2
2025-05-27 21:26:43,679:INFO:             IPython: 8.36.0
2025-05-27 21:26:43,679:INFO:          ipywidgets: 8.1.7
2025-05-27 21:26:43,679:INFO:                tqdm: 4.67.1
2025-05-27 21:26:43,679:INFO:               numpy: 1.26.4
2025-05-27 21:26:43,679:INFO:              pandas: 2.1.4
2025-05-27 21:26:43,679:INFO:              jinja2: 3.1.6
2025-05-27 21:26:43,679:INFO:               scipy: 1.11.4
2025-05-27 21:26:43,679:INFO:              joblib: 1.3.2
2025-05-27 21:26:43,679:INFO:             sklearn: 1.4.2
2025-05-27 21:26:43,679:INFO:                pyod: 2.0.5
2025-05-27 21:26:43,679:INFO:            imblearn: 0.13.0
2025-05-27 21:26:43,679:INFO:   category_encoders: 2.6.2
2025-05-27 21:26:43,679:INFO:            lightgbm: 4.6.0
2025-05-27 21:26:43,679:INFO:               numba: 0.61.2
2025-05-27 21:26:43,679:INFO:            requests: 2.32.3
2025-05-27 21:26:43,679:INFO:          matplotlib: 3.7.5
2025-05-27 21:26:43,679:INFO:          scikitplot: 0.3.7
2025-05-27 21:26:43,679:INFO:         yellowbrick: 1.5
2025-05-27 21:26:43,679:INFO:              plotly: 5.24.1
2025-05-27 21:26:43,680:INFO:    plotly-resampler: Not installed
2025-05-27 21:26:43,680:INFO:             kaleido: 0.2.1
2025-05-27 21:26:43,680:INFO:           schemdraw: 0.15
2025-05-27 21:26:43,680:INFO:         statsmodels: 0.14.4
2025-05-27 21:26:43,680:INFO:              sktime: 0.26.0
2025-05-27 21:26:43,680:INFO:               tbats: 1.1.3
2025-05-27 21:26:43,680:INFO:            pmdarima: 2.0.4
2025-05-27 21:26:43,680:INFO:              psutil: 7.0.0
2025-05-27 21:26:43,680:INFO:          markupsafe: 3.0.2
2025-05-27 21:26:43,680:INFO:             pickle5: Not installed
2025-05-27 21:26:43,680:INFO:         cloudpickle: 3.1.1
2025-05-27 21:26:43,680:INFO:         deprecation: 2.1.0
2025-05-27 21:26:43,680:INFO:              xxhash: 3.5.0
2025-05-27 21:26:43,680:INFO:           wurlitzer: 3.1.1
2025-05-27 21:26:43,680:INFO:PyCaret optional dependencies:
2025-05-27 21:26:43,998:INFO:                shap: Not installed
2025-05-27 21:26:43,998:INFO:           interpret: Not installed
2025-05-27 21:26:43,998:INFO:                umap: Not installed
2025-05-27 21:26:43,998:INFO:     ydata_profiling: Not installed
2025-05-27 21:26:43,998:INFO:  explainerdashboard: Not installed
2025-05-27 21:26:43,998:INFO:             autoviz: Not installed
2025-05-27 21:26:43,998:INFO:           fairlearn: Not installed
2025-05-27 21:26:43,998:INFO:          deepchecks: Not installed
2025-05-27 21:26:43,998:INFO:             xgboost: Not installed
2025-05-27 21:26:43,998:INFO:            catboost: Not installed
2025-05-27 21:26:43,998:INFO:              kmodes: Not installed
2025-05-27 21:26:43,998:INFO:             mlxtend: Not installed
2025-05-27 21:26:43,998:INFO:       statsforecast: Not installed
2025-05-27 21:26:43,998:INFO:        tune_sklearn: Not installed
2025-05-27 21:26:43,999:INFO:                 ray: Not installed
2025-05-27 21:26:43,999:INFO:            hyperopt: Not installed
2025-05-27 21:26:43,999:INFO:              optuna: Not installed
2025-05-27 21:26:43,999:INFO:               skopt: Not installed
2025-05-27 21:26:43,999:INFO:              mlflow: Not installed
2025-05-27 21:26:43,999:INFO:              gradio: Not installed
2025-05-27 21:26:43,999:INFO:             fastapi: 0.115.12
2025-05-27 21:26:43,999:INFO:             uvicorn: 0.34.2
2025-05-27 21:26:43,999:INFO:              m2cgen: Not installed
2025-05-27 21:26:43,999:INFO:           evidently: Not installed
2025-05-27 21:26:43,999:INFO:               fugue: Not installed
2025-05-27 21:26:43,999:INFO:           streamlit: Not installed
2025-05-27 21:26:43,999:INFO:             prophet: Not installed
2025-05-27 21:26:43,999:INFO:None
2025-05-27 21:26:43,999:INFO:Set up GPU usage.
2025-05-27 21:26:43,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:26:43,999:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-27 21:26:43,999:INFO:Set up data.
2025-05-27 21:26:44,011:INFO:Set up folding strategy.
2025-05-27 21:26:44,011:INFO:Set up train/test split.
2025-05-27 21:26:44,021:INFO:Set up index.
2025-05-27 21:26:44,021:INFO:Assigning column types.
2025-05-27 21:28:07,541:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:07,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 21:28:10,016:INFO:PyCaret ClassificationExperiment
2025-05-27 21:28:10,016:INFO:Logging name: clf-default-name
2025-05-27 21:28:10,016:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 21:28:10,016:INFO:version 3.3.2
2025-05-27 21:28:10,016:INFO:Initializing setup()
2025-05-27 21:28:10,016:INFO:self.USI: c6da
2025-05-27 21:28:10,016:INFO:self._variable_keys: {'fix_imbalance', 'memory', 'html_param', 'fold_shuffle_param', '_ml_usecase', 'y_train', 'idx', 'USI', 'exp_id', 'y', 'target_param', '_available_plots', 'pipeline', 'log_plots_param', 'X_test', 'logging_param', 'X', 'fold_groups_param', 'gpu_param', 'fold_generator', 'X_train', 'seed', 'n_jobs_param', 'is_multiclass', 'gpu_n_jobs_param', 'y_test', 'exp_name_log', 'data'}
2025-05-27 21:28:10,016:INFO:Checking environment
2025-05-27 21:28:10,016:INFO:python_version: 3.10.17
2025-05-27 21:28:10,016:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 21:28:10,016:INFO:machine: x86_64
2025-05-27 21:28:10,018:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:28:10,019:INFO:Memory: svmem(total=16407515136, available=8024006656, percent=51.1, used=7040962560, free=2778345472, active=1465597952, inactive=11127222272, buffers=94097408, cached=6494109696, shared=992894976, slab=671227904)
2025-05-27 21:28:10,019:INFO:Physical Core: 4
2025-05-27 21:28:10,019:INFO:Logical Core: 8
2025-05-27 21:28:10,019:INFO:Checking libraries
2025-05-27 21:28:10,020:INFO:System:
2025-05-27 21:28:10,020:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 21:28:10,020:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 21:28:10,020:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 21:28:10,020:INFO:PyCaret required dependencies:
2025-05-27 21:28:10,049:INFO:                 pip: 25.1.1
2025-05-27 21:28:10,050:INFO:          setuptools: 65.5.0
2025-05-27 21:28:10,050:INFO:             pycaret: 3.3.2
2025-05-27 21:28:10,050:INFO:             IPython: 8.36.0
2025-05-27 21:28:10,050:INFO:          ipywidgets: 8.1.7
2025-05-27 21:28:10,050:INFO:                tqdm: 4.67.1
2025-05-27 21:28:10,050:INFO:               numpy: 1.26.4
2025-05-27 21:28:10,050:INFO:              pandas: 2.1.4
2025-05-27 21:28:10,050:INFO:              jinja2: 3.1.6
2025-05-27 21:28:10,050:INFO:               scipy: 1.11.4
2025-05-27 21:28:10,050:INFO:              joblib: 1.3.2
2025-05-27 21:28:10,050:INFO:             sklearn: 1.4.2
2025-05-27 21:28:10,050:INFO:                pyod: 2.0.5
2025-05-27 21:28:10,050:INFO:            imblearn: 0.13.0
2025-05-27 21:28:10,050:INFO:   category_encoders: 2.6.2
2025-05-27 21:28:10,050:INFO:            lightgbm: 4.6.0
2025-05-27 21:28:10,050:INFO:               numba: 0.61.2
2025-05-27 21:28:10,051:INFO:            requests: 2.32.3
2025-05-27 21:28:10,051:INFO:          matplotlib: 3.7.5
2025-05-27 21:28:10,051:INFO:          scikitplot: 0.3.7
2025-05-27 21:28:10,051:INFO:         yellowbrick: 1.5
2025-05-27 21:28:10,051:INFO:              plotly: 5.24.1
2025-05-27 21:28:10,051:INFO:    plotly-resampler: Not installed
2025-05-27 21:28:10,051:INFO:             kaleido: 0.2.1
2025-05-27 21:28:10,051:INFO:           schemdraw: 0.15
2025-05-27 21:28:10,051:INFO:         statsmodels: 0.14.4
2025-05-27 21:28:10,051:INFO:              sktime: 0.26.0
2025-05-27 21:28:10,051:INFO:               tbats: 1.1.3
2025-05-27 21:28:10,051:INFO:            pmdarima: 2.0.4
2025-05-27 21:28:10,051:INFO:              psutil: 7.0.0
2025-05-27 21:28:10,051:INFO:          markupsafe: 3.0.2
2025-05-27 21:28:10,051:INFO:             pickle5: Not installed
2025-05-27 21:28:10,051:INFO:         cloudpickle: 3.1.1
2025-05-27 21:28:10,052:INFO:         deprecation: 2.1.0
2025-05-27 21:28:10,052:INFO:              xxhash: 3.5.0
2025-05-27 21:28:10,052:INFO:           wurlitzer: 3.1.1
2025-05-27 21:28:10,052:INFO:PyCaret optional dependencies:
2025-05-27 21:28:10,372:INFO:                shap: Not installed
2025-05-27 21:28:10,372:INFO:           interpret: Not installed
2025-05-27 21:28:10,372:INFO:                umap: Not installed
2025-05-27 21:28:10,372:INFO:     ydata_profiling: Not installed
2025-05-27 21:28:10,372:INFO:  explainerdashboard: Not installed
2025-05-27 21:28:10,372:INFO:             autoviz: Not installed
2025-05-27 21:28:10,373:INFO:           fairlearn: Not installed
2025-05-27 21:28:10,373:INFO:          deepchecks: Not installed
2025-05-27 21:28:10,373:INFO:             xgboost: Not installed
2025-05-27 21:28:10,373:INFO:            catboost: Not installed
2025-05-27 21:28:10,373:INFO:              kmodes: Not installed
2025-05-27 21:28:10,373:INFO:             mlxtend: Not installed
2025-05-27 21:28:10,373:INFO:       statsforecast: Not installed
2025-05-27 21:28:10,373:INFO:        tune_sklearn: Not installed
2025-05-27 21:28:10,373:INFO:                 ray: Not installed
2025-05-27 21:28:10,373:INFO:            hyperopt: Not installed
2025-05-27 21:28:10,373:INFO:              optuna: Not installed
2025-05-27 21:28:10,373:INFO:               skopt: Not installed
2025-05-27 21:28:10,373:INFO:              mlflow: Not installed
2025-05-27 21:28:10,373:INFO:              gradio: Not installed
2025-05-27 21:28:10,373:INFO:             fastapi: 0.115.12
2025-05-27 21:28:10,373:INFO:             uvicorn: 0.34.2
2025-05-27 21:28:10,373:INFO:              m2cgen: Not installed
2025-05-27 21:28:10,373:INFO:           evidently: Not installed
2025-05-27 21:28:10,374:INFO:               fugue: Not installed
2025-05-27 21:28:10,374:INFO:           streamlit: Not installed
2025-05-27 21:28:10,374:INFO:             prophet: Not installed
2025-05-27 21:28:10,374:INFO:None
2025-05-27 21:28:10,374:INFO:Set up GPU usage.
2025-05-27 21:28:10,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,374:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-27 21:28:10,374:INFO:Set up data.
2025-05-27 21:28:10,391:INFO:Set up folding strategy.
2025-05-27 21:28:10,391:INFO:Set up train/test split.
2025-05-27 21:28:10,401:INFO:Set up index.
2025-05-27 21:28:10,401:INFO:Assigning column types.
2025-05-27 21:28:10,405:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 21:28:10,405:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 21:28:10,457:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,462:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,463:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 21:28:10,463:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,492:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,497:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:10,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 21:28:14,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,617:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,618:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 21:28:14,618:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,649:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,739:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,740:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 21:28:14,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 21:28:14,794:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,819:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,824:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:14,923:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,974:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,975:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 21:28:14,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:14,999:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,004:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,096:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,096:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 21:28:15,098:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,151:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,175:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,180:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,274:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,275:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,326:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,327:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,329:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,354:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,359:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:15,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:15,454:INFO:Preparing preprocessing pipeline...
2025-05-27 21:28:15,456:INFO:Set up label encoding.
2025-05-27 21:28:15,456:INFO:Set up simple imputation.
2025-05-27 21:28:15,463:INFO:Set up encoding of ordinal features.
2025-05-27 21:28:15,472:INFO:Set up encoding of categorical features.
2025-05-27 21:28:15,619:INFO:Finished creating preprocessing pipeline.
2025-05-27 21:28:15,680:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 21:28:15,680:INFO:Creating final display dataframe.
2025-05-27 21:28:16,070:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           210
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 25)
6   Transformed train set shape                    (1674, 25)
7    Transformed test set shape                     (718, 25)
8               Ignore features                             1
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                        median
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                             5
19                     CPU Jobs                             2
20                      Use GPU                          True
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          c6da
2025-05-27 21:28:16,071:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,120:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,121:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,150:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:16,238:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:16,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,295:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,320:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,324:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 21:28:16,325:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:16,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 21:28:16,417:INFO:setup() successfully completed in 6.4s...............
2025-05-27 21:28:16,417:INFO:Initializing compare_models()
2025-05-27 21:28:16,417:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 21:28:16,417:INFO:Checking exceptions
2025-05-27 21:28:16,422:INFO:Preparing display monitor
2025-05-27 21:28:16,430:INFO:Initializing Logistic Regression
2025-05-27 21:28:16,430:INFO:Total runtime is 2.0345052083333333e-06 minutes
2025-05-27 21:28:16,430:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:16,430:INFO:Initializing create_model()
2025-05-27 21:28:16,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:16,430:INFO:Checking exceptions
2025-05-27 21:28:16,430:INFO:Importing libraries
2025-05-27 21:28:16,430:INFO:Copying training dataset
2025-05-27 21:28:16,436:INFO:Defining folds
2025-05-27 21:28:16,436:INFO:Declaring metric variables
2025-05-27 21:28:16,436:INFO:Importing untrained model
2025-05-27 21:28:16,437:INFO:Logistic Regression Imported successfully
2025-05-27 21:28:16,437:INFO:Starting cross validation
2025-05-27 21:28:16,439:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:17,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 21:28:17,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:17,154:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:17,158:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:17,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:17,701:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 21:28:17,744:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:17,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:17,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:17,754:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,302:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 21:28:18,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:18,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,356:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 21:28:18,940:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:18,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,946:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:18,950:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 21:28:19,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:19,537:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,545:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,552:INFO:Calculating mean and std
2025-05-27 21:28:19,553:INFO:Creating metrics dataframe
2025-05-27 21:28:19,555:INFO:Uploading results into container
2025-05-27 21:28:19,555:INFO:Uploading model into container now
2025-05-27 21:28:19,555:INFO:_master_model_container: 1
2025-05-27 21:28:19,555:INFO:_display_container: 2
2025-05-27 21:28:19,556:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 21:28:19,556:INFO:create_model() successfully completed......................................
2025-05-27 21:28:19,672:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:19,672:INFO:Creating metrics dataframe
2025-05-27 21:28:19,676:INFO:Initializing K Neighbors Classifier
2025-05-27 21:28:19,676:INFO:Total runtime is 0.05410426060358683 minutes
2025-05-27 21:28:19,676:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:19,677:INFO:Initializing create_model()
2025-05-27 21:28:19,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:19,677:INFO:Checking exceptions
2025-05-27 21:28:19,677:INFO:Importing libraries
2025-05-27 21:28:19,677:INFO:Copying training dataset
2025-05-27 21:28:19,684:INFO:Defining folds
2025-05-27 21:28:19,684:INFO:Declaring metric variables
2025-05-27 21:28:19,684:INFO:Importing untrained model
2025-05-27 21:28:19,685:INFO:K Neighbors Classifier Imported successfully
2025-05-27 21:28:19,685:INFO:Starting cross validation
2025-05-27 21:28:19,687:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:19,907:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:19,915:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,096:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,100:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,460:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,464:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,645:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,649:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,653:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,660:INFO:Calculating mean and std
2025-05-27 21:28:20,661:INFO:Creating metrics dataframe
2025-05-27 21:28:20,663:INFO:Uploading results into container
2025-05-27 21:28:20,663:INFO:Uploading model into container now
2025-05-27 21:28:20,663:INFO:_master_model_container: 2
2025-05-27 21:28:20,663:INFO:_display_container: 2
2025-05-27 21:28:20,664:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=2, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 21:28:20,664:INFO:create_model() successfully completed......................................
2025-05-27 21:28:20,777:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:20,778:INFO:Creating metrics dataframe
2025-05-27 21:28:20,783:INFO:Initializing Naive Bayes
2025-05-27 21:28:20,783:INFO:Total runtime is 0.07256008386611938 minutes
2025-05-27 21:28:20,784:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:20,784:INFO:Initializing create_model()
2025-05-27 21:28:20,784:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:20,784:INFO:Checking exceptions
2025-05-27 21:28:20,784:INFO:Importing libraries
2025-05-27 21:28:20,784:INFO:Copying training dataset
2025-05-27 21:28:20,793:INFO:Defining folds
2025-05-27 21:28:20,793:INFO:Declaring metric variables
2025-05-27 21:28:20,793:INFO:Importing untrained model
2025-05-27 21:28:20,793:INFO:Naive Bayes Imported successfully
2025-05-27 21:28:20,794:INFO:Starting cross validation
2025-05-27 21:28:20,796:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:20,954:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:20,962:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:21,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,288:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,442:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,447:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,605:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,613:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,619:INFO:Calculating mean and std
2025-05-27 21:28:21,620:INFO:Creating metrics dataframe
2025-05-27 21:28:21,622:INFO:Uploading results into container
2025-05-27 21:28:21,622:INFO:Uploading model into container now
2025-05-27 21:28:21,623:INFO:_master_model_container: 3
2025-05-27 21:28:21,623:INFO:_display_container: 2
2025-05-27 21:28:21,623:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 21:28:21,623:INFO:create_model() successfully completed......................................
2025-05-27 21:28:21,740:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:21,741:INFO:Creating metrics dataframe
2025-05-27 21:28:21,745:INFO:Initializing Decision Tree Classifier
2025-05-27 21:28:21,745:INFO:Total runtime is 0.0885954737663269 minutes
2025-05-27 21:28:21,746:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:21,746:INFO:Initializing create_model()
2025-05-27 21:28:21,746:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:21,746:INFO:Checking exceptions
2025-05-27 21:28:21,746:INFO:Importing libraries
2025-05-27 21:28:21,746:INFO:Copying training dataset
2025-05-27 21:28:21,754:INFO:Defining folds
2025-05-27 21:28:21,754:INFO:Declaring metric variables
2025-05-27 21:28:21,754:INFO:Importing untrained model
2025-05-27 21:28:21,755:INFO:Decision Tree Classifier Imported successfully
2025-05-27 21:28:21,755:INFO:Starting cross validation
2025-05-27 21:28:21,758:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:21,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,929:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:21,933:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,095:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,263:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,436:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,440:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,630:INFO:Calculating mean and std
2025-05-27 21:28:22,631:INFO:Creating metrics dataframe
2025-05-27 21:28:22,633:INFO:Uploading results into container
2025-05-27 21:28:22,633:INFO:Uploading model into container now
2025-05-27 21:28:22,633:INFO:_master_model_container: 4
2025-05-27 21:28:22,633:INFO:_display_container: 2
2025-05-27 21:28:22,634:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=210, splitter='best')
2025-05-27 21:28:22,634:INFO:create_model() successfully completed......................................
2025-05-27 21:28:22,752:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:22,753:INFO:Creating metrics dataframe
2025-05-27 21:28:22,757:INFO:Initializing SVM - Linear Kernel
2025-05-27 21:28:22,758:INFO:Total runtime is 0.10546318292617797 minutes
2025-05-27 21:28:22,758:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:22,758:INFO:Initializing create_model()
2025-05-27 21:28:22,758:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:22,758:INFO:Checking exceptions
2025-05-27 21:28:22,759:INFO:Importing libraries
2025-05-27 21:28:22,759:INFO:Copying training dataset
2025-05-27 21:28:22,767:INFO:Defining folds
2025-05-27 21:28:22,767:INFO:Declaring metric variables
2025-05-27 21:28:22,767:INFO:Importing untrained model
2025-05-27 21:28:22,768:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 21:28:22,768:INFO:Starting cross validation
2025-05-27 21:28:22,770:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:22,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:22,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,980:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:22,982:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:22,984:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,194:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:23,196:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,202:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:23,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,394:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:23,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,403:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:23,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:23,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:23,597:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,787:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:23,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,793:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,797:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:23,804:INFO:Calculating mean and std
2025-05-27 21:28:23,805:INFO:Creating metrics dataframe
2025-05-27 21:28:23,807:INFO:Uploading results into container
2025-05-27 21:28:23,807:INFO:Uploading model into container now
2025-05-27 21:28:23,807:INFO:_master_model_container: 5
2025-05-27 21:28:23,807:INFO:_display_container: 2
2025-05-27 21:28:23,808:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=2, penalty='l2',
              power_t=0.5, random_state=210, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 21:28:23,808:INFO:create_model() successfully completed......................................
2025-05-27 21:28:23,925:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:23,925:INFO:Creating metrics dataframe
2025-05-27 21:28:23,930:INFO:Initializing Ridge Classifier
2025-05-27 21:28:23,930:INFO:Total runtime is 0.1250131646792094 minutes
2025-05-27 21:28:23,931:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:23,931:INFO:Initializing create_model()
2025-05-27 21:28:23,931:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:23,931:INFO:Checking exceptions
2025-05-27 21:28:23,931:INFO:Importing libraries
2025-05-27 21:28:23,931:INFO:Copying training dataset
2025-05-27 21:28:23,939:INFO:Defining folds
2025-05-27 21:28:23,939:INFO:Declaring metric variables
2025-05-27 21:28:23,940:INFO:Importing untrained model
2025-05-27 21:28:23,940:INFO:Ridge Classifier Imported successfully
2025-05-27 21:28:23,940:INFO:Starting cross validation
2025-05-27 21:28:23,943:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:24,106:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:24,108:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,112:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:24,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,266:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:24,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,272:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:24,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,425:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:24,427:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,431:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,433:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:24,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,585:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:24,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,591:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:24,596:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:24,752:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,756:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,758:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:24,761:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:24,768:INFO:Calculating mean and std
2025-05-27 21:28:24,768:INFO:Creating metrics dataframe
2025-05-27 21:28:24,770:INFO:Uploading results into container
2025-05-27 21:28:24,771:INFO:Uploading model into container now
2025-05-27 21:28:24,771:INFO:_master_model_container: 6
2025-05-27 21:28:24,771:INFO:_display_container: 2
2025-05-27 21:28:24,771:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=210, solver='auto',
                tol=0.0001)
2025-05-27 21:28:24,771:INFO:create_model() successfully completed......................................
2025-05-27 21:28:24,892:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:24,892:INFO:Creating metrics dataframe
2025-05-27 21:28:24,897:INFO:Initializing Random Forest Classifier
2025-05-27 21:28:24,897:INFO:Total runtime is 0.14112389087677002 minutes
2025-05-27 21:28:24,897:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:24,898:INFO:Initializing create_model()
2025-05-27 21:28:24,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:24,898:INFO:Checking exceptions
2025-05-27 21:28:24,898:INFO:Importing libraries
2025-05-27 21:28:24,898:INFO:Copying training dataset
2025-05-27 21:28:24,906:INFO:Defining folds
2025-05-27 21:28:24,906:INFO:Declaring metric variables
2025-05-27 21:28:24,906:INFO:Importing untrained model
2025-05-27 21:28:24,907:INFO:Random Forest Classifier Imported successfully
2025-05-27 21:28:24,907:INFO:Starting cross validation
2025-05-27 21:28:24,910:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:25,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:25,400:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:25,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:25,824:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:25,834:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:25,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,241:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,245:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,249:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,676:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:26,680:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,132:INFO:Calculating mean and std
2025-05-27 21:28:27,133:INFO:Creating metrics dataframe
2025-05-27 21:28:27,135:INFO:Uploading results into container
2025-05-27 21:28:27,136:INFO:Uploading model into container now
2025-05-27 21:28:27,136:INFO:_master_model_container: 7
2025-05-27 21:28:27,136:INFO:_display_container: 2
2025-05-27 21:28:27,137:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=2,
                       oob_score=False, random_state=210, verbose=0,
                       warm_start=False)
2025-05-27 21:28:27,137:INFO:create_model() successfully completed......................................
2025-05-27 21:28:27,256:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:27,256:INFO:Creating metrics dataframe
2025-05-27 21:28:27,260:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 21:28:27,261:INFO:Total runtime is 0.1805136521657308 minutes
2025-05-27 21:28:27,261:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:27,261:INFO:Initializing create_model()
2025-05-27 21:28:27,261:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:27,261:INFO:Checking exceptions
2025-05-27 21:28:27,261:INFO:Importing libraries
2025-05-27 21:28:27,261:INFO:Copying training dataset
2025-05-27 21:28:27,269:INFO:Defining folds
2025-05-27 21:28:27,269:INFO:Declaring metric variables
2025-05-27 21:28:27,269:INFO:Importing untrained model
2025-05-27 21:28:27,270:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 21:28:27,270:INFO:Starting cross validation
2025-05-27 21:28:27,273:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:27,390:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 21:28:27,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:27,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 21:28:27,692:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:27,696:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,705:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,707:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:27,709:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,814:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 21:28:27,903:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:27,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:27,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,025:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 21:28:28,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:28,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,131:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,235:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 21:28:28,325:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:28,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,348:INFO:Calculating mean and std
2025-05-27 21:28:28,349:INFO:Creating metrics dataframe
2025-05-27 21:28:28,351:INFO:Uploading results into container
2025-05-27 21:28:28,351:INFO:Uploading model into container now
2025-05-27 21:28:28,352:INFO:_master_model_container: 8
2025-05-27 21:28:28,352:INFO:_display_container: 2
2025-05-27 21:28:28,352:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 21:28:28,352:INFO:create_model() successfully completed......................................
2025-05-27 21:28:28,473:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:28,473:INFO:Creating metrics dataframe
2025-05-27 21:28:28,478:INFO:Initializing Ada Boost Classifier
2025-05-27 21:28:28,478:INFO:Total runtime is 0.20080438852310178 minutes
2025-05-27 21:28:28,478:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:28,479:INFO:Initializing create_model()
2025-05-27 21:28:28,479:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:28,479:INFO:Checking exceptions
2025-05-27 21:28:28,479:INFO:Importing libraries
2025-05-27 21:28:28,479:INFO:Copying training dataset
2025-05-27 21:28:28,487:INFO:Defining folds
2025-05-27 21:28:28,487:INFO:Declaring metric variables
2025-05-27 21:28:28,487:INFO:Importing untrained model
2025-05-27 21:28:28,487:INFO:Ada Boost Classifier Imported successfully
2025-05-27 21:28:28,488:INFO:Starting cross validation
2025-05-27 21:28:28,490:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:28,604:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 21:28:28,798:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:28,800:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,804:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,808:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:28,913:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 21:28:29,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:29,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,138:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,243:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 21:28:29,435:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:29,437:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,549:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 21:28:29,744:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:29,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,754:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:29,872:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 21:28:30,064:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:30,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:30,070:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:30,072:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:30,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:30,081:INFO:Calculating mean and std
2025-05-27 21:28:30,082:INFO:Creating metrics dataframe
2025-05-27 21:28:30,084:INFO:Uploading results into container
2025-05-27 21:28:30,084:INFO:Uploading model into container now
2025-05-27 21:28:30,085:INFO:_master_model_container: 9
2025-05-27 21:28:30,085:INFO:_display_container: 2
2025-05-27 21:28:30,085:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=210)
2025-05-27 21:28:30,085:INFO:create_model() successfully completed......................................
2025-05-27 21:28:30,204:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:30,205:INFO:Creating metrics dataframe
2025-05-27 21:28:30,209:INFO:Initializing Gradient Boosting Classifier
2025-05-27 21:28:30,209:INFO:Total runtime is 0.22966134548187253 minutes
2025-05-27 21:28:30,210:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:30,210:INFO:Initializing create_model()
2025-05-27 21:28:30,210:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:30,210:INFO:Checking exceptions
2025-05-27 21:28:30,210:INFO:Importing libraries
2025-05-27 21:28:30,210:INFO:Copying training dataset
2025-05-27 21:28:30,218:INFO:Defining folds
2025-05-27 21:28:30,218:INFO:Declaring metric variables
2025-05-27 21:28:30,218:INFO:Importing untrained model
2025-05-27 21:28:30,219:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 21:28:30,219:INFO:Starting cross validation
2025-05-27 21:28:30,222:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:31,939:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:31,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:31,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:31,949:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:33,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:33,656:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:33,660:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:33,664:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:35,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:35,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:35,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:35,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:37,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:37,094:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:37,098:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:37,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:38,816:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:38,818:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:38,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:38,826:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:38,833:INFO:Calculating mean and std
2025-05-27 21:28:38,834:INFO:Creating metrics dataframe
2025-05-27 21:28:38,836:INFO:Uploading results into container
2025-05-27 21:28:38,836:INFO:Uploading model into container now
2025-05-27 21:28:38,837:INFO:_master_model_container: 10
2025-05-27 21:28:38,837:INFO:_display_container: 2
2025-05-27 21:28:38,837:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 21:28:38,837:INFO:create_model() successfully completed......................................
2025-05-27 21:28:38,954:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:38,954:INFO:Creating metrics dataframe
2025-05-27 21:28:38,958:INFO:Initializing Linear Discriminant Analysis
2025-05-27 21:28:38,959:INFO:Total runtime is 0.3754811843236287 minutes
2025-05-27 21:28:38,959:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:38,959:INFO:Initializing create_model()
2025-05-27 21:28:38,959:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:38,959:INFO:Checking exceptions
2025-05-27 21:28:38,960:INFO:Importing libraries
2025-05-27 21:28:38,960:INFO:Copying training dataset
2025-05-27 21:28:38,969:INFO:Defining folds
2025-05-27 21:28:38,969:INFO:Declaring metric variables
2025-05-27 21:28:38,969:INFO:Importing untrained model
2025-05-27 21:28:38,969:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 21:28:38,970:INFO:Starting cross validation
2025-05-27 21:28:38,972:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:39,174:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:39,179:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,188:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,192:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,385:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:39,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,398:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,402:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:39,599:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,613:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,805:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:39,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,819:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:39,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 21:28:40,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,031:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,035:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,042:INFO:Calculating mean and std
2025-05-27 21:28:40,043:INFO:Creating metrics dataframe
2025-05-27 21:28:40,044:INFO:Uploading results into container
2025-05-27 21:28:40,045:INFO:Uploading model into container now
2025-05-27 21:28:40,045:INFO:_master_model_container: 11
2025-05-27 21:28:40,045:INFO:_display_container: 2
2025-05-27 21:28:40,045:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 21:28:40,046:INFO:create_model() successfully completed......................................
2025-05-27 21:28:40,161:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:40,161:INFO:Creating metrics dataframe
2025-05-27 21:28:40,166:INFO:Initializing Extra Trees Classifier
2025-05-27 21:28:40,166:INFO:Total runtime is 0.39560143550237015 minutes
2025-05-27 21:28:40,166:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:40,166:INFO:Initializing create_model()
2025-05-27 21:28:40,166:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:40,167:INFO:Checking exceptions
2025-05-27 21:28:40,167:INFO:Importing libraries
2025-05-27 21:28:40,167:INFO:Copying training dataset
2025-05-27 21:28:40,175:INFO:Defining folds
2025-05-27 21:28:40,175:INFO:Declaring metric variables
2025-05-27 21:28:40,175:INFO:Importing untrained model
2025-05-27 21:28:40,176:INFO:Extra Trees Classifier Imported successfully
2025-05-27 21:28:40,176:INFO:Starting cross validation
2025-05-27 21:28:40,178:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:40,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:40,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,076:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,082:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,559:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,571:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:41,998:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,005:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,010:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,440:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,456:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:42,465:INFO:Calculating mean and std
2025-05-27 21:28:42,466:INFO:Creating metrics dataframe
2025-05-27 21:28:42,468:INFO:Uploading results into container
2025-05-27 21:28:42,468:INFO:Uploading model into container now
2025-05-27 21:28:42,469:INFO:_master_model_container: 12
2025-05-27 21:28:42,469:INFO:_display_container: 2
2025-05-27 21:28:42,469:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=2,
                     oob_score=False, random_state=210, verbose=0,
                     warm_start=False)
2025-05-27 21:28:42,469:INFO:create_model() successfully completed......................................
2025-05-27 21:28:42,591:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:42,592:INFO:Creating metrics dataframe
2025-05-27 21:28:42,596:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 21:28:42,597:INFO:Total runtime is 0.4361147205034891 minutes
2025-05-27 21:28:42,597:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:42,597:INFO:Initializing create_model()
2025-05-27 21:28:42,597:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:42,597:INFO:Checking exceptions
2025-05-27 21:28:42,597:INFO:Importing libraries
2025-05-27 21:28:42,598:INFO:Copying training dataset
2025-05-27 21:28:42,605:INFO:Defining folds
2025-05-27 21:28:42,605:INFO:Declaring metric variables
2025-05-27 21:28:42,605:INFO:Importing untrained model
2025-05-27 21:28:42,606:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 21:28:42,606:INFO:Starting cross validation
2025-05-27 21:28:42,609:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:42,725:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 21:28:42,725:INFO:[LightGBM] [Info] Total Bins 585
2025-05-27 21:28:42,725:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 24
2025-05-27 21:28:42,775:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 21:28:42,776:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 21:28:46,984:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 21:28:46,985:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 21:28:46,986:INFO:[LightGBM] [Info] 8 dense feature groups (0.01 MB) transferred to GPU in 0.000460 secs. 1 sparse feature groups
2025-05-27 21:28:46,986:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 21:28:46,986:INFO:[LightGBM] [Info] Start training from score -2.182399
2025-05-27 21:28:46,986:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 21:28:46,986:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 21:28:46,987:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 21:28:48,128:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:48,132:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:48,136:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:48,247:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 21:28:48,247:INFO:[LightGBM] [Info] Total Bins 585
2025-05-27 21:28:48,247:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 24
2025-05-27 21:28:48,287:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 21:28:48,287:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 21:28:48,296:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 21:28:48,297:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 21:28:48,298:INFO:[LightGBM] [Info] 8 dense feature groups (0.01 MB) transferred to GPU in 0.000447 secs. 1 sparse feature groups
2025-05-27 21:28:48,298:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 21:28:48,298:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 21:28:48,298:INFO:[LightGBM] [Info] Start training from score -1.806051
2025-05-27 21:28:48,298:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 21:28:48,299:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 21:28:49,437:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:49,441:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:49,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:49,555:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 21:28:49,556:INFO:[LightGBM] [Info] Total Bins 585
2025-05-27 21:28:49,556:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 24
2025-05-27 21:28:49,596:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 21:28:49,596:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 21:28:49,605:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 21:28:49,606:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] 8 dense feature groups (0.01 MB) transferred to GPU in 0.000442 secs. 1 sparse feature groups
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 21:28:49,607:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 21:28:50,741:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:50,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:50,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:50,869:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 21:28:50,869:INFO:[LightGBM] [Info] Total Bins 585
2025-05-27 21:28:50,869:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 24
2025-05-27 21:28:50,909:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 21:28:50,909:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 21:28:50,918:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 21:28:50,919:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] 8 dense feature groups (0.01 MB) transferred to GPU in 0.000461 secs. 1 sparse feature groups
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 21:28:50,920:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 21:28:52,073:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:52,077:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:52,081:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:52,192:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 21:28:52,192:INFO:[LightGBM] [Info] Total Bins 585
2025-05-27 21:28:52,192:INFO:[LightGBM] [Info] Number of data points in the train set: 1340, number of used features: 24
2025-05-27 21:28:52,232:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 21:28:52,232:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 21:28:52,241:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 21:28:52,242:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 21:28:52,243:INFO:[LightGBM] [Info] 8 dense feature groups (0.01 MB) transferred to GPU in 0.000441 secs. 1 sparse feature groups
2025-05-27 21:28:52,243:INFO:[LightGBM] [Info] Start training from score -3.106080
2025-05-27 21:28:52,243:INFO:[LightGBM] [Info] Start training from score -2.183145
2025-05-27 21:28:52,243:INFO:[LightGBM] [Info] Start training from score -1.811353
2025-05-27 21:28:52,244:INFO:[LightGBM] [Info] Start training from score -1.753688
2025-05-27 21:28:52,244:INFO:[LightGBM] [Info] Start training from score -0.681278
2025-05-27 21:28:53,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,409:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,416:INFO:Calculating mean and std
2025-05-27 21:28:53,417:INFO:Creating metrics dataframe
2025-05-27 21:28:53,419:INFO:Uploading results into container
2025-05-27 21:28:53,419:INFO:Uploading model into container now
2025-05-27 21:28:53,420:INFO:_master_model_container: 13
2025-05-27 21:28:53,420:INFO:_display_container: 2
2025-05-27 21:28:53,420:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-27 21:28:53,421:INFO:create_model() successfully completed......................................
2025-05-27 21:28:53,538:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:53,538:INFO:Creating metrics dataframe
2025-05-27 21:28:53,543:INFO:Initializing Dummy Classifier
2025-05-27 21:28:53,543:INFO:Total runtime is 0.6185528596242268 minutes
2025-05-27 21:28:53,543:INFO:SubProcess create_model() called ==================================
2025-05-27 21:28:53,544:INFO:Initializing create_model()
2025-05-27 21:28:53,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f99601a7ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:53,544:INFO:Checking exceptions
2025-05-27 21:28:53,544:INFO:Importing libraries
2025-05-27 21:28:53,544:INFO:Copying training dataset
2025-05-27 21:28:53,551:INFO:Defining folds
2025-05-27 21:28:53,551:INFO:Declaring metric variables
2025-05-27 21:28:53,551:INFO:Importing untrained model
2025-05-27 21:28:53,552:INFO:Dummy Classifier Imported successfully
2025-05-27 21:28:53,552:INFO:Starting cross validation
2025-05-27 21:28:53,554:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 21:28:53,712:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,716:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,718:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:53,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,871:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,875:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:53,877:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:53,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,029:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,033:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,035:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:54,037:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,188:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,192:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,194:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:54,196:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,350:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,352:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 21:28:54,354:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 21:28:54,360:INFO:Calculating mean and std
2025-05-27 21:28:54,361:INFO:Creating metrics dataframe
2025-05-27 21:28:54,363:INFO:Uploading results into container
2025-05-27 21:28:54,363:INFO:Uploading model into container now
2025-05-27 21:28:54,364:INFO:_master_model_container: 14
2025-05-27 21:28:54,364:INFO:_display_container: 2
2025-05-27 21:28:54,364:INFO:DummyClassifier(constant=None, random_state=210, strategy='prior')
2025-05-27 21:28:54,364:INFO:create_model() successfully completed......................................
2025-05-27 21:28:54,480:INFO:SubProcess create_model() end ==================================
2025-05-27 21:28:54,480:INFO:Creating metrics dataframe
2025-05-27 21:28:54,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-05-27 21:28:54,492:INFO:Initializing create_model()
2025-05-27 21:28:54,492:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9a5743f3a0>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 21:28:54,492:INFO:Checking exceptions
2025-05-27 21:28:54,493:INFO:Importing libraries
2025-05-27 21:28:54,493:INFO:Copying training dataset
2025-05-27 21:28:54,503:INFO:Defining folds
2025-05-27 21:28:54,503:INFO:Declaring metric variables
2025-05-27 21:28:54,503:INFO:Importing untrained model
2025-05-27 21:28:54,504:INFO:Declaring custom model
2025-05-27 21:28:54,505:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 21:28:54,508:INFO:Cross validation set to False
2025-05-27 21:28:54,508:INFO:Fitting Model
2025-05-27 21:28:56,443:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 21:28:56,443:INFO:create_model() successfully completed......................................
2025-05-27 21:28:56,571:INFO:_master_model_container: 14
2025-05-27 21:28:56,571:INFO:_display_container: 2
2025-05-27 21:28:56,572:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 21:28:56,572:INFO:compare_models() successfully completed......................................
2025-05-27 21:28:56,640:INFO:Initializing save_model()
2025-05-27 21:28:56,640:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-27 21:28:56,641:INFO:Adding model into prep_pipe
2025-05-27 21:28:56,668:INFO:student_performance_model.pkl saved in current working directory
2025-05-27 21:28:56,733:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=210, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-27 21:28:56,733:INFO:save_model() successfully completed......................................
2025-05-27 22:39:55,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:39:55,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:39:55,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:39:55,041:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:09,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:09,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:09,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:09,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:35,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:35,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:35,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:35,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:35,679:INFO:Initializing load_model()
2025-05-27 22:40:35,679:INFO:load_model(model_name=student_performance_model.pkl, platform=None, authentication=None, verbose=True)
2025-05-27 22:40:55,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:55,849:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:55,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:55,850:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:40:56,504:INFO:Initializing load_model()
2025-05-27 22:40:56,504:INFO:load_model(model_name=student_performance_model.pkl, platform=None, authentication=None, verbose=True)
2025-05-27 22:41:06,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:06,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:06,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:06,172:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:06,837:INFO:Initializing load_model()
2025-05-27 22:41:06,837:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:41:22,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:22,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:22,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:22,576:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:41:23,230:INFO:Initializing load_model()
2025-05-27 22:41:23,230:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:42:30,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:42:30,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:42:30,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:42:30,479:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:42:31,352:INFO:Initializing load_model()
2025-05-27 22:42:31,352:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:43:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:43:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:43:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:43:08,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:43:08,705:INFO:Initializing load_model()
2025-05-27 22:43:08,705:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:44:34,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:44:34,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:44:34,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:44:34,133:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:44:34,799:INFO:Initializing load_model()
2025-05-27 22:44:34,799:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:45:39,474:INFO:Initializing predict_model()
2025-05-27 22:45:39,474:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3745257550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f37450b2050>)
2025-05-27 22:45:39,474:INFO:Checking exceptions
2025-05-27 22:45:39,474:INFO:Preloading libraries
2025-05-27 22:45:39,475:INFO:Set up data.
2025-05-27 22:45:39,482:INFO:Set up index.
2025-05-27 22:47:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:42,374:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:44,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 22:47:44,841:INFO:PyCaret ClassificationExperiment
2025-05-27 22:47:44,841:INFO:Logging name: clf-default-name
2025-05-27 22:47:44,841:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 22:47:44,841:INFO:version 3.3.2
2025-05-27 22:47:44,841:INFO:Initializing setup()
2025-05-27 22:47:44,841:INFO:self.USI: b1cd
2025-05-27 22:47:44,841:INFO:self._variable_keys: {'html_param', '_ml_usecase', 'fold_generator', 'log_plots_param', 'fold_shuffle_param', 'pipeline', 'USI', 'idx', 'X', 'gpu_param', 'gpu_n_jobs_param', 'logging_param', 'X_test', 'y_train', 'y', 'is_multiclass', '_available_plots', 'data', 'target_param', 'fold_groups_param', 'exp_name_log', 'n_jobs_param', 'y_test', 'exp_id', 'fix_imbalance', 'seed', 'X_train', 'memory'}
2025-05-27 22:47:44,841:INFO:Checking environment
2025-05-27 22:47:44,841:INFO:python_version: 3.10.17
2025-05-27 22:47:44,841:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 22:47:44,841:INFO:machine: x86_64
2025-05-27 22:47:44,843:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 22:47:44,843:INFO:Memory: svmem(total=16407515136, available=7572029440, percent=53.9, used=7328448512, free=1747697664, active=1822212096, inactive=11345969152, buffers=199987200, cached=7131381760, shared=1157394432, slab=691441664)
2025-05-27 22:47:44,844:INFO:Physical Core: 4
2025-05-27 22:47:44,844:INFO:Logical Core: 8
2025-05-27 22:47:44,844:INFO:Checking libraries
2025-05-27 22:47:44,844:INFO:System:
2025-05-27 22:47:44,844:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 22:47:44,844:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 22:47:44,844:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 22:47:44,844:INFO:PyCaret required dependencies:
2025-05-27 22:47:44,865:INFO:                 pip: 25.1.1
2025-05-27 22:47:44,865:INFO:          setuptools: 65.5.0
2025-05-27 22:47:44,865:INFO:             pycaret: 3.3.2
2025-05-27 22:47:44,865:INFO:             IPython: 8.36.0
2025-05-27 22:47:44,865:INFO:          ipywidgets: 8.1.7
2025-05-27 22:47:44,865:INFO:                tqdm: 4.67.1
2025-05-27 22:47:44,865:INFO:               numpy: 1.26.4
2025-05-27 22:47:44,865:INFO:              pandas: 2.1.4
2025-05-27 22:47:44,866:INFO:              jinja2: 3.1.6
2025-05-27 22:47:44,866:INFO:               scipy: 1.11.4
2025-05-27 22:47:44,866:INFO:              joblib: 1.3.2
2025-05-27 22:47:44,866:INFO:             sklearn: 1.4.2
2025-05-27 22:47:44,866:INFO:                pyod: 2.0.5
2025-05-27 22:47:44,866:INFO:            imblearn: 0.13.0
2025-05-27 22:47:44,866:INFO:   category_encoders: 2.6.2
2025-05-27 22:47:44,866:INFO:            lightgbm: 4.6.0
2025-05-27 22:47:44,866:INFO:               numba: 0.61.2
2025-05-27 22:47:44,866:INFO:            requests: 2.32.3
2025-05-27 22:47:44,866:INFO:          matplotlib: 3.7.5
2025-05-27 22:47:44,866:INFO:          scikitplot: 0.3.7
2025-05-27 22:47:44,866:INFO:         yellowbrick: 1.5
2025-05-27 22:47:44,866:INFO:              plotly: 5.24.1
2025-05-27 22:47:44,866:INFO:    plotly-resampler: Not installed
2025-05-27 22:47:44,866:INFO:             kaleido: 0.2.1
2025-05-27 22:47:44,866:INFO:           schemdraw: 0.15
2025-05-27 22:47:44,866:INFO:         statsmodels: 0.14.4
2025-05-27 22:47:44,866:INFO:              sktime: 0.26.0
2025-05-27 22:47:44,866:INFO:               tbats: 1.1.3
2025-05-27 22:47:44,866:INFO:            pmdarima: 2.0.4
2025-05-27 22:47:44,866:INFO:              psutil: 7.0.0
2025-05-27 22:47:44,866:INFO:          markupsafe: 3.0.2
2025-05-27 22:47:44,866:INFO:             pickle5: Not installed
2025-05-27 22:47:44,866:INFO:         cloudpickle: 3.1.1
2025-05-27 22:47:44,866:INFO:         deprecation: 2.1.0
2025-05-27 22:47:44,866:INFO:              xxhash: 3.5.0
2025-05-27 22:47:44,866:INFO:           wurlitzer: 3.1.1
2025-05-27 22:47:44,866:INFO:PyCaret optional dependencies:
2025-05-27 22:47:45,188:INFO:                shap: Not installed
2025-05-27 22:47:45,188:INFO:           interpret: Not installed
2025-05-27 22:47:45,188:INFO:                umap: Not installed
2025-05-27 22:47:45,188:INFO:     ydata_profiling: Not installed
2025-05-27 22:47:45,188:INFO:  explainerdashboard: Not installed
2025-05-27 22:47:45,188:INFO:             autoviz: Not installed
2025-05-27 22:47:45,188:INFO:           fairlearn: Not installed
2025-05-27 22:47:45,189:INFO:          deepchecks: Not installed
2025-05-27 22:47:45,189:INFO:             xgboost: Not installed
2025-05-27 22:47:45,189:INFO:            catboost: Not installed
2025-05-27 22:47:45,189:INFO:              kmodes: Not installed
2025-05-27 22:47:45,189:INFO:             mlxtend: Not installed
2025-05-27 22:47:45,189:INFO:       statsforecast: Not installed
2025-05-27 22:47:45,189:INFO:        tune_sklearn: Not installed
2025-05-27 22:47:45,189:INFO:                 ray: Not installed
2025-05-27 22:47:45,189:INFO:            hyperopt: Not installed
2025-05-27 22:47:45,189:INFO:              optuna: Not installed
2025-05-27 22:47:45,189:INFO:               skopt: Not installed
2025-05-27 22:47:45,189:INFO:              mlflow: Not installed
2025-05-27 22:47:45,189:INFO:              gradio: Not installed
2025-05-27 22:47:45,189:INFO:             fastapi: 0.115.12
2025-05-27 22:47:45,189:INFO:             uvicorn: 0.34.2
2025-05-27 22:47:45,189:INFO:              m2cgen: Not installed
2025-05-27 22:47:45,189:INFO:           evidently: Not installed
2025-05-27 22:47:45,189:INFO:               fugue: Not installed
2025-05-27 22:47:45,189:INFO:           streamlit: Not installed
2025-05-27 22:47:45,189:INFO:             prophet: Not installed
2025-05-27 22:47:45,189:INFO:None
2025-05-27 22:47:45,189:INFO:Set up GPU usage.
2025-05-27 22:47:45,189:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,189:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-27 22:47:45,189:INFO:Set up data.
2025-05-27 22:47:45,201:INFO:Set up folding strategy.
2025-05-27 22:47:45,201:INFO:Set up train/test split.
2025-05-27 22:47:45,211:INFO:Set up index.
2025-05-27 22:47:45,211:INFO:Assigning column types.
2025-05-27 22:47:45,214:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 22:47:45,214:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,260:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,260:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,263:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,263:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,290:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,294:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,455:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,456:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,511:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,512:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,512:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,535:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,540:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,541:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,635:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,635:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 22:47:45,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,687:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,688:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,711:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,715:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,716:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,859:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,860:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 22:47:45,860:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,883:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,888:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:45,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:45,975:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 22:47:45,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,027:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,056:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:46,142:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:46,142:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,194:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,195:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,197:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,225:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:46,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:46,312:INFO:Preparing preprocessing pipeline...
2025-05-27 22:47:46,313:INFO:Set up label encoding.
2025-05-27 22:47:46,313:INFO:Set up simple imputation.
2025-05-27 22:47:46,319:INFO:Set up encoding of ordinal features.
2025-05-27 22:47:46,329:INFO:Set up encoding of categorical features.
2025-05-27 22:47:46,475:INFO:Finished creating preprocessing pipeline.
2025-05-27 22:47:46,534:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 22:47:46,534:INFO:Creating final display dataframe.
2025-05-27 22:47:46,919:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           210
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 24)
6   Transformed train set shape                    (1674, 24)
7    Transformed test set shape                     (718, 24)
8               Ignore features                             2
9              Numeric features                             3
10         Categorical features                             9
11                   Preprocess                          True
12              Imputation type                        simple
13           Numeric imputation                        median
14       Categorical imputation                          mode
15     Maximum one-hot encoding                            25
16              Encoding method                          None
17               Fold Generator               StratifiedKFold
18                  Fold Number                             5
19                     CPU Jobs                             2
20                      Use GPU                          True
21               Log Experiment                         False
22              Experiment Name              clf-default-name
23                          USI                          b1cd
2025-05-27 22:47:46,919:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,965:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,966:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,989:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,993:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:46,994:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:47,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:47,083:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,130:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,154:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,159:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:47:47,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:47,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 22:47:47,273:INFO:setup() successfully completed in 2.43s...............
2025-05-27 22:47:47,273:INFO:Initializing compare_models()
2025-05-27 22:47:47,273:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 22:47:47,273:INFO:Checking exceptions
2025-05-27 22:47:47,278:INFO:Preparing display monitor
2025-05-27 22:47:47,295:INFO:Initializing Logistic Regression
2025-05-27 22:47:47,295:INFO:Total runtime is 2.586841583251953e-06 minutes
2025-05-27 22:47:47,296:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:47,296:INFO:Initializing create_model()
2025-05-27 22:47:47,296:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:47,296:INFO:Checking exceptions
2025-05-27 22:47:47,296:INFO:Importing libraries
2025-05-27 22:47:47,296:INFO:Copying training dataset
2025-05-27 22:47:47,302:INFO:Defining folds
2025-05-27 22:47:47,302:INFO:Declaring metric variables
2025-05-27 22:47:47,303:INFO:Importing untrained model
2025-05-27 22:47:47,303:INFO:Logistic Regression Imported successfully
2025-05-27 22:47:47,303:INFO:Starting cross validation
2025-05-27 22:47:47,307:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:47,976:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 22:47:48,020:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:48,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:48,026:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:48,031:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:48,554:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:48,556:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:48,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:48,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:49,118:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:49,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:49,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,187:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:50,189:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,193:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,197:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,204:INFO:Calculating mean and std
2025-05-27 22:47:50,205:INFO:Creating metrics dataframe
2025-05-27 22:47:50,206:INFO:Uploading results into container
2025-05-27 22:47:50,207:INFO:Uploading model into container now
2025-05-27 22:47:50,207:INFO:_master_model_container: 1
2025-05-27 22:47:50,207:INFO:_display_container: 2
2025-05-27 22:47:50,208:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 22:47:50,208:INFO:create_model() successfully completed......................................
2025-05-27 22:47:50,323:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:50,323:INFO:Creating metrics dataframe
2025-05-27 22:47:50,327:INFO:Initializing K Neighbors Classifier
2025-05-27 22:47:50,327:INFO:Total runtime is 0.0505266269048055 minutes
2025-05-27 22:47:50,327:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:50,327:INFO:Initializing create_model()
2025-05-27 22:47:50,328:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:50,328:INFO:Checking exceptions
2025-05-27 22:47:50,328:INFO:Importing libraries
2025-05-27 22:47:50,328:INFO:Copying training dataset
2025-05-27 22:47:50,335:INFO:Defining folds
2025-05-27 22:47:50,335:INFO:Declaring metric variables
2025-05-27 22:47:50,335:INFO:Importing untrained model
2025-05-27 22:47:50,335:INFO:K Neighbors Classifier Imported successfully
2025-05-27 22:47:50,336:INFO:Starting cross validation
2025-05-27 22:47:50,338:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:50,551:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,555:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,559:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,734:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,738:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,742:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,917:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,921:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:50,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,108:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,285:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,289:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,293:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,300:INFO:Calculating mean and std
2025-05-27 22:47:51,300:INFO:Creating metrics dataframe
2025-05-27 22:47:51,302:INFO:Uploading results into container
2025-05-27 22:47:51,303:INFO:Uploading model into container now
2025-05-27 22:47:51,303:INFO:_master_model_container: 2
2025-05-27 22:47:51,303:INFO:_display_container: 2
2025-05-27 22:47:51,303:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=2, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 22:47:51,303:INFO:create_model() successfully completed......................................
2025-05-27 22:47:51,419:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:51,419:INFO:Creating metrics dataframe
2025-05-27 22:47:51,424:INFO:Initializing Naive Bayes
2025-05-27 22:47:51,424:INFO:Total runtime is 0.0688175082206726 minutes
2025-05-27 22:47:51,425:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:51,425:INFO:Initializing create_model()
2025-05-27 22:47:51,425:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:51,425:INFO:Checking exceptions
2025-05-27 22:47:51,425:INFO:Importing libraries
2025-05-27 22:47:51,425:INFO:Copying training dataset
2025-05-27 22:47:51,432:INFO:Defining folds
2025-05-27 22:47:51,432:INFO:Declaring metric variables
2025-05-27 22:47:51,433:INFO:Importing untrained model
2025-05-27 22:47:51,433:INFO:Naive Bayes Imported successfully
2025-05-27 22:47:51,433:INFO:Starting cross validation
2025-05-27 22:47:51,436:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:51,597:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,601:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,605:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,760:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,764:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,766:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:51,768:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,927:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,931:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:51,935:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,090:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,095:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,099:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,254:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,258:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,262:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,269:INFO:Calculating mean and std
2025-05-27 22:47:52,270:INFO:Creating metrics dataframe
2025-05-27 22:47:52,272:INFO:Uploading results into container
2025-05-27 22:47:52,272:INFO:Uploading model into container now
2025-05-27 22:47:52,273:INFO:_master_model_container: 3
2025-05-27 22:47:52,273:INFO:_display_container: 2
2025-05-27 22:47:52,273:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 22:47:52,273:INFO:create_model() successfully completed......................................
2025-05-27 22:47:52,389:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:52,390:INFO:Creating metrics dataframe
2025-05-27 22:47:52,394:INFO:Initializing Decision Tree Classifier
2025-05-27 22:47:52,394:INFO:Total runtime is 0.08498540719350178 minutes
2025-05-27 22:47:52,395:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:52,395:INFO:Initializing create_model()
2025-05-27 22:47:52,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:52,395:INFO:Checking exceptions
2025-05-27 22:47:52,395:INFO:Importing libraries
2025-05-27 22:47:52,395:INFO:Copying training dataset
2025-05-27 22:47:52,402:INFO:Defining folds
2025-05-27 22:47:52,403:INFO:Declaring metric variables
2025-05-27 22:47:52,403:INFO:Importing untrained model
2025-05-27 22:47:52,403:INFO:Decision Tree Classifier Imported successfully
2025-05-27 22:47:52,404:INFO:Starting cross validation
2025-05-27 22:47:52,406:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:52,572:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,576:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,580:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,747:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:52,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,075:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,080:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,084:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,246:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,250:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,254:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,261:INFO:Calculating mean and std
2025-05-27 22:47:53,262:INFO:Creating metrics dataframe
2025-05-27 22:47:53,264:INFO:Uploading results into container
2025-05-27 22:47:53,264:INFO:Uploading model into container now
2025-05-27 22:47:53,264:INFO:_master_model_container: 4
2025-05-27 22:47:53,264:INFO:_display_container: 2
2025-05-27 22:47:53,265:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=210, splitter='best')
2025-05-27 22:47:53,265:INFO:create_model() successfully completed......................................
2025-05-27 22:47:53,378:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:53,379:INFO:Creating metrics dataframe
2025-05-27 22:47:53,384:INFO:Initializing SVM - Linear Kernel
2025-05-27 22:47:53,384:INFO:Total runtime is 0.10147633949915567 minutes
2025-05-27 22:47:53,384:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:53,384:INFO:Initializing create_model()
2025-05-27 22:47:53,384:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:53,385:INFO:Checking exceptions
2025-05-27 22:47:53,385:INFO:Importing libraries
2025-05-27 22:47:53,385:INFO:Copying training dataset
2025-05-27 22:47:53,392:INFO:Defining folds
2025-05-27 22:47:53,392:INFO:Declaring metric variables
2025-05-27 22:47:53,392:INFO:Importing untrained model
2025-05-27 22:47:53,393:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 22:47:53,393:INFO:Starting cross validation
2025-05-27 22:47:53,396:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:53,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:53,586:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,590:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,592:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:53,594:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:53,777:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:53,785:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:53,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,979:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:53,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:53,983:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:54,165:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,169:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:54,173:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,364:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:54,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,372:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:54,374:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,381:INFO:Calculating mean and std
2025-05-27 22:47:54,381:INFO:Creating metrics dataframe
2025-05-27 22:47:54,383:INFO:Uploading results into container
2025-05-27 22:47:54,384:INFO:Uploading model into container now
2025-05-27 22:47:54,384:INFO:_master_model_container: 5
2025-05-27 22:47:54,384:INFO:_display_container: 2
2025-05-27 22:47:54,385:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=2, penalty='l2',
              power_t=0.5, random_state=210, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 22:47:54,385:INFO:create_model() successfully completed......................................
2025-05-27 22:47:54,505:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:54,505:INFO:Creating metrics dataframe
2025-05-27 22:47:54,510:INFO:Initializing Ridge Classifier
2025-05-27 22:47:54,510:INFO:Total runtime is 0.12024452686309814 minutes
2025-05-27 22:47:54,510:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:54,511:INFO:Initializing create_model()
2025-05-27 22:47:54,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:54,511:INFO:Checking exceptions
2025-05-27 22:47:54,511:INFO:Importing libraries
2025-05-27 22:47:54,511:INFO:Copying training dataset
2025-05-27 22:47:54,520:INFO:Defining folds
2025-05-27 22:47:54,520:INFO:Declaring metric variables
2025-05-27 22:47:54,520:INFO:Importing untrained model
2025-05-27 22:47:54,520:INFO:Ridge Classifier Imported successfully
2025-05-27 22:47:54,521:INFO:Starting cross validation
2025-05-27 22:47:54,523:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:54,677:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:54,679:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,683:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:54,687:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,839:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:54,841:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,845:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:54,849:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:54,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:54,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,005:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:55,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,156:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:55,158:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,162:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,164:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:55,166:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:55,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,319:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,321:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:55,323:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,330:INFO:Calculating mean and std
2025-05-27 22:47:55,330:INFO:Creating metrics dataframe
2025-05-27 22:47:55,332:INFO:Uploading results into container
2025-05-27 22:47:55,333:INFO:Uploading model into container now
2025-05-27 22:47:55,333:INFO:_master_model_container: 6
2025-05-27 22:47:55,333:INFO:_display_container: 2
2025-05-27 22:47:55,334:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=210, solver='auto',
                tol=0.0001)
2025-05-27 22:47:55,334:INFO:create_model() successfully completed......................................
2025-05-27 22:47:55,454:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:55,454:INFO:Creating metrics dataframe
2025-05-27 22:47:55,459:INFO:Initializing Random Forest Classifier
2025-05-27 22:47:55,459:INFO:Total runtime is 0.13606809377670287 minutes
2025-05-27 22:47:55,460:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:55,460:INFO:Initializing create_model()
2025-05-27 22:47:55,460:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:55,460:INFO:Checking exceptions
2025-05-27 22:47:55,460:INFO:Importing libraries
2025-05-27 22:47:55,460:INFO:Copying training dataset
2025-05-27 22:47:55,468:INFO:Defining folds
2025-05-27 22:47:55,468:INFO:Declaring metric variables
2025-05-27 22:47:55,468:INFO:Importing untrained model
2025-05-27 22:47:55,469:INFO:Random Forest Classifier Imported successfully
2025-05-27 22:47:55,469:INFO:Starting cross validation
2025-05-27 22:47:55,472:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:55,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:55,966:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:56,978:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:57,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:57,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:57,508:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:57,996:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,006:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:47:58,008:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,015:INFO:Calculating mean and std
2025-05-27 22:47:58,016:INFO:Creating metrics dataframe
2025-05-27 22:47:58,018:INFO:Uploading results into container
2025-05-27 22:47:58,018:INFO:Uploading model into container now
2025-05-27 22:47:58,019:INFO:_master_model_container: 7
2025-05-27 22:47:58,019:INFO:_display_container: 2
2025-05-27 22:47:58,019:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=2,
                       oob_score=False, random_state=210, verbose=0,
                       warm_start=False)
2025-05-27 22:47:58,019:INFO:create_model() successfully completed......................................
2025-05-27 22:47:58,138:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:58,138:INFO:Creating metrics dataframe
2025-05-27 22:47:58,143:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 22:47:58,143:INFO:Total runtime is 0.18079973856608073 minutes
2025-05-27 22:47:58,144:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:58,144:INFO:Initializing create_model()
2025-05-27 22:47:58,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:58,144:INFO:Checking exceptions
2025-05-27 22:47:58,144:INFO:Importing libraries
2025-05-27 22:47:58,144:INFO:Copying training dataset
2025-05-27 22:47:58,151:INFO:Defining folds
2025-05-27 22:47:58,151:INFO:Declaring metric variables
2025-05-27 22:47:58,152:INFO:Importing untrained model
2025-05-27 22:47:58,152:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 22:47:58,153:INFO:Starting cross validation
2025-05-27 22:47:58,155:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:58,264:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 22:47:58,353:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:58,357:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,366:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,474:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 22:47:58,562:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:58,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,579:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,683:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 22:47:58,771:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:58,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,784:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:58,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 22:47:58,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:58,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,002:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,010:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 22:47:59,202:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:59,207:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,216:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,223:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,230:INFO:Calculating mean and std
2025-05-27 22:47:59,231:INFO:Creating metrics dataframe
2025-05-27 22:47:59,233:INFO:Uploading results into container
2025-05-27 22:47:59,234:INFO:Uploading model into container now
2025-05-27 22:47:59,234:INFO:_master_model_container: 8
2025-05-27 22:47:59,234:INFO:_display_container: 2
2025-05-27 22:47:59,235:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 22:47:59,235:INFO:create_model() successfully completed......................................
2025-05-27 22:47:59,352:INFO:SubProcess create_model() end ==================================
2025-05-27 22:47:59,352:INFO:Creating metrics dataframe
2025-05-27 22:47:59,356:INFO:Initializing Ada Boost Classifier
2025-05-27 22:47:59,357:INFO:Total runtime is 0.2010226845741272 minutes
2025-05-27 22:47:59,357:INFO:SubProcess create_model() called ==================================
2025-05-27 22:47:59,357:INFO:Initializing create_model()
2025-05-27 22:47:59,357:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:47:59,357:INFO:Checking exceptions
2025-05-27 22:47:59,357:INFO:Importing libraries
2025-05-27 22:47:59,357:INFO:Copying training dataset
2025-05-27 22:47:59,365:INFO:Defining folds
2025-05-27 22:47:59,365:INFO:Declaring metric variables
2025-05-27 22:47:59,365:INFO:Importing untrained model
2025-05-27 22:47:59,365:INFO:Ada Boost Classifier Imported successfully
2025-05-27 22:47:59,366:INFO:Starting cross validation
2025-05-27 22:47:59,368:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:47:59,476:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 22:47:59,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:59,659:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,667:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,770:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 22:47:59,949:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:47:59,951:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,955:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:47:59,959:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,063:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 22:48:00,242:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:00,244:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,248:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,252:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 22:48:00,534:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:00,536:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,540:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,544:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,647:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 22:48:00,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:00,829:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:00,844:INFO:Calculating mean and std
2025-05-27 22:48:00,844:INFO:Creating metrics dataframe
2025-05-27 22:48:00,846:INFO:Uploading results into container
2025-05-27 22:48:00,847:INFO:Uploading model into container now
2025-05-27 22:48:00,847:INFO:_master_model_container: 9
2025-05-27 22:48:00,847:INFO:_display_container: 2
2025-05-27 22:48:00,847:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=210)
2025-05-27 22:48:00,847:INFO:create_model() successfully completed......................................
2025-05-27 22:48:00,961:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:00,961:INFO:Creating metrics dataframe
2025-05-27 22:48:00,966:INFO:Initializing Gradient Boosting Classifier
2025-05-27 22:48:00,966:INFO:Total runtime is 0.22784597078959146 minutes
2025-05-27 22:48:00,966:INFO:SubProcess create_model() called ==================================
2025-05-27 22:48:00,967:INFO:Initializing create_model()
2025-05-27 22:48:00,967:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:00,967:INFO:Checking exceptions
2025-05-27 22:48:00,967:INFO:Importing libraries
2025-05-27 22:48:00,967:INFO:Copying training dataset
2025-05-27 22:48:00,974:INFO:Defining folds
2025-05-27 22:48:00,974:INFO:Declaring metric variables
2025-05-27 22:48:00,975:INFO:Importing untrained model
2025-05-27 22:48:00,975:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 22:48:00,975:INFO:Starting cross validation
2025-05-27 22:48:00,978:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:48:02,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:02,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:02,397:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:02,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:03,803:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:03,805:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:03,809:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:03,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:05,217:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:05,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:05,223:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:05,227:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:06,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:06,632:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:06,636:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:06,640:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,048:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:08,050:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,058:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,065:INFO:Calculating mean and std
2025-05-27 22:48:08,066:INFO:Creating metrics dataframe
2025-05-27 22:48:08,067:INFO:Uploading results into container
2025-05-27 22:48:08,068:INFO:Uploading model into container now
2025-05-27 22:48:08,068:INFO:_master_model_container: 10
2025-05-27 22:48:08,068:INFO:_display_container: 2
2025-05-27 22:48:08,069:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 22:48:08,069:INFO:create_model() successfully completed......................................
2025-05-27 22:48:08,185:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:08,185:INFO:Creating metrics dataframe
2025-05-27 22:48:08,190:INFO:Initializing Linear Discriminant Analysis
2025-05-27 22:48:08,190:INFO:Total runtime is 0.34824163516362505 minutes
2025-05-27 22:48:08,190:INFO:SubProcess create_model() called ==================================
2025-05-27 22:48:08,190:INFO:Initializing create_model()
2025-05-27 22:48:08,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:08,190:INFO:Checking exceptions
2025-05-27 22:48:08,190:INFO:Importing libraries
2025-05-27 22:48:08,191:INFO:Copying training dataset
2025-05-27 22:48:08,197:INFO:Defining folds
2025-05-27 22:48:08,197:INFO:Declaring metric variables
2025-05-27 22:48:08,197:INFO:Importing untrained model
2025-05-27 22:48:08,198:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 22:48:08,198:INFO:Starting cross validation
2025-05-27 22:48:08,200:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:48:08,396:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:08,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,411:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,415:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,604:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:08,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,818:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:08,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:08,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,028:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:09,032:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,042:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,236:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 22:48:09,240:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,250:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,254:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,261:INFO:Calculating mean and std
2025-05-27 22:48:09,262:INFO:Creating metrics dataframe
2025-05-27 22:48:09,263:INFO:Uploading results into container
2025-05-27 22:48:09,264:INFO:Uploading model into container now
2025-05-27 22:48:09,264:INFO:_master_model_container: 11
2025-05-27 22:48:09,264:INFO:_display_container: 2
2025-05-27 22:48:09,265:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 22:48:09,265:INFO:create_model() successfully completed......................................
2025-05-27 22:48:09,382:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:09,382:INFO:Creating metrics dataframe
2025-05-27 22:48:09,386:INFO:Initializing Extra Trees Classifier
2025-05-27 22:48:09,386:INFO:Total runtime is 0.3681873122851054 minutes
2025-05-27 22:48:09,387:INFO:SubProcess create_model() called ==================================
2025-05-27 22:48:09,387:INFO:Initializing create_model()
2025-05-27 22:48:09,387:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:09,387:INFO:Checking exceptions
2025-05-27 22:48:09,387:INFO:Importing libraries
2025-05-27 22:48:09,387:INFO:Copying training dataset
2025-05-27 22:48:09,394:INFO:Defining folds
2025-05-27 22:48:09,394:INFO:Declaring metric variables
2025-05-27 22:48:09,395:INFO:Importing untrained model
2025-05-27 22:48:09,395:INFO:Extra Trees Classifier Imported successfully
2025-05-27 22:48:09,395:INFO:Starting cross validation
2025-05-27 22:48:09,398:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:48:09,814:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,819:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:09,824:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,200:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,204:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,208:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,628:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:10,634:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,065:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,074:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,080:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,469:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,473:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:11,484:INFO:Calculating mean and std
2025-05-27 22:48:11,484:INFO:Creating metrics dataframe
2025-05-27 22:48:11,486:INFO:Uploading results into container
2025-05-27 22:48:11,487:INFO:Uploading model into container now
2025-05-27 22:48:11,487:INFO:_master_model_container: 12
2025-05-27 22:48:11,487:INFO:_display_container: 2
2025-05-27 22:48:11,488:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=2,
                     oob_score=False, random_state=210, verbose=0,
                     warm_start=False)
2025-05-27 22:48:11,488:INFO:create_model() successfully completed......................................
2025-05-27 22:48:11,608:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:11,608:INFO:Creating metrics dataframe
2025-05-27 22:48:11,613:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 22:48:11,613:INFO:Total runtime is 0.4052996516227722 minutes
2025-05-27 22:48:11,613:INFO:SubProcess create_model() called ==================================
2025-05-27 22:48:11,614:INFO:Initializing create_model()
2025-05-27 22:48:11,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:11,614:INFO:Checking exceptions
2025-05-27 22:48:11,614:INFO:Importing libraries
2025-05-27 22:48:11,614:INFO:Copying training dataset
2025-05-27 22:48:11,622:INFO:Defining folds
2025-05-27 22:48:11,622:INFO:Declaring metric variables
2025-05-27 22:48:11,622:INFO:Importing untrained model
2025-05-27 22:48:11,623:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 22:48:11,623:INFO:Starting cross validation
2025-05-27 22:48:11,626:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:48:11,738:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 22:48:11,739:INFO:[LightGBM] [Info] Total Bins 330
2025-05-27 22:48:11,739:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 23
2025-05-27 22:48:11,788:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 22:48:11,788:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 22:48:11,798:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 22:48:11,799:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000285 secs. 1 sparse feature groups
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] Start training from score -2.182399
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 22:48:11,800:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 22:48:12,868:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:12,872:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:12,876:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:12,983:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 22:48:12,984:INFO:[LightGBM] [Info] Total Bins 330
2025-05-27 22:48:12,984:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 23
2025-05-27 22:48:13,023:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 22:48:13,023:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 22:48:13,032:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 22:48:13,033:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000270 secs. 1 sparse feature groups
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] Start training from score -1.806051
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 22:48:13,034:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 22:48:14,106:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:14,110:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:14,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:14,222:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 22:48:14,222:INFO:[LightGBM] [Info] Total Bins 330
2025-05-27 22:48:14,222:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 23
2025-05-27 22:48:14,261:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 22:48:14,262:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 22:48:14,271:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 22:48:14,272:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 22:48:14,272:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000272 secs. 1 sparse feature groups
2025-05-27 22:48:14,273:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 22:48:14,273:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 22:48:14,273:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 22:48:14,273:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 22:48:14,273:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 22:48:15,335:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:15,339:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:15,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:15,451:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 22:48:15,452:INFO:[LightGBM] [Info] Total Bins 330
2025-05-27 22:48:15,452:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 23
2025-05-27 22:48:15,491:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 22:48:15,491:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 22:48:15,500:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 22:48:15,501:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000276 secs. 1 sparse feature groups
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 22:48:15,502:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 22:48:16,565:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:16,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:16,574:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:16,681:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 22:48:16,682:INFO:[LightGBM] [Info] Total Bins 330
2025-05-27 22:48:16,682:INFO:[LightGBM] [Info] Number of data points in the train set: 1340, number of used features: 23
2025-05-27 22:48:16,721:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 22:48:16,722:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 22:48:16,730:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 22:48:16,732:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 22:48:16,732:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000275 secs. 1 sparse feature groups
2025-05-27 22:48:16,733:INFO:[LightGBM] [Info] Start training from score -3.106080
2025-05-27 22:48:16,733:INFO:[LightGBM] [Info] Start training from score -2.183145
2025-05-27 22:48:16,733:INFO:[LightGBM] [Info] Start training from score -1.811353
2025-05-27 22:48:16,733:INFO:[LightGBM] [Info] Start training from score -1.753688
2025-05-27 22:48:16,733:INFO:[LightGBM] [Info] Start training from score -0.681278
2025-05-27 22:48:17,799:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:17,803:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:17,807:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:17,814:INFO:Calculating mean and std
2025-05-27 22:48:17,815:INFO:Creating metrics dataframe
2025-05-27 22:48:17,817:INFO:Uploading results into container
2025-05-27 22:48:17,818:INFO:Uploading model into container now
2025-05-27 22:48:17,818:INFO:_master_model_container: 13
2025-05-27 22:48:17,818:INFO:_display_container: 2
2025-05-27 22:48:17,819:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-27 22:48:17,819:INFO:create_model() successfully completed......................................
2025-05-27 22:48:17,938:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:17,938:INFO:Creating metrics dataframe
2025-05-27 22:48:17,943:INFO:Initializing Dummy Classifier
2025-05-27 22:48:17,943:INFO:Total runtime is 0.5107941587766012 minutes
2025-05-27 22:48:17,943:INFO:SubProcess create_model() called ==================================
2025-05-27 22:48:17,943:INFO:Initializing create_model()
2025-05-27 22:48:17,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7ff3bd63b490>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:17,944:INFO:Checking exceptions
2025-05-27 22:48:17,944:INFO:Importing libraries
2025-05-27 22:48:17,944:INFO:Copying training dataset
2025-05-27 22:48:17,950:INFO:Defining folds
2025-05-27 22:48:17,950:INFO:Declaring metric variables
2025-05-27 22:48:17,951:INFO:Importing untrained model
2025-05-27 22:48:17,951:INFO:Dummy Classifier Imported successfully
2025-05-27 22:48:17,951:INFO:Starting cross validation
2025-05-27 22:48:17,953:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 22:48:18,108:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,112:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,114:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:48:18,117:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,265:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,269:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:48:18,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,422:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,426:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,428:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:48:18,430:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,578:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,582:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,584:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:48:18,586:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,737:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 22:48:18,741:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 22:48:18,748:INFO:Calculating mean and std
2025-05-27 22:48:18,748:INFO:Creating metrics dataframe
2025-05-27 22:48:18,750:INFO:Uploading results into container
2025-05-27 22:48:18,750:INFO:Uploading model into container now
2025-05-27 22:48:18,751:INFO:_master_model_container: 14
2025-05-27 22:48:18,751:INFO:_display_container: 2
2025-05-27 22:48:18,751:INFO:DummyClassifier(constant=None, random_state=210, strategy='prior')
2025-05-27 22:48:18,751:INFO:create_model() successfully completed......................................
2025-05-27 22:48:18,867:INFO:SubProcess create_model() end ==================================
2025-05-27 22:48:18,867:INFO:Creating metrics dataframe
2025-05-27 22:48:18,873:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-05-27 22:48:18,875:INFO:Initializing create_model()
2025-05-27 22:48:18,876:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff4b28ed600>, estimator=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 22:48:18,876:INFO:Checking exceptions
2025-05-27 22:48:18,877:INFO:Importing libraries
2025-05-27 22:48:18,877:INFO:Copying training dataset
2025-05-27 22:48:18,885:INFO:Defining folds
2025-05-27 22:48:18,885:INFO:Declaring metric variables
2025-05-27 22:48:18,886:INFO:Importing untrained model
2025-05-27 22:48:18,886:INFO:Declaring custom model
2025-05-27 22:48:18,887:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 22:48:18,892:INFO:Cross validation set to False
2025-05-27 22:48:18,892:INFO:Fitting Model
2025-05-27 22:48:20,453:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 22:48:20,453:INFO:create_model() successfully completed......................................
2025-05-27 22:48:20,575:INFO:_master_model_container: 14
2025-05-27 22:48:20,576:INFO:_display_container: 2
2025-05-27 22:48:20,576:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 22:48:20,576:INFO:compare_models() successfully completed......................................
2025-05-27 22:48:20,643:INFO:Initializing save_model()
2025-05-27 22:48:20,643:INFO:save_model(model=GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-27 22:48:20,643:INFO:Adding model into prep_pipe
2025-05-27 22:48:20,671:INFO:student_performance_model.pkl saved in current working directory
2025-05-27 22:48:20,737:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                            criterion='friedman_mse', init=None,
                                            learning_rate=0.1, loss='log_loss',
                                            max_depth=3, max_features=None,
                                            max_leaf_nodes=None,
                                            min_impurity_decrease=0.0,
                                            min_samples_leaf=1,
                                            min_samples_split=2,
                                            min_weight_fraction_leaf=0.0,
                                            n_estimators=100,
                                            n_iter_no_change=None,
                                            random_state=210, subsample=1.0,
                                            tol=0.0001, validation_fraction=0.1,
                                            verbose=0, warm_start=False))],
         verbose=False)
2025-05-27 22:48:20,737:INFO:save_model() successfully completed......................................
2025-05-27 22:48:36,443:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:48:36,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:48:36,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:48:36,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:48:37,093:INFO:Initializing load_model()
2025-05-27 22:48:37,093:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:49:31,022:INFO:Initializing predict_model()
2025-05-27 22:49:31,022:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbb2934db40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fbb291ae050>)
2025-05-27 22:49:31,022:INFO:Checking exceptions
2025-05-27 22:49:31,022:INFO:Preloading libraries
2025-05-27 22:49:31,023:INFO:Set up data.
2025-05-27 22:49:31,030:INFO:Set up index.
2025-05-27 22:53:39,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:39,272:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:39,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:39,273:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:39,937:INFO:Initializing load_model()
2025-05-27 22:53:39,937:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:53:54,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:54,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:54,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:54,038:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:53:54,684:INFO:Initializing load_model()
2025-05-27 22:53:54,684:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:54:57,156:INFO:Initializing predict_model()
2025-05-27 22:54:57,156:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa384afdb40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa384b5a050>)
2025-05-27 22:54:57,156:INFO:Checking exceptions
2025-05-27 22:54:57,156:INFO:Preloading libraries
2025-05-27 22:54:57,156:INFO:Set up data.
2025-05-27 22:54:57,162:INFO:Set up index.
2025-05-27 22:55:57,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:55:57,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:55:57,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:55:57,688:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:55:58,339:INFO:Initializing load_model()
2025-05-27 22:55:58,339:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:56:02,630:INFO:Initializing predict_model()
2025-05-27 22:56:02,631:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7ba05e6c50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f7ba0641fc0>)
2025-05-27 22:56:02,631:INFO:Checking exceptions
2025-05-27 22:56:02,631:INFO:Preloading libraries
2025-05-27 22:56:02,631:INFO:Set up data.
2025-05-27 22:56:02,637:INFO:Set up index.
2025-05-27 22:58:03,499:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:58:03,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:58:03,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:58:03,500:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 22:58:04,324:INFO:Initializing load_model()
2025-05-27 22:58:04,324:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 22:58:30,442:INFO:Initializing predict_model()
2025-05-27 22:58:30,442:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f48a3cdc100>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f48a3b3b010>)
2025-05-27 22:58:30,443:INFO:Checking exceptions
2025-05-27 22:58:30,443:INFO:Preloading libraries
2025-05-27 22:58:30,444:INFO:Set up data.
2025-05-27 22:58:30,451:INFO:Set up index.
2025-05-27 23:00:01,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:00:01,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:00:01,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:00:01,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:00:01,848:INFO:Initializing load_model()
2025-05-27 23:00:01,848:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:00:34,454:INFO:Initializing predict_model()
2025-05-27 23:00:34,454:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f9adbf94b80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f9adbff1fc0>)
2025-05-27 23:00:34,454:INFO:Checking exceptions
2025-05-27 23:00:34,454:INFO:Preloading libraries
2025-05-27 23:00:34,455:INFO:Set up data.
2025-05-27 23:00:34,463:INFO:Set up index.
2025-05-27 23:04:22,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:04:22,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:04:22,876:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:04:22,877:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:04:23,596:INFO:Initializing load_model()
2025-05-27 23:04:23,596:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:04:57,697:INFO:Initializing predict_model()
2025-05-27 23:04:57,697:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fc1ccc435b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fc1ccc9dfc0>)
2025-05-27 23:04:57,697:INFO:Checking exceptions
2025-05-27 23:04:57,698:INFO:Preloading libraries
2025-05-27 23:04:57,698:INFO:Set up data.
2025-05-27 23:04:57,703:INFO:Set up index.
2025-05-27 23:06:26,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:06:26,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:06:26,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:06:26,046:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:06:26,753:INFO:Initializing load_model()
2025-05-27 23:06:26,753:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:06:59,989:INFO:Initializing predict_model()
2025-05-27 23:06:59,990:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbf44acf520>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fbf44949fc0>)
2025-05-27 23:06:59,990:INFO:Checking exceptions
2025-05-27 23:06:59,990:INFO:Preloading libraries
2025-05-27 23:06:59,991:INFO:Set up data.
2025-05-27 23:06:59,997:INFO:Set up index.
2025-05-27 23:08:50,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:08:50,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:08:50,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:08:50,786:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:08:51,381:INFO:Initializing load_model()
2025-05-27 23:08:51,381:INFO:load_model(model_name=your_saved_pycaret_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:09:10,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:09:10,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:09:10,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:09:10,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:09:11,541:INFO:Initializing load_model()
2025-05-27 23:09:11,541:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:09:11,686:INFO:Initializing predict_model()
2025-05-27 23:09:11,686:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbeddeb17b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fbeddf7bd90>)
2025-05-27 23:09:11,686:INFO:Checking exceptions
2025-05-27 23:09:11,686:INFO:Preloading libraries
2025-05-27 23:09:11,687:INFO:Set up data.
2025-05-27 23:09:11,692:INFO:Set up index.
2025-05-27 23:12:49,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:12:49,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:12:49,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:12:49,674:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:12:50,269:INFO:Initializing load_model()
2025-05-27 23:12:50,269:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:12:50,413:INFO:Initializing predict_model()
2025-05-27 23:12:50,413:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3567db17b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3567e7bd90>)
2025-05-27 23:12:50,413:INFO:Checking exceptions
2025-05-27 23:12:50,413:INFO:Preloading libraries
2025-05-27 23:12:50,414:INFO:Set up data.
2025-05-27 23:12:50,419:INFO:Set up index.
2025-05-27 23:17:15,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:17:15,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:17:15,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:17:15,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:17:16,022:INFO:Initializing load_model()
2025-05-27 23:17:16,022:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:17:16,183:INFO:Initializing predict_model()
2025-05-27 23:17:16,183:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5f0d2efa90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f5f0d557d90>)
2025-05-27 23:17:16,183:INFO:Checking exceptions
2025-05-27 23:17:16,183:INFO:Preloading libraries
2025-05-27 23:17:16,184:INFO:Set up data.
2025-05-27 23:17:16,252:INFO:Set up index.
2025-05-27 23:17:16,386:INFO:Initializing predict_model()
2025-05-27 23:17:16,386:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5f0d2efa90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f5f0d557d90>)
2025-05-27 23:17:16,386:INFO:Checking exceptions
2025-05-27 23:17:16,386:INFO:Preloading libraries
2025-05-27 23:17:16,386:INFO:Set up data.
2025-05-27 23:17:16,393:INFO:Set up index.
2025-05-27 23:19:31,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:31,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:31,257:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:31,258:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:31,859:INFO:Initializing load_model()
2025-05-27 23:19:31,859:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:19:32,028:INFO:Initializing predict_model()
2025-05-27 23:19:32,029:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f51ca987a90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f51cabefd90>)
2025-05-27 23:19:32,029:INFO:Checking exceptions
2025-05-27 23:19:32,029:INFO:Preloading libraries
2025-05-27 23:19:32,029:INFO:Set up data.
2025-05-27 23:19:32,098:INFO:Set up index.
2025-05-27 23:19:32,253:INFO:Initializing predict_model()
2025-05-27 23:19:32,253:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f51ca987a90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f51cabefd90>)
2025-05-27 23:19:32,253:INFO:Checking exceptions
2025-05-27 23:19:32,253:INFO:Preloading libraries
2025-05-27 23:19:32,253:INFO:Set up data.
2025-05-27 23:19:32,261:INFO:Set up index.
2025-05-27 23:19:41,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:41,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:41,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:41,798:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:19:42,396:INFO:Initializing load_model()
2025-05-27 23:19:42,396:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:19:42,545:INFO:Initializing predict_model()
2025-05-27 23:19:42,546:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb08ed5d750>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fb08ee2bd90>)
2025-05-27 23:19:42,546:INFO:Checking exceptions
2025-05-27 23:19:42,546:INFO:Preloading libraries
2025-05-27 23:19:42,546:INFO:Set up data.
2025-05-27 23:19:42,551:INFO:Set up index.
2025-05-27 23:20:34,242:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:20:34,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:20:34,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:20:34,243:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:20:34,876:INFO:Initializing load_model()
2025-05-27 23:20:34,877:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:20:35,025:INFO:Initializing predict_model()
2025-05-27 23:20:35,025:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fce50b697b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fce50c33d90>)
2025-05-27 23:20:35,025:INFO:Checking exceptions
2025-05-27 23:20:35,025:INFO:Preloading libraries
2025-05-27 23:20:35,025:INFO:Set up data.
2025-05-27 23:20:35,032:INFO:Set up index.
2025-05-27 23:45:37,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:37,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:37,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:37,267:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:37,861:INFO:Initializing load_model()
2025-05-27 23:45:37,861:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:45:38,008:INFO:Initializing predict_model()
2025-05-27 23:45:38,008:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f158f0e17b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f158f1abd90>)
2025-05-27 23:45:38,008:INFO:Checking exceptions
2025-05-27 23:45:38,008:INFO:Preloading libraries
2025-05-27 23:45:38,008:INFO:Set up data.
2025-05-27 23:45:38,015:INFO:Set up index.
2025-05-27 23:45:44,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:44,102:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:44,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:44,103:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:45:44,699:INFO:Initializing load_model()
2025-05-27 23:45:44,699:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:45:44,846:INFO:Initializing predict_model()
2025-05-27 23:45:44,846:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5b0d8597b0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f5b0d927d90>)
2025-05-27 23:45:44,846:INFO:Checking exceptions
2025-05-27 23:45:44,846:INFO:Preloading libraries
2025-05-27 23:45:44,847:INFO:Set up data.
2025-05-27 23:45:44,854:INFO:Set up index.
2025-05-27 23:47:04,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:47:04,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:47:04,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:47:04,934:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:47:05,538:INFO:Initializing load_model()
2025-05-27 23:47:05,538:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:47:05,690:INFO:Initializing predict_model()
2025-05-27 23:47:05,690:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1a542f09d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f1a89353d90>)
2025-05-27 23:47:05,690:INFO:Checking exceptions
2025-05-27 23:47:05,690:INFO:Preloading libraries
2025-05-27 23:47:05,690:INFO:Set up data.
2025-05-27 23:47:05,756:INFO:Set up index.
2025-05-27 23:48:17,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:48:17,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:48:17,474:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:48:17,475:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:48:18,069:INFO:Initializing load_model()
2025-05-27 23:48:18,069:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-27 23:48:18,222:INFO:Initializing predict_model()
2025-05-27 23:48:18,222:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5587f80c40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(strategy='median'))),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tut...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': 0      0
1      1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 GradientBoostingClassifier(random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f558c1d8310>)
2025-05-27 23:48:18,222:INFO:Checking exceptions
2025-05-27 23:48:18,222:INFO:Preloading libraries
2025-05-27 23:48:18,222:INFO:Set up data.
2025-05-27 23:48:18,229:INFO:Set up index.
2025-05-27 23:52:14,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:14,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:14,350:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:14,351:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,064:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/torch/cuda/__init__.py:174: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)
  return torch._C._cuda_getDeviceCount() > 0

2025-05-27 23:52:15,065:INFO:PyCaret ClassificationExperiment
2025-05-27 23:52:15,065:INFO:Logging name: clf-default-name
2025-05-27 23:52:15,065:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-27 23:52:15,066:INFO:version 3.3.2
2025-05-27 23:52:15,066:INFO:Initializing setup()
2025-05-27 23:52:15,066:INFO:self.USI: 809e
2025-05-27 23:52:15,066:INFO:self._variable_keys: {'y', 'fold_groups_param', '_available_plots', '_ml_usecase', 'target_param', 'is_multiclass', 'exp_id', 'y_train', 'logging_param', 'data', 'html_param', 'memory', 'X', 'fix_imbalance', 'fold_shuffle_param', 'gpu_param', 'fold_generator', 'X_train', 'gpu_n_jobs_param', 'exp_name_log', 'USI', 'seed', 'y_test', 'X_test', 'n_jobs_param', 'pipeline', 'log_plots_param', 'idx'}
2025-05-27 23:52:15,066:INFO:Checking environment
2025-05-27 23:52:15,066:INFO:python_version: 3.10.17
2025-05-27 23:52:15,066:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-27 23:52:15,066:INFO:machine: x86_64
2025-05-27 23:52:15,068:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 23:52:15,068:INFO:Memory: svmem(total=16407515136, available=7357558784, percent=55.2, used=7550509056, free=1488547840, active=1842753536, inactive=11552100352, buffers=215482368, cached=7152975872, shared=1149804544, slab=695230464)
2025-05-27 23:52:15,068:INFO:Physical Core: 4
2025-05-27 23:52:15,069:INFO:Logical Core: 8
2025-05-27 23:52:15,069:INFO:Checking libraries
2025-05-27 23:52:15,069:INFO:System:
2025-05-27 23:52:15,069:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-27 23:52:15,069:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-27 23:52:15,069:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-27 23:52:15,069:INFO:PyCaret required dependencies:
2025-05-27 23:52:15,089:INFO:                 pip: 25.1.1
2025-05-27 23:52:15,089:INFO:          setuptools: 65.5.0
2025-05-27 23:52:15,089:INFO:             pycaret: 3.3.2
2025-05-27 23:52:15,089:INFO:             IPython: 8.36.0
2025-05-27 23:52:15,089:INFO:          ipywidgets: 8.1.7
2025-05-27 23:52:15,089:INFO:                tqdm: 4.67.1
2025-05-27 23:52:15,089:INFO:               numpy: 1.26.4
2025-05-27 23:52:15,089:INFO:              pandas: 2.1.4
2025-05-27 23:52:15,089:INFO:              jinja2: 3.1.6
2025-05-27 23:52:15,089:INFO:               scipy: 1.11.4
2025-05-27 23:52:15,089:INFO:              joblib: 1.3.2
2025-05-27 23:52:15,089:INFO:             sklearn: 1.4.2
2025-05-27 23:52:15,089:INFO:                pyod: 2.0.5
2025-05-27 23:52:15,089:INFO:            imblearn: 0.13.0
2025-05-27 23:52:15,089:INFO:   category_encoders: 2.6.2
2025-05-27 23:52:15,089:INFO:            lightgbm: 4.6.0
2025-05-27 23:52:15,089:INFO:               numba: 0.61.2
2025-05-27 23:52:15,089:INFO:            requests: 2.32.3
2025-05-27 23:52:15,089:INFO:          matplotlib: 3.7.5
2025-05-27 23:52:15,089:INFO:          scikitplot: 0.3.7
2025-05-27 23:52:15,089:INFO:         yellowbrick: 1.5
2025-05-27 23:52:15,089:INFO:              plotly: 5.24.1
2025-05-27 23:52:15,090:INFO:    plotly-resampler: Not installed
2025-05-27 23:52:15,090:INFO:             kaleido: 0.2.1
2025-05-27 23:52:15,090:INFO:           schemdraw: 0.15
2025-05-27 23:52:15,090:INFO:         statsmodels: 0.14.4
2025-05-27 23:52:15,090:INFO:              sktime: 0.26.0
2025-05-27 23:52:15,090:INFO:               tbats: 1.1.3
2025-05-27 23:52:15,090:INFO:            pmdarima: 2.0.4
2025-05-27 23:52:15,090:INFO:              psutil: 7.0.0
2025-05-27 23:52:15,090:INFO:          markupsafe: 3.0.2
2025-05-27 23:52:15,090:INFO:             pickle5: Not installed
2025-05-27 23:52:15,090:INFO:         cloudpickle: 3.1.1
2025-05-27 23:52:15,090:INFO:         deprecation: 2.1.0
2025-05-27 23:52:15,090:INFO:              xxhash: 3.5.0
2025-05-27 23:52:15,090:INFO:           wurlitzer: 3.1.1
2025-05-27 23:52:15,090:INFO:PyCaret optional dependencies:
2025-05-27 23:52:15,416:INFO:                shap: Not installed
2025-05-27 23:52:15,416:INFO:           interpret: Not installed
2025-05-27 23:52:15,416:INFO:                umap: Not installed
2025-05-27 23:52:15,416:INFO:     ydata_profiling: Not installed
2025-05-27 23:52:15,416:INFO:  explainerdashboard: Not installed
2025-05-27 23:52:15,416:INFO:             autoviz: Not installed
2025-05-27 23:52:15,416:INFO:           fairlearn: Not installed
2025-05-27 23:52:15,416:INFO:          deepchecks: Not installed
2025-05-27 23:52:15,416:INFO:             xgboost: Not installed
2025-05-27 23:52:15,416:INFO:            catboost: Not installed
2025-05-27 23:52:15,416:INFO:              kmodes: Not installed
2025-05-27 23:52:15,416:INFO:             mlxtend: Not installed
2025-05-27 23:52:15,416:INFO:       statsforecast: Not installed
2025-05-27 23:52:15,416:INFO:        tune_sklearn: Not installed
2025-05-27 23:52:15,416:INFO:                 ray: Not installed
2025-05-27 23:52:15,416:INFO:            hyperopt: Not installed
2025-05-27 23:52:15,417:INFO:              optuna: Not installed
2025-05-27 23:52:15,417:INFO:               skopt: Not installed
2025-05-27 23:52:15,417:INFO:              mlflow: Not installed
2025-05-27 23:52:15,417:INFO:              gradio: Not installed
2025-05-27 23:52:15,417:INFO:             fastapi: 0.115.12
2025-05-27 23:52:15,417:INFO:             uvicorn: 0.34.2
2025-05-27 23:52:15,417:INFO:              m2cgen: Not installed
2025-05-27 23:52:15,417:INFO:           evidently: Not installed
2025-05-27 23:52:15,417:INFO:               fugue: Not installed
2025-05-27 23:52:15,417:INFO:           streamlit: Not installed
2025-05-27 23:52:15,417:INFO:             prophet: Not installed
2025-05-27 23:52:15,417:INFO:None
2025-05-27 23:52:15,417:INFO:Set up GPU usage.
2025-05-27 23:52:15,417:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,417:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-27 23:52:15,417:INFO:Set up data.
2025-05-27 23:52:15,424:INFO:Set up folding strategy.
2025-05-27 23:52:15,424:INFO:Set up train/test split.
2025-05-27 23:52:15,433:INFO:Set up index.
2025-05-27 23:52:15,434:INFO:Assigning column types.
2025-05-27 23:52:15,438:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-27 23:52:15,439:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,482:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 23:52:15,482:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,485:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 23:52:15,485:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,510:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,514:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:15,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:15,724:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,778:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-27 23:52:15,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,778:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,779:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 23:52:15,779:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,801:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,805:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:15,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:15,895:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-27 23:52:15,895:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,946:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,948:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 23:52:15,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,970:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,975:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:15,976:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,062:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,115:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,116:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-27 23:52:16,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,140:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,145:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,258:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,259:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-27 23:52:16,259:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,313:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,314:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,341:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,431:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,480:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,481:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,504:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,508:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:16,509:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:16,602:INFO:Preparing preprocessing pipeline...
2025-05-27 23:52:16,603:INFO:Set up label encoding.
2025-05-27 23:52:16,603:INFO:Set up simple imputation.
2025-05-27 23:52:16,609:INFO:Set up encoding of ordinal features.
2025-05-27 23:52:16,622:INFO:Set up encoding of categorical features.
2025-05-27 23:52:16,805:INFO:Finished creating preprocessing pipeline.
2025-05-27 23:52:16,890:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences', 'GPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feat...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-27 23:52:16,890:INFO:Creating final display dataframe.
2025-05-27 23:52:17,355:INFO:Setup _display_container:                     Description                         Value
0                    Session id                           210
1                        Target                    GradeClass
2                   Target type                    Multiclass
3                Target mapping  0: 0, 1: 1, 2: 2, 3: 3, 4: 4
4           Original data shape                    (2392, 15)
5        Transformed data shape                    (2392, 23)
6   Transformed train set shape                    (1674, 23)
7    Transformed test set shape                     (718, 23)
8               Ignore features                             1
9              Ordinal features                             2
10             Numeric features                             4
11         Categorical features                             9
12     Rows with missing values                         39.8%
13                   Preprocess                          True
14              Imputation type                        simple
15           Numeric imputation                        median
16       Categorical imputation                          mode
17     Maximum one-hot encoding                            25
18              Encoding method                          None
19               Fold Generator               StratifiedKFold
20                  Fold Number                             5
21                     CPU Jobs                             2
22                      Use GPU                          True
23               Log Experiment                         False
24              Experiment Name              clf-default-name
25                          USI                          809e
2025-05-27 23:52:17,355:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,401:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,402:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,423:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,428:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,429:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:17,515:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:17,516:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,562:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,563:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,564:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,586:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,591:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-27 23:52:17,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:17,680:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-27 23:52:17,683:INFO:setup() successfully completed in 2.62s...............
2025-05-27 23:52:17,683:INFO:Initializing compare_models()
2025-05-27 23:52:17,683:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-27 23:52:17,683:INFO:Checking exceptions
2025-05-27 23:52:17,688:INFO:Preparing display monitor
2025-05-27 23:52:17,692:INFO:Initializing Logistic Regression
2025-05-27 23:52:17,692:INFO:Total runtime is 1.7921129862467448e-06 minutes
2025-05-27 23:52:17,692:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:17,692:INFO:Initializing create_model()
2025-05-27 23:52:17,693:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=lr, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:17,693:INFO:Checking exceptions
2025-05-27 23:52:17,693:INFO:Importing libraries
2025-05-27 23:52:17,693:INFO:Copying training dataset
2025-05-27 23:52:17,700:INFO:Defining folds
2025-05-27 23:52:17,700:INFO:Declaring metric variables
2025-05-27 23:52:17,700:INFO:Importing untrained model
2025-05-27 23:52:17,701:INFO:Logistic Regression Imported successfully
2025-05-27 23:52:17,701:INFO:Starting cross validation
2025-05-27 23:52:17,704:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:18,253:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 23:52:18,300:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:18,302:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:18,307:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:18,309:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:18,311:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:18,844:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 23:52:18,890:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:18,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:18,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:18,900:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:19,433:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 23:52:19,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:19,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:19,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:19,494:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,056:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 23:52:20,103:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:20,105:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-27 23:52:20,695:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:20,697:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,702:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,706:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:20,712:INFO:Calculating mean and std
2025-05-27 23:52:20,713:INFO:Creating metrics dataframe
2025-05-27 23:52:20,715:INFO:Uploading results into container
2025-05-27 23:52:20,715:INFO:Uploading model into container now
2025-05-27 23:52:20,716:INFO:_master_model_container: 1
2025-05-27 23:52:20,716:INFO:_display_container: 2
2025-05-27 23:52:20,716:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-27 23:52:20,716:INFO:create_model() successfully completed......................................
2025-05-27 23:52:20,829:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:20,829:INFO:Creating metrics dataframe
2025-05-27 23:52:20,833:INFO:Initializing K Neighbors Classifier
2025-05-27 23:52:20,833:INFO:Total runtime is 0.052347528934478756 minutes
2025-05-27 23:52:20,833:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:20,833:INFO:Initializing create_model()
2025-05-27 23:52:20,833:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=knn, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:20,833:INFO:Checking exceptions
2025-05-27 23:52:20,834:INFO:Importing libraries
2025-05-27 23:52:20,834:INFO:Copying training dataset
2025-05-27 23:52:20,840:INFO:Defining folds
2025-05-27 23:52:20,841:INFO:Declaring metric variables
2025-05-27 23:52:20,841:INFO:Importing untrained model
2025-05-27 23:52:20,841:INFO:K Neighbors Classifier Imported successfully
2025-05-27 23:52:20,842:INFO:Starting cross validation
2025-05-27 23:52:20,844:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:21,072:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,077:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,081:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,284:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,481:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,490:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,685:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,690:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,695:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,912:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:21,927:INFO:Calculating mean and std
2025-05-27 23:52:21,928:INFO:Creating metrics dataframe
2025-05-27 23:52:21,930:INFO:Uploading results into container
2025-05-27 23:52:21,930:INFO:Uploading model into container now
2025-05-27 23:52:21,931:INFO:_master_model_container: 2
2025-05-27 23:52:21,931:INFO:_display_container: 2
2025-05-27 23:52:21,931:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=2, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-27 23:52:21,931:INFO:create_model() successfully completed......................................
2025-05-27 23:52:22,042:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:22,042:INFO:Creating metrics dataframe
2025-05-27 23:52:22,047:INFO:Initializing Naive Bayes
2025-05-27 23:52:22,047:INFO:Total runtime is 0.0725874145825704 minutes
2025-05-27 23:52:22,047:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:22,048:INFO:Initializing create_model()
2025-05-27 23:52:22,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=nb, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:22,048:INFO:Checking exceptions
2025-05-27 23:52:22,048:INFO:Importing libraries
2025-05-27 23:52:22,048:INFO:Copying training dataset
2025-05-27 23:52:22,055:INFO:Defining folds
2025-05-27 23:52:22,055:INFO:Declaring metric variables
2025-05-27 23:52:22,056:INFO:Importing untrained model
2025-05-27 23:52:22,056:INFO:Naive Bayes Imported successfully
2025-05-27 23:52:22,056:INFO:Starting cross validation
2025-05-27 23:52:22,059:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:22,230:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,235:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,239:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,412:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,417:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:22,421:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,590:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,594:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,599:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,770:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,774:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,952:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:22,963:INFO:Calculating mean and std
2025-05-27 23:52:22,964:INFO:Creating metrics dataframe
2025-05-27 23:52:22,966:INFO:Uploading results into container
2025-05-27 23:52:22,966:INFO:Uploading model into container now
2025-05-27 23:52:22,966:INFO:_master_model_container: 3
2025-05-27 23:52:22,966:INFO:_display_container: 2
2025-05-27 23:52:22,967:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-27 23:52:22,967:INFO:create_model() successfully completed......................................
2025-05-27 23:52:23,074:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:23,074:INFO:Creating metrics dataframe
2025-05-27 23:52:23,078:INFO:Initializing Decision Tree Classifier
2025-05-27 23:52:23,078:INFO:Total runtime is 0.08976404269536337 minutes
2025-05-27 23:52:23,078:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:23,078:INFO:Initializing create_model()
2025-05-27 23:52:23,078:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=dt, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:23,078:INFO:Checking exceptions
2025-05-27 23:52:23,078:INFO:Importing libraries
2025-05-27 23:52:23,078:INFO:Copying training dataset
2025-05-27 23:52:23,084:INFO:Defining folds
2025-05-27 23:52:23,084:INFO:Declaring metric variables
2025-05-27 23:52:23,085:INFO:Importing untrained model
2025-05-27 23:52:23,085:INFO:Decision Tree Classifier Imported successfully
2025-05-27 23:52:23,085:INFO:Starting cross validation
2025-05-27 23:52:23,087:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:23,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,271:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,449:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,454:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,458:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,633:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,637:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,812:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,818:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:23,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,003:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,010:INFO:Calculating mean and std
2025-05-27 23:52:24,010:INFO:Creating metrics dataframe
2025-05-27 23:52:24,012:INFO:Uploading results into container
2025-05-27 23:52:24,012:INFO:Uploading model into container now
2025-05-27 23:52:24,013:INFO:_master_model_container: 4
2025-05-27 23:52:24,013:INFO:_display_container: 2
2025-05-27 23:52:24,013:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=210, splitter='best')
2025-05-27 23:52:24,013:INFO:create_model() successfully completed......................................
2025-05-27 23:52:24,125:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:24,125:INFO:Creating metrics dataframe
2025-05-27 23:52:24,129:INFO:Initializing SVM - Linear Kernel
2025-05-27 23:52:24,130:INFO:Total runtime is 0.10729378859202067 minutes
2025-05-27 23:52:24,130:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:24,130:INFO:Initializing create_model()
2025-05-27 23:52:24,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=svm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:24,130:INFO:Checking exceptions
2025-05-27 23:52:24,130:INFO:Importing libraries
2025-05-27 23:52:24,130:INFO:Copying training dataset
2025-05-27 23:52:24,137:INFO:Defining folds
2025-05-27 23:52:24,137:INFO:Declaring metric variables
2025-05-27 23:52:24,137:INFO:Importing untrained model
2025-05-27 23:52:24,138:INFO:SVM - Linear Kernel Imported successfully
2025-05-27 23:52:24,138:INFO:Starting cross validation
2025-05-27 23:52:24,141:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:24,358:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:24,360:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,367:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:24,369:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,565:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:24,567:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,571:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,573:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:24,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,781:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:24,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,787:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:24,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:25,002:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,007:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,009:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:25,011:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,207:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:25,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,213:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,215:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:25,217:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,224:INFO:Calculating mean and std
2025-05-27 23:52:25,225:INFO:Creating metrics dataframe
2025-05-27 23:52:25,227:INFO:Uploading results into container
2025-05-27 23:52:25,227:INFO:Uploading model into container now
2025-05-27 23:52:25,228:INFO:_master_model_container: 5
2025-05-27 23:52:25,228:INFO:_display_container: 2
2025-05-27 23:52:25,228:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=2, penalty='l2',
              power_t=0.5, random_state=210, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-27 23:52:25,228:INFO:create_model() successfully completed......................................
2025-05-27 23:52:25,353:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:25,353:INFO:Creating metrics dataframe
2025-05-27 23:52:25,358:INFO:Initializing Ridge Classifier
2025-05-27 23:52:25,358:INFO:Total runtime is 0.12776625553766885 minutes
2025-05-27 23:52:25,358:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:25,359:INFO:Initializing create_model()
2025-05-27 23:52:25,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=ridge, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:25,359:INFO:Checking exceptions
2025-05-27 23:52:25,359:INFO:Importing libraries
2025-05-27 23:52:25,359:INFO:Copying training dataset
2025-05-27 23:52:25,366:INFO:Defining folds
2025-05-27 23:52:25,366:INFO:Declaring metric variables
2025-05-27 23:52:25,366:INFO:Importing untrained model
2025-05-27 23:52:25,367:INFO:Ridge Classifier Imported successfully
2025-05-27 23:52:25,367:INFO:Starting cross validation
2025-05-27 23:52:25,370:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:25,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:25,543:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,547:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,549:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:25,551:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:25,741:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,748:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:25,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,914:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:25,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,920:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:25,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:25,927:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:26,094:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,098:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,100:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:26,102:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:26,270:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:26,279:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,286:INFO:Calculating mean and std
2025-05-27 23:52:26,286:INFO:Creating metrics dataframe
2025-05-27 23:52:26,288:INFO:Uploading results into container
2025-05-27 23:52:26,289:INFO:Uploading model into container now
2025-05-27 23:52:26,289:INFO:_master_model_container: 6
2025-05-27 23:52:26,289:INFO:_display_container: 2
2025-05-27 23:52:26,289:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=210, solver='auto',
                tol=0.0001)
2025-05-27 23:52:26,290:INFO:create_model() successfully completed......................................
2025-05-27 23:52:26,438:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:26,438:INFO:Creating metrics dataframe
2025-05-27 23:52:26,446:INFO:Initializing Random Forest Classifier
2025-05-27 23:52:26,447:INFO:Total runtime is 0.14591248035430907 minutes
2025-05-27 23:52:26,447:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:26,447:INFO:Initializing create_model()
2025-05-27 23:52:26,447:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=rf, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:26,448:INFO:Checking exceptions
2025-05-27 23:52:26,448:INFO:Importing libraries
2025-05-27 23:52:26,448:INFO:Copying training dataset
2025-05-27 23:52:26,458:INFO:Defining folds
2025-05-27 23:52:26,458:INFO:Declaring metric variables
2025-05-27 23:52:26,458:INFO:Importing untrained model
2025-05-27 23:52:26,459:INFO:Random Forest Classifier Imported successfully
2025-05-27 23:52:26,459:INFO:Starting cross validation
2025-05-27 23:52:26,462:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:26,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,980:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:26,986:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,479:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,989:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,993:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:27,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:28,554:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:28,561:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:28,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,086:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,092:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,097:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,105:INFO:Calculating mean and std
2025-05-27 23:52:29,105:INFO:Creating metrics dataframe
2025-05-27 23:52:29,107:INFO:Uploading results into container
2025-05-27 23:52:29,108:INFO:Uploading model into container now
2025-05-27 23:52:29,108:INFO:_master_model_container: 7
2025-05-27 23:52:29,108:INFO:_display_container: 2
2025-05-27 23:52:29,108:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=2,
                       oob_score=False, random_state=210, verbose=0,
                       warm_start=False)
2025-05-27 23:52:29,108:INFO:create_model() successfully completed......................................
2025-05-27 23:52:29,239:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:29,239:INFO:Creating metrics dataframe
2025-05-27 23:52:29,244:INFO:Initializing Quadratic Discriminant Analysis
2025-05-27 23:52:29,244:INFO:Total runtime is 0.1925344387690226 minutes
2025-05-27 23:52:29,245:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:29,245:INFO:Initializing create_model()
2025-05-27 23:52:29,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=qda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:29,245:INFO:Checking exceptions
2025-05-27 23:52:29,245:INFO:Importing libraries
2025-05-27 23:52:29,245:INFO:Copying training dataset
2025-05-27 23:52:29,253:INFO:Defining folds
2025-05-27 23:52:29,253:INFO:Declaring metric variables
2025-05-27 23:52:29,253:INFO:Importing untrained model
2025-05-27 23:52:29,254:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-27 23:52:29,254:INFO:Starting cross validation
2025-05-27 23:52:29,256:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:29,382:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 23:52:29,477:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:29,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,487:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,608:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 23:52:29,703:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:29,707:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,713:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,717:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,835:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 23:52:29,943:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:29,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,950:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:29,956:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,086:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 23:52:30,181:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:30,186:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,191:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,195:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,315:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-27 23:52:30,416:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:30,419:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,424:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:30,437:INFO:Calculating mean and std
2025-05-27 23:52:30,437:INFO:Creating metrics dataframe
2025-05-27 23:52:30,441:INFO:Uploading results into container
2025-05-27 23:52:30,441:INFO:Uploading model into container now
2025-05-27 23:52:30,441:INFO:_master_model_container: 8
2025-05-27 23:52:30,442:INFO:_display_container: 2
2025-05-27 23:52:30,442:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-27 23:52:30,442:INFO:create_model() successfully completed......................................
2025-05-27 23:52:30,582:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:30,583:INFO:Creating metrics dataframe
2025-05-27 23:52:30,587:INFO:Initializing Ada Boost Classifier
2025-05-27 23:52:30,587:INFO:Total runtime is 0.2149154225985209 minutes
2025-05-27 23:52:30,587:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:30,587:INFO:Initializing create_model()
2025-05-27 23:52:30,587:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=ada, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:30,587:INFO:Checking exceptions
2025-05-27 23:52:30,588:INFO:Importing libraries
2025-05-27 23:52:30,588:INFO:Copying training dataset
2025-05-27 23:52:30,594:INFO:Defining folds
2025-05-27 23:52:30,594:INFO:Declaring metric variables
2025-05-27 23:52:30,594:INFO:Importing untrained model
2025-05-27 23:52:30,594:INFO:Ada Boost Classifier Imported successfully
2025-05-27 23:52:30,595:INFO:Starting cross validation
2025-05-27 23:52:30,597:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:30,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 23:52:31,029:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:31,031:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,035:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,039:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,154:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 23:52:31,351:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:31,353:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,357:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,361:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,478:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 23:52:31,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:31,674:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,678:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,682:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:31,800:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 23:52:32,026:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:32,033:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,040:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,047:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,209:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-27 23:52:32,482:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:32,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:32,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:32,503:INFO:Calculating mean and std
2025-05-27 23:52:32,503:INFO:Creating metrics dataframe
2025-05-27 23:52:32,505:INFO:Uploading results into container
2025-05-27 23:52:32,506:INFO:Uploading model into container now
2025-05-27 23:52:32,506:INFO:_master_model_container: 9
2025-05-27 23:52:32,506:INFO:_display_container: 2
2025-05-27 23:52:32,506:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=210)
2025-05-27 23:52:32,506:INFO:create_model() successfully completed......................................
2025-05-27 23:52:32,644:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:32,645:INFO:Creating metrics dataframe
2025-05-27 23:52:32,651:INFO:Initializing Gradient Boosting Classifier
2025-05-27 23:52:32,651:INFO:Total runtime is 0.24932094415028888 minutes
2025-05-27 23:52:32,651:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:32,652:INFO:Initializing create_model()
2025-05-27 23:52:32,652:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=gbc, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:32,652:INFO:Checking exceptions
2025-05-27 23:52:32,652:INFO:Importing libraries
2025-05-27 23:52:32,652:INFO:Copying training dataset
2025-05-27 23:52:32,659:INFO:Defining folds
2025-05-27 23:52:32,659:INFO:Declaring metric variables
2025-05-27 23:52:32,660:INFO:Importing untrained model
2025-05-27 23:52:32,660:INFO:Gradient Boosting Classifier Imported successfully
2025-05-27 23:52:32,660:INFO:Starting cross validation
2025-05-27 23:52:32,664:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:34,406:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:34,409:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:34,413:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:34,417:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:36,124:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:36,126:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:36,130:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:36,134:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:37,847:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:37,849:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:37,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:37,858:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:39,784:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:39,787:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:39,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:39,795:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:41,611:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:41,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:41,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:41,623:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:41,633:INFO:Calculating mean and std
2025-05-27 23:52:41,633:INFO:Creating metrics dataframe
2025-05-27 23:52:41,635:INFO:Uploading results into container
2025-05-27 23:52:41,636:INFO:Uploading model into container now
2025-05-27 23:52:41,636:INFO:_master_model_container: 10
2025-05-27 23:52:41,636:INFO:_display_container: 2
2025-05-27 23:52:41,637:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-27 23:52:41,637:INFO:create_model() successfully completed......................................
2025-05-27 23:52:41,790:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:41,790:INFO:Creating metrics dataframe
2025-05-27 23:52:41,796:INFO:Initializing Linear Discriminant Analysis
2025-05-27 23:52:41,796:INFO:Total runtime is 0.4017335216204325 minutes
2025-05-27 23:52:41,796:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:41,797:INFO:Initializing create_model()
2025-05-27 23:52:41,797:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=lda, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:41,797:INFO:Checking exceptions
2025-05-27 23:52:41,797:INFO:Importing libraries
2025-05-27 23:52:41,797:INFO:Copying training dataset
2025-05-27 23:52:41,805:INFO:Defining folds
2025-05-27 23:52:41,805:INFO:Declaring metric variables
2025-05-27 23:52:41,805:INFO:Importing untrained model
2025-05-27 23:52:41,806:INFO:Linear Discriminant Analysis Imported successfully
2025-05-27 23:52:41,806:INFO:Starting cross validation
2025-05-27 23:52:41,808:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:42,046:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:42,049:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,058:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,062:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,294:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:42,296:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,301:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,305:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,539:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:42,542:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,546:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,551:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,774:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:42,777:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,782:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:42,786:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-27 23:52:43,019:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,023:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,027:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,035:INFO:Calculating mean and std
2025-05-27 23:52:43,036:INFO:Creating metrics dataframe
2025-05-27 23:52:43,038:INFO:Uploading results into container
2025-05-27 23:52:43,038:INFO:Uploading model into container now
2025-05-27 23:52:43,038:INFO:_master_model_container: 11
2025-05-27 23:52:43,038:INFO:_display_container: 2
2025-05-27 23:52:43,039:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-27 23:52:43,039:INFO:create_model() successfully completed......................................
2025-05-27 23:52:43,196:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:43,196:INFO:Creating metrics dataframe
2025-05-27 23:52:43,201:INFO:Initializing Extra Trees Classifier
2025-05-27 23:52:43,201:INFO:Total runtime is 0.42514652411142984 minutes
2025-05-27 23:52:43,201:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:43,201:INFO:Initializing create_model()
2025-05-27 23:52:43,201:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=et, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:43,201:INFO:Checking exceptions
2025-05-27 23:52:43,202:INFO:Importing libraries
2025-05-27 23:52:43,202:INFO:Copying training dataset
2025-05-27 23:52:43,210:INFO:Defining folds
2025-05-27 23:52:43,210:INFO:Declaring metric variables
2025-05-27 23:52:43,210:INFO:Importing untrained model
2025-05-27 23:52:43,211:INFO:Extra Trees Classifier Imported successfully
2025-05-27 23:52:43,211:INFO:Starting cross validation
2025-05-27 23:52:43,215:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:43,663:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,672:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:43,677:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,116:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,121:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,582:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:44,588:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,019:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,023:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:45,575:INFO:Calculating mean and std
2025-05-27 23:52:45,576:INFO:Creating metrics dataframe
2025-05-27 23:52:45,578:INFO:Uploading results into container
2025-05-27 23:52:45,579:INFO:Uploading model into container now
2025-05-27 23:52:45,579:INFO:_master_model_container: 12
2025-05-27 23:52:45,579:INFO:_display_container: 2
2025-05-27 23:52:45,580:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=2,
                     oob_score=False, random_state=210, verbose=0,
                     warm_start=False)
2025-05-27 23:52:45,580:INFO:create_model() successfully completed......................................
2025-05-27 23:52:45,712:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:45,712:INFO:Creating metrics dataframe
2025-05-27 23:52:45,719:INFO:Initializing Light Gradient Boosting Machine
2025-05-27 23:52:45,719:INFO:Total runtime is 0.46711848974227904 minutes
2025-05-27 23:52:45,719:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:45,720:INFO:Initializing create_model()
2025-05-27 23:52:45,720:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:45,720:INFO:Checking exceptions
2025-05-27 23:52:45,720:INFO:Importing libraries
2025-05-27 23:52:45,720:INFO:Copying training dataset
2025-05-27 23:52:45,726:INFO:Defining folds
2025-05-27 23:52:45,726:INFO:Declaring metric variables
2025-05-27 23:52:45,727:INFO:Importing untrained model
2025-05-27 23:52:45,728:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 23:52:45,728:INFO:Starting cross validation
2025-05-27 23:52:45,731:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:45,857:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:45,857:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:45,857:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 22
2025-05-27 23:52:45,910:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:45,910:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:45,921:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:45,923:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:45,923:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000310 secs. 1 sparse feature groups
2025-05-27 23:52:45,923:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 23:52:45,923:INFO:[LightGBM] [Info] Start training from score -2.182399
2025-05-27 23:52:45,924:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 23:52:45,924:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 23:52:45,924:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 23:52:47,141:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:47,145:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:47,150:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:47,281:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:47,282:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:47,282:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 22
2025-05-27 23:52:47,323:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:47,323:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:47,333:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:47,334:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:47,334:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000287 secs. 1 sparse feature groups
2025-05-27 23:52:47,335:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 23:52:47,335:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 23:52:47,335:INFO:[LightGBM] [Info] Start training from score -1.806051
2025-05-27 23:52:47,335:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 23:52:47,335:INFO:[LightGBM] [Info] Start training from score -0.682007
2025-05-27 23:52:48,577:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:48,581:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:48,585:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:48,713:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:48,713:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:48,713:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 22
2025-05-27 23:52:48,756:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:48,756:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:48,766:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:48,768:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:48,768:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000299 secs. 1 sparse feature groups
2025-05-27 23:52:48,768:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 23:52:48,768:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 23:52:48,769:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 23:52:48,769:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 23:52:48,769:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 23:52:49,963:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:49,967:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:49,971:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:50,096:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:50,097:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:50,097:INFO:[LightGBM] [Info] Number of data points in the train set: 1339, number of used features: 22
2025-05-27 23:52:50,141:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:50,141:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:50,151:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:50,153:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:50,153:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000275 secs. 1 sparse feature groups
2025-05-27 23:52:50,153:INFO:[LightGBM] [Info] Start training from score -3.105334
2025-05-27 23:52:50,153:INFO:[LightGBM] [Info] Start training from score -2.189043
2025-05-27 23:52:50,153:INFO:[LightGBM] [Info] Start training from score -1.810607
2025-05-27 23:52:50,154:INFO:[LightGBM] [Info] Start training from score -1.752941
2025-05-27 23:52:50,154:INFO:[LightGBM] [Info] Start training from score -0.680531
2025-05-27 23:52:51,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:51,351:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:51,355:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:51,480:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:51,481:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:51,481:INFO:[LightGBM] [Info] Number of data points in the train set: 1340, number of used features: 22
2025-05-27 23:52:51,527:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:51,528:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:51,537:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:51,538:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:51,539:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000295 secs. 1 sparse feature groups
2025-05-27 23:52:51,539:INFO:[LightGBM] [Info] Start training from score -3.106080
2025-05-27 23:52:51,539:INFO:[LightGBM] [Info] Start training from score -2.183145
2025-05-27 23:52:51,539:INFO:[LightGBM] [Info] Start training from score -1.811353
2025-05-27 23:52:51,539:INFO:[LightGBM] [Info] Start training from score -1.753688
2025-05-27 23:52:51,540:INFO:[LightGBM] [Info] Start training from score -0.681278
2025-05-27 23:52:52,798:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:52,802:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:52,807:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:52,814:INFO:Calculating mean and std
2025-05-27 23:52:52,814:INFO:Creating metrics dataframe
2025-05-27 23:52:52,816:INFO:Uploading results into container
2025-05-27 23:52:52,817:INFO:Uploading model into container now
2025-05-27 23:52:52,817:INFO:_master_model_container: 13
2025-05-27 23:52:52,817:INFO:_display_container: 2
2025-05-27 23:52:52,818:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-27 23:52:52,818:INFO:create_model() successfully completed......................................
2025-05-27 23:52:52,951:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:52,952:INFO:Creating metrics dataframe
2025-05-27 23:52:52,956:INFO:Initializing Dummy Classifier
2025-05-27 23:52:52,956:INFO:Total runtime is 0.5877320329348246 minutes
2025-05-27 23:52:52,956:INFO:SubProcess create_model() called ==================================
2025-05-27 23:52:52,956:INFO:Initializing create_model()
2025-05-27 23:52:52,956:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=dummy, fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7f94bc2f7e80>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:52,956:INFO:Checking exceptions
2025-05-27 23:52:52,957:INFO:Importing libraries
2025-05-27 23:52:52,957:INFO:Copying training dataset
2025-05-27 23:52:52,963:INFO:Defining folds
2025-05-27 23:52:52,963:INFO:Declaring metric variables
2025-05-27 23:52:52,963:INFO:Importing untrained model
2025-05-27 23:52:52,964:INFO:Dummy Classifier Imported successfully
2025-05-27 23:52:52,964:INFO:Starting cross validation
2025-05-27 23:52:52,966:INFO:Cross validating with StratifiedKFold(n_splits=5, random_state=None, shuffle=False), n_jobs=1
2025-05-27 23:52:53,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,152:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,155:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:53,157:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,344:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:53,347:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,521:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,525:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,527:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:53,529:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,699:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,704:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,706:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:53,708:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,910:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,914:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-27 23:52:53,919:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to '4') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-27 23:52:53,925:INFO:Calculating mean and std
2025-05-27 23:52:53,926:INFO:Creating metrics dataframe
2025-05-27 23:52:53,928:INFO:Uploading results into container
2025-05-27 23:52:53,928:INFO:Uploading model into container now
2025-05-27 23:52:53,929:INFO:_master_model_container: 14
2025-05-27 23:52:53,929:INFO:_display_container: 2
2025-05-27 23:52:53,929:INFO:DummyClassifier(constant=None, random_state=210, strategy='prior')
2025-05-27 23:52:53,929:INFO:create_model() successfully completed......................................
2025-05-27 23:52:54,044:INFO:SubProcess create_model() end ==================================
2025-05-27 23:52:54,044:INFO:Creating metrics dataframe
2025-05-27 23:52:54,050:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-05-27 23:52:54,052:INFO:Initializing create_model()
2025-05-27 23:52:54,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95c497bf10>, estimator=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), fold=StratifiedKFold(n_splits=5, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-27 23:52:54,053:INFO:Checking exceptions
2025-05-27 23:52:54,054:INFO:Importing libraries
2025-05-27 23:52:54,054:INFO:Copying training dataset
2025-05-27 23:52:54,063:INFO:Defining folds
2025-05-27 23:52:54,063:INFO:Declaring metric variables
2025-05-27 23:52:54,064:INFO:Importing untrained model
2025-05-27 23:52:54,064:INFO:Declaring custom model
2025-05-27 23:52:54,065:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-27 23:52:54,068:INFO:Cross validation set to False
2025-05-27 23:52:54,068:INFO:Fitting Model
2025-05-27 23:52:54,196:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-27 23:52:54,196:INFO:[LightGBM] [Info] Total Bins 581
2025-05-27 23:52:54,196:INFO:[LightGBM] [Info] Number of data points in the train set: 1674, number of used features: 22
2025-05-27 23:52:54,238:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-27 23:52:54,238:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-27 23:52:54,247:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-27 23:52:54,249:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-27 23:52:54,249:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000292 secs. 1 sparse feature groups
2025-05-27 23:52:54,249:INFO:[LightGBM] [Info] Start training from score -3.105483
2025-05-27 23:52:54,249:INFO:[LightGBM] [Info] Start training from score -2.186529
2025-05-27 23:52:54,249:INFO:[LightGBM] [Info] Start training from score -1.809843
2025-05-27 23:52:54,250:INFO:[LightGBM] [Info] Start training from score -1.753090
2025-05-27 23:52:54,250:INFO:[LightGBM] [Info] Start training from score -0.681271
2025-05-27 23:52:55,434:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-27 23:52:55,434:INFO:create_model() successfully completed......................................
2025-05-27 23:52:55,566:INFO:_master_model_container: 14
2025-05-27 23:52:55,566:INFO:_display_container: 2
2025-05-27 23:52:55,567:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-27 23:52:55,567:INFO:compare_models() successfully completed......................................
2025-05-27 23:52:55,659:INFO:Initializing save_model()
2025-05-27 23:52:55,659:INFO:save_model(model=LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=2, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences', 'GPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_feat...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-27 23:52:55,659:INFO:Adding model into prep_pipe
2025-05-27 23:52:55,726:INFO:student_performance_model.pkl saved in current working directory
2025-05-27 23:52:55,817:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences', 'GPA'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                 LGBMClassifier(boosting_type='gbdt', class_weight=None,
                                colsample_bytree=1.0, device='gpu',
                                importance_type='split', learning_rate=0.1,
                                max_depth=-1, min_child_samples=20,
                                min_child_weight=0.001, min_split_gain=0.0,
                                n_estimators=100, n_jobs=2, num_leaves=31,
                                objective=None, random_state=210, reg_alpha=0.0,
                                reg_lambda=0.0, subsample=1.0,
                                subsample_for_bin=200000, subsample_freq=0))],
         verbose=False)
2025-05-27 23:52:55,817:INFO:save_model() successfully completed......................................
2025-05-28 00:01:26,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:26,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:26,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:26,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:26,734:INFO:PyCaret ClassificationExperiment
2025-05-28 00:01:26,734:INFO:Logging name: clf-default-name
2025-05-28 00:01:26,734:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-28 00:01:26,734:INFO:version 3.3.2
2025-05-28 00:01:26,734:INFO:Initializing setup()
2025-05-28 00:01:26,735:INFO:self.USI: c3cf
2025-05-28 00:01:26,735:INFO:self._variable_keys: {'seed', 'USI', 'gpu_n_jobs_param', 'html_param', 'exp_id', 'X_train', '_ml_usecase', 'X_test', 'fold_shuffle_param', 'idx', 'log_plots_param', 'y_test', 'is_multiclass', 'y', 'target_param', 'exp_name_log', '_available_plots', 'logging_param', 'X', 'fold_generator', 'data', 'n_jobs_param', 'gpu_param', 'fix_imbalance', 'pipeline', 'fold_groups_param', 'memory', 'y_train'}
2025-05-28 00:01:26,735:INFO:Checking environment
2025-05-28 00:01:26,735:INFO:python_version: 3.10.17
2025-05-28 00:01:26,735:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-28 00:01:26,735:INFO:machine: x86_64
2025-05-28 00:01:26,737:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:01:26,737:INFO:Memory: svmem(total=16407515136, available=7416852480, percent=54.8, used=7507058688, free=1518338048, active=1856913408, inactive=11496046592, buffers=221745152, cached=7160373248, shared=1133961216, slab=705290240)
2025-05-28 00:01:26,737:INFO:Physical Core: 4
2025-05-28 00:01:26,738:INFO:Logical Core: 8
2025-05-28 00:01:26,738:INFO:Checking libraries
2025-05-28 00:01:26,738:INFO:System:
2025-05-28 00:01:26,738:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-28 00:01:26,738:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-28 00:01:26,738:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:01:26,738:INFO:PyCaret required dependencies:
2025-05-28 00:01:26,758:INFO:                 pip: 25.1.1
2025-05-28 00:01:26,758:INFO:          setuptools: 65.5.0
2025-05-28 00:01:26,758:INFO:             pycaret: 3.3.2
2025-05-28 00:01:26,758:INFO:             IPython: 8.36.0
2025-05-28 00:01:26,758:INFO:          ipywidgets: 8.1.7
2025-05-28 00:01:26,758:INFO:                tqdm: 4.67.1
2025-05-28 00:01:26,758:INFO:               numpy: 1.26.4
2025-05-28 00:01:26,758:INFO:              pandas: 2.1.4
2025-05-28 00:01:26,758:INFO:              jinja2: 3.1.6
2025-05-28 00:01:26,758:INFO:               scipy: 1.11.4
2025-05-28 00:01:26,758:INFO:              joblib: 1.3.2
2025-05-28 00:01:26,758:INFO:             sklearn: 1.4.2
2025-05-28 00:01:26,758:INFO:                pyod: 2.0.5
2025-05-28 00:01:26,758:INFO:            imblearn: 0.13.0
2025-05-28 00:01:26,759:INFO:   category_encoders: 2.6.2
2025-05-28 00:01:26,759:INFO:            lightgbm: 4.6.0
2025-05-28 00:01:26,759:INFO:               numba: 0.61.2
2025-05-28 00:01:26,759:INFO:            requests: 2.32.3
2025-05-28 00:01:26,759:INFO:          matplotlib: 3.7.5
2025-05-28 00:01:26,759:INFO:          scikitplot: 0.3.7
2025-05-28 00:01:26,759:INFO:         yellowbrick: 1.5
2025-05-28 00:01:26,759:INFO:              plotly: 5.24.1
2025-05-28 00:01:26,759:INFO:    plotly-resampler: Not installed
2025-05-28 00:01:26,759:INFO:             kaleido: 0.2.1
2025-05-28 00:01:26,759:INFO:           schemdraw: 0.15
2025-05-28 00:01:26,759:INFO:         statsmodels: 0.14.4
2025-05-28 00:01:26,759:INFO:              sktime: 0.26.0
2025-05-28 00:01:26,759:INFO:               tbats: 1.1.3
2025-05-28 00:01:26,759:INFO:            pmdarima: 2.0.4
2025-05-28 00:01:26,759:INFO:              psutil: 7.0.0
2025-05-28 00:01:26,759:INFO:          markupsafe: 3.0.2
2025-05-28 00:01:26,759:INFO:             pickle5: Not installed
2025-05-28 00:01:26,759:INFO:         cloudpickle: 3.1.1
2025-05-28 00:01:26,759:INFO:         deprecation: 2.1.0
2025-05-28 00:01:26,759:INFO:              xxhash: 3.5.0
2025-05-28 00:01:26,759:INFO:           wurlitzer: 3.1.1
2025-05-28 00:01:26,759:INFO:PyCaret optional dependencies:
2025-05-28 00:01:27,156:INFO:                shap: Not installed
2025-05-28 00:01:27,156:INFO:           interpret: Not installed
2025-05-28 00:01:27,156:INFO:                umap: Not installed
2025-05-28 00:01:27,156:INFO:     ydata_profiling: Not installed
2025-05-28 00:01:27,156:INFO:  explainerdashboard: Not installed
2025-05-28 00:01:27,156:INFO:             autoviz: Not installed
2025-05-28 00:01:27,156:INFO:           fairlearn: Not installed
2025-05-28 00:01:27,156:INFO:          deepchecks: Not installed
2025-05-28 00:01:27,156:INFO:             xgboost: Not installed
2025-05-28 00:01:27,156:INFO:            catboost: Not installed
2025-05-28 00:01:27,156:INFO:              kmodes: Not installed
2025-05-28 00:01:27,156:INFO:             mlxtend: Not installed
2025-05-28 00:01:27,156:INFO:       statsforecast: Not installed
2025-05-28 00:01:27,156:INFO:        tune_sklearn: Not installed
2025-05-28 00:01:27,156:INFO:                 ray: Not installed
2025-05-28 00:01:27,156:INFO:            hyperopt: Not installed
2025-05-28 00:01:27,157:INFO:              optuna: Not installed
2025-05-28 00:01:27,157:INFO:               skopt: Not installed
2025-05-28 00:01:27,157:INFO:              mlflow: Not installed
2025-05-28 00:01:27,157:INFO:              gradio: Not installed
2025-05-28 00:01:27,157:INFO:             fastapi: 0.115.12
2025-05-28 00:01:27,157:INFO:             uvicorn: 0.34.2
2025-05-28 00:01:27,157:INFO:              m2cgen: Not installed
2025-05-28 00:01:27,157:INFO:           evidently: Not installed
2025-05-28 00:01:27,157:INFO:               fugue: Not installed
2025-05-28 00:01:27,157:INFO:           streamlit: Not installed
2025-05-28 00:01:27,157:INFO:             prophet: Not installed
2025-05-28 00:01:27,157:INFO:None
2025-05-28 00:01:27,157:INFO:Set up GPU usage.
2025-05-28 00:01:27,157:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:27,157:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-28 00:01:27,157:INFO:Set up data.
2025-05-28 00:01:27,167:INFO:Set up folding strategy.
2025-05-28 00:01:27,168:INFO:Set up train/test split.
2025-05-28 00:01:27,182:INFO:Set up index.
2025-05-28 00:01:27,183:INFO:Assigning column types.
2025-05-28 00:01:57,444:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:57,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:57,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:57,445:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:58,084:INFO:PyCaret ClassificationExperiment
2025-05-28 00:01:58,085:INFO:Logging name: clf-default-name
2025-05-28 00:01:58,085:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-28 00:01:58,085:INFO:version 3.3.2
2025-05-28 00:01:58,085:INFO:Initializing setup()
2025-05-28 00:01:58,085:INFO:self.USI: 769a
2025-05-28 00:01:58,085:INFO:self._variable_keys: {'gpu_n_jobs_param', 'fold_generator', 'idx', '_ml_usecase', 'log_plots_param', 'memory', 'n_jobs_param', 'X_test', 'logging_param', 'y_train', 'exp_id', 'fold_groups_param', 'is_multiclass', 'seed', 'fold_shuffle_param', 'data', 'USI', '_available_plots', 'y_test', 'gpu_param', 'exp_name_log', 'html_param', 'X', 'X_train', 'fix_imbalance', 'target_param', 'pipeline', 'y'}
2025-05-28 00:01:58,085:INFO:Checking environment
2025-05-28 00:01:58,085:INFO:python_version: 3.10.17
2025-05-28 00:01:58,085:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-28 00:01:58,085:INFO:machine: x86_64
2025-05-28 00:01:58,087:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:01:58,087:INFO:Memory: svmem(total=16407515136, available=7422763008, percent=54.8, used=7548379136, free=1516691456, active=1875128320, inactive=11515162624, buffers=221884416, cached=7120560128, shared=1086730240, slab=705380352)
2025-05-28 00:01:58,088:INFO:Physical Core: 4
2025-05-28 00:01:58,088:INFO:Logical Core: 8
2025-05-28 00:01:58,088:INFO:Checking libraries
2025-05-28 00:01:58,088:INFO:System:
2025-05-28 00:01:58,088:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-28 00:01:58,088:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-28 00:01:58,088:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:01:58,089:INFO:PyCaret required dependencies:
2025-05-28 00:01:58,109:INFO:                 pip: 25.1.1
2025-05-28 00:01:58,109:INFO:          setuptools: 65.5.0
2025-05-28 00:01:58,110:INFO:             pycaret: 3.3.2
2025-05-28 00:01:58,110:INFO:             IPython: 8.36.0
2025-05-28 00:01:58,110:INFO:          ipywidgets: 8.1.7
2025-05-28 00:01:58,110:INFO:                tqdm: 4.67.1
2025-05-28 00:01:58,110:INFO:               numpy: 1.26.4
2025-05-28 00:01:58,110:INFO:              pandas: 2.1.4
2025-05-28 00:01:58,110:INFO:              jinja2: 3.1.6
2025-05-28 00:01:58,110:INFO:               scipy: 1.11.4
2025-05-28 00:01:58,110:INFO:              joblib: 1.3.2
2025-05-28 00:01:58,110:INFO:             sklearn: 1.4.2
2025-05-28 00:01:58,110:INFO:                pyod: 2.0.5
2025-05-28 00:01:58,110:INFO:            imblearn: 0.13.0
2025-05-28 00:01:58,110:INFO:   category_encoders: 2.6.2
2025-05-28 00:01:58,110:INFO:            lightgbm: 4.6.0
2025-05-28 00:01:58,110:INFO:               numba: 0.61.2
2025-05-28 00:01:58,110:INFO:            requests: 2.32.3
2025-05-28 00:01:58,110:INFO:          matplotlib: 3.7.5
2025-05-28 00:01:58,110:INFO:          scikitplot: 0.3.7
2025-05-28 00:01:58,110:INFO:         yellowbrick: 1.5
2025-05-28 00:01:58,111:INFO:              plotly: 5.24.1
2025-05-28 00:01:58,111:INFO:    plotly-resampler: Not installed
2025-05-28 00:01:58,111:INFO:             kaleido: 0.2.1
2025-05-28 00:01:58,111:INFO:           schemdraw: 0.15
2025-05-28 00:01:58,111:INFO:         statsmodels: 0.14.4
2025-05-28 00:01:58,111:INFO:              sktime: 0.26.0
2025-05-28 00:01:58,111:INFO:               tbats: 1.1.3
2025-05-28 00:01:58,111:INFO:            pmdarima: 2.0.4
2025-05-28 00:01:58,111:INFO:              psutil: 7.0.0
2025-05-28 00:01:58,111:INFO:          markupsafe: 3.0.2
2025-05-28 00:01:58,111:INFO:             pickle5: Not installed
2025-05-28 00:01:58,111:INFO:         cloudpickle: 3.1.1
2025-05-28 00:01:58,111:INFO:         deprecation: 2.1.0
2025-05-28 00:01:58,111:INFO:              xxhash: 3.5.0
2025-05-28 00:01:58,111:INFO:           wurlitzer: 3.1.1
2025-05-28 00:01:58,111:INFO:PyCaret optional dependencies:
2025-05-28 00:01:58,429:INFO:                shap: Not installed
2025-05-28 00:01:58,429:INFO:           interpret: Not installed
2025-05-28 00:01:58,429:INFO:                umap: Not installed
2025-05-28 00:01:58,429:INFO:     ydata_profiling: Not installed
2025-05-28 00:01:58,429:INFO:  explainerdashboard: Not installed
2025-05-28 00:01:58,429:INFO:             autoviz: Not installed
2025-05-28 00:01:58,429:INFO:           fairlearn: Not installed
2025-05-28 00:01:58,429:INFO:          deepchecks: Not installed
2025-05-28 00:01:58,430:INFO:             xgboost: Not installed
2025-05-28 00:01:58,430:INFO:            catboost: Not installed
2025-05-28 00:01:58,430:INFO:              kmodes: Not installed
2025-05-28 00:01:58,430:INFO:             mlxtend: Not installed
2025-05-28 00:01:58,430:INFO:       statsforecast: Not installed
2025-05-28 00:01:58,430:INFO:        tune_sklearn: Not installed
2025-05-28 00:01:58,430:INFO:                 ray: Not installed
2025-05-28 00:01:58,430:INFO:            hyperopt: Not installed
2025-05-28 00:01:58,430:INFO:              optuna: Not installed
2025-05-28 00:01:58,430:INFO:               skopt: Not installed
2025-05-28 00:01:58,430:INFO:              mlflow: Not installed
2025-05-28 00:01:58,430:INFO:              gradio: Not installed
2025-05-28 00:01:58,430:INFO:             fastapi: 0.115.12
2025-05-28 00:01:58,430:INFO:             uvicorn: 0.34.2
2025-05-28 00:01:58,430:INFO:              m2cgen: Not installed
2025-05-28 00:01:58,430:INFO:           evidently: Not installed
2025-05-28 00:01:58,430:INFO:               fugue: Not installed
2025-05-28 00:01:58,430:INFO:           streamlit: Not installed
2025-05-28 00:01:58,430:INFO:             prophet: Not installed
2025-05-28 00:01:58,430:INFO:None
2025-05-28 00:01:58,430:INFO:Set up GPU usage.
2025-05-28 00:01:58,430:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:01:58,430:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-28 00:01:58,430:INFO:Set up data.
2025-05-28 00:01:58,437:INFO:Set up folding strategy.
2025-05-28 00:01:58,437:INFO:Set up train/test split.
2025-05-28 00:01:58,446:INFO:Set up index.
2025-05-28 00:01:58,446:INFO:Assigning column types.
2025-05-28 00:04:28,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:28,641:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:28,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:28,642:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,333:INFO:PyCaret ClassificationExperiment
2025-05-28 00:04:29,334:INFO:Logging name: clf-default-name
2025-05-28 00:04:29,334:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-05-28 00:04:29,334:INFO:version 3.3.2
2025-05-28 00:04:29,334:INFO:Initializing setup()
2025-05-28 00:04:29,334:INFO:self.USI: d226
2025-05-28 00:04:29,334:INFO:self._variable_keys: {'idx', 'fold_shuffle_param', 'data', 'y', 'n_jobs_param', 'html_param', 'fold_groups_param', 'logging_param', 'gpu_param', 'pipeline', '_ml_usecase', 'exp_name_log', 'is_multiclass', 'fold_generator', 'X', 'fix_imbalance', 'target_param', 'X_train', 'gpu_n_jobs_param', 'y_test', 'log_plots_param', 'seed', 'y_train', '_available_plots', 'X_test', 'memory', 'USI', 'exp_id'}
2025-05-28 00:04:29,334:INFO:Checking environment
2025-05-28 00:04:29,334:INFO:python_version: 3.10.17
2025-05-28 00:04:29,334:INFO:python_build: ('main', 'Apr  9 2025 08:54:15')
2025-05-28 00:04:29,334:INFO:machine: x86_64
2025-05-28 00:04:29,336:INFO:platform: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:04:29,336:INFO:Memory: svmem(total=16407515136, available=7328133120, percent=55.3, used=7612145664, free=1421070336, active=1876373504, inactive=11596124160, buffers=222482432, cached=7151816704, shared=1117593600, slab=705531904)
2025-05-28 00:04:29,337:INFO:Physical Core: 4
2025-05-28 00:04:29,337:INFO:Logical Core: 8
2025-05-28 00:04:29,337:INFO:Checking libraries
2025-05-28 00:04:29,337:INFO:System:
2025-05-28 00:04:29,337:INFO:    python: 3.10.17 (main, Apr  9 2025, 08:54:15) [GCC 9.4.0]
2025-05-28 00:04:29,337:INFO:executable: /home/hosam/Desktop/projects/software-school/pycaret-env/bin/python3.10
2025-05-28 00:04:29,338:INFO:   machine: Linux-5.15.0-139-generic-x86_64-with-glibc2.31
2025-05-28 00:04:29,338:INFO:PyCaret required dependencies:
2025-05-28 00:04:29,360:INFO:                 pip: 25.1.1
2025-05-28 00:04:29,360:INFO:          setuptools: 65.5.0
2025-05-28 00:04:29,360:INFO:             pycaret: 3.3.2
2025-05-28 00:04:29,360:INFO:             IPython: 8.36.0
2025-05-28 00:04:29,360:INFO:          ipywidgets: 8.1.7
2025-05-28 00:04:29,360:INFO:                tqdm: 4.67.1
2025-05-28 00:04:29,361:INFO:               numpy: 1.26.4
2025-05-28 00:04:29,361:INFO:              pandas: 2.1.4
2025-05-28 00:04:29,361:INFO:              jinja2: 3.1.6
2025-05-28 00:04:29,361:INFO:               scipy: 1.11.4
2025-05-28 00:04:29,361:INFO:              joblib: 1.3.2
2025-05-28 00:04:29,361:INFO:             sklearn: 1.4.2
2025-05-28 00:04:29,361:INFO:                pyod: 2.0.5
2025-05-28 00:04:29,361:INFO:            imblearn: 0.13.0
2025-05-28 00:04:29,361:INFO:   category_encoders: 2.6.2
2025-05-28 00:04:29,361:INFO:            lightgbm: 4.6.0
2025-05-28 00:04:29,361:INFO:               numba: 0.61.2
2025-05-28 00:04:29,361:INFO:            requests: 2.32.3
2025-05-28 00:04:29,361:INFO:          matplotlib: 3.7.5
2025-05-28 00:04:29,361:INFO:          scikitplot: 0.3.7
2025-05-28 00:04:29,361:INFO:         yellowbrick: 1.5
2025-05-28 00:04:29,362:INFO:              plotly: 5.24.1
2025-05-28 00:04:29,362:INFO:    plotly-resampler: Not installed
2025-05-28 00:04:29,362:INFO:             kaleido: 0.2.1
2025-05-28 00:04:29,362:INFO:           schemdraw: 0.15
2025-05-28 00:04:29,362:INFO:         statsmodels: 0.14.4
2025-05-28 00:04:29,362:INFO:              sktime: 0.26.0
2025-05-28 00:04:29,362:INFO:               tbats: 1.1.3
2025-05-28 00:04:29,362:INFO:            pmdarima: 2.0.4
2025-05-28 00:04:29,362:INFO:              psutil: 7.0.0
2025-05-28 00:04:29,362:INFO:          markupsafe: 3.0.2
2025-05-28 00:04:29,362:INFO:             pickle5: Not installed
2025-05-28 00:04:29,362:INFO:         cloudpickle: 3.1.1
2025-05-28 00:04:29,362:INFO:         deprecation: 2.1.0
2025-05-28 00:04:29,362:INFO:              xxhash: 3.5.0
2025-05-28 00:04:29,362:INFO:           wurlitzer: 3.1.1
2025-05-28 00:04:29,362:INFO:PyCaret optional dependencies:
2025-05-28 00:04:29,768:INFO:                shap: Not installed
2025-05-28 00:04:29,768:INFO:           interpret: Not installed
2025-05-28 00:04:29,768:INFO:                umap: Not installed
2025-05-28 00:04:29,768:INFO:     ydata_profiling: Not installed
2025-05-28 00:04:29,768:INFO:  explainerdashboard: Not installed
2025-05-28 00:04:29,768:INFO:             autoviz: Not installed
2025-05-28 00:04:29,768:INFO:           fairlearn: Not installed
2025-05-28 00:04:29,768:INFO:          deepchecks: Not installed
2025-05-28 00:04:29,768:INFO:             xgboost: Not installed
2025-05-28 00:04:29,768:INFO:            catboost: Not installed
2025-05-28 00:04:29,768:INFO:              kmodes: Not installed
2025-05-28 00:04:29,768:INFO:             mlxtend: Not installed
2025-05-28 00:04:29,768:INFO:       statsforecast: Not installed
2025-05-28 00:04:29,768:INFO:        tune_sklearn: Not installed
2025-05-28 00:04:29,768:INFO:                 ray: Not installed
2025-05-28 00:04:29,769:INFO:            hyperopt: Not installed
2025-05-28 00:04:29,769:INFO:              optuna: Not installed
2025-05-28 00:04:29,769:INFO:               skopt: Not installed
2025-05-28 00:04:29,769:INFO:              mlflow: Not installed
2025-05-28 00:04:29,769:INFO:              gradio: Not installed
2025-05-28 00:04:29,769:INFO:             fastapi: 0.115.12
2025-05-28 00:04:29,769:INFO:             uvicorn: 0.34.2
2025-05-28 00:04:29,769:INFO:              m2cgen: Not installed
2025-05-28 00:04:29,769:INFO:           evidently: Not installed
2025-05-28 00:04:29,769:INFO:               fugue: Not installed
2025-05-28 00:04:29,769:INFO:           streamlit: Not installed
2025-05-28 00:04:29,769:INFO:             prophet: Not installed
2025-05-28 00:04:29,769:INFO:None
2025-05-28 00:04:29,769:INFO:Set up GPU usage.
2025-05-28 00:04:29,769:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,770:WARNING:cuML is outdated or not found. Required version is >=23.08.
                Please visit https://rapids.ai/install for installation instructions.
2025-05-28 00:04:29,770:INFO:Set up data.
2025-05-28 00:04:29,779:INFO:Set up folding strategy.
2025-05-28 00:04:29,779:INFO:Set up train/test split.
2025-05-28 00:04:29,788:INFO:Set up index.
2025-05-28 00:04:29,788:INFO:Assigning column types.
2025-05-28 00:04:29,793:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-05-28 00:04:29,793:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,844:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-28 00:04:29,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,847:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,848:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-28 00:04:29,848:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,880:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:29,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,057:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,058:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,107:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-05-28 00:04:30,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,107:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,108:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-28 00:04:30,108:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,131:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,136:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,137:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,228:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-05-28 00:04:30,228:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,289:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-28 00:04:30,289:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,312:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,317:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,415:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,416:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,469:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,470:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-05-28 00:04:30,470:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,493:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,498:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,595:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-05-28 00:04:30,596:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,643:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,644:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,667:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,672:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,767:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,816:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,817:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,818:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,845:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:30,845:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,935:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:30,937:INFO:Preparing preprocessing pipeline...
2025-05-28 00:04:30,938:INFO:Set up label encoding.
2025-05-28 00:04:30,939:INFO:Set up simple imputation.
2025-05-28 00:04:30,944:INFO:Set up encoding of ordinal features.
2025-05-28 00:04:30,957:INFO:Set up encoding of categorical features.
2025-05-28 00:04:31,137:INFO:Finished creating preprocessing pipeline.
2025-05-28 00:04:31,244:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False)
2025-05-28 00:04:31,245:INFO:Creating final display dataframe.
2025-05-28 00:04:31,691:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                210
1                        Target                                         GradeClass
2                   Target type                                         Multiclass
3                Target mapping  excellent: 0, fail: 1, good: 2, pass: 3, very_...
4           Original data shape                                         (2392, 15)
5        Transformed data shape                                         (2392, 24)
6   Transformed train set shape                                         (1674, 24)
7    Transformed test set shape                                          (718, 24)
8               Ignore features                                                  2
9              Ordinal features                                                  2
10             Numeric features                                                  3
11         Categorical features                                                  9
12                   Preprocess                                               True
13              Imputation type                                             simple
14           Numeric imputation                                               mean
15       Categorical imputation                                               mode
16     Maximum one-hot encoding                                                 25
17              Encoding method                                               None
18               Fold Generator                                    StratifiedKFold
19                  Fold Number                                                 10
20                     CPU Jobs                                                 -1
21                      Use GPU                                               True
22               Log Experiment                                              False
23              Experiment Name                                   clf-default-name
24                          USI                                               d226
2025-05-28 00:04:31,691:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,740:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,741:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,763:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,768:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:31,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:31,856:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,904:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,905:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,906:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,928:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,933:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:04:31,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:32,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-05-28 00:04:32,051:INFO:setup() successfully completed in 2.72s...............
2025-05-28 00:04:32,051:INFO:Initializing compare_models()
2025-05-28 00:04:32,052:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-05-28 00:04:32,052:INFO:Checking exceptions
2025-05-28 00:04:32,057:INFO:Preparing display monitor
2025-05-28 00:04:32,064:INFO:Initializing Logistic Regression
2025-05-28 00:04:32,065:INFO:Total runtime is 3.4133593241373697e-06 minutes
2025-05-28 00:04:32,065:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:32,065:INFO:Initializing create_model()
2025-05-28 00:04:32,065:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:32,066:INFO:Checking exceptions
2025-05-28 00:04:32,066:INFO:Importing libraries
2025-05-28 00:04:32,066:INFO:Copying training dataset
2025-05-28 00:04:32,075:INFO:Defining folds
2025-05-28 00:04:32,075:INFO:Declaring metric variables
2025-05-28 00:04:32,076:INFO:Importing untrained model
2025-05-28 00:04:32,076:INFO:Logistic Regression Imported successfully
2025-05-28 00:04:32,077:INFO:Starting cross validation
2025-05-28 00:04:32,080:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:32,684:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-28 00:04:32,732:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:32,734:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:32,738:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:32,742:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:33,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:33,447:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:33,451:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:33,454:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,024:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:34,025:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,029:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,031:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:34,033:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:34,813:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:34,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:35,612:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:35,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:35,617:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:35,619:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:35,621:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,170:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:36,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,176:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,179:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:36,742:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:36,748:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:36,750:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,308:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:37,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,313:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,317:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,830:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:37,832:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,836:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:37,839:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:38,486:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,499:INFO:Calculating mean and std
2025-05-28 00:04:38,499:INFO:Creating metrics dataframe
2025-05-28 00:04:38,501:INFO:Uploading results into container
2025-05-28 00:04:38,501:INFO:Uploading model into container now
2025-05-28 00:04:38,502:INFO:_master_model_container: 1
2025-05-28 00:04:38,502:INFO:_display_container: 2
2025-05-28 00:04:38,502:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-28 00:04:38,502:INFO:create_model() successfully completed......................................
2025-05-28 00:04:38,618:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:38,618:INFO:Creating metrics dataframe
2025-05-28 00:04:38,622:INFO:Initializing K Neighbors Classifier
2025-05-28 00:04:38,622:INFO:Total runtime is 0.1092959960301717 minutes
2025-05-28 00:04:38,622:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:38,623:INFO:Initializing create_model()
2025-05-28 00:04:38,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:38,623:INFO:Checking exceptions
2025-05-28 00:04:38,623:INFO:Importing libraries
2025-05-28 00:04:38,623:INFO:Copying training dataset
2025-05-28 00:04:38,630:INFO:Defining folds
2025-05-28 00:04:38,630:INFO:Declaring metric variables
2025-05-28 00:04:38,630:INFO:Importing untrained model
2025-05-28 00:04:38,631:INFO:K Neighbors Classifier Imported successfully
2025-05-28 00:04:38,631:INFO:Starting cross validation
2025-05-28 00:04:38,634:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:38,848:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,852:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:38,855:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,034:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,037:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,041:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,221:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,226:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,230:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,410:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,414:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,418:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,599:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,608:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,803:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,807:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,991:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,995:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:39,999:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,183:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,187:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,190:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,370:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,377:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,568:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,576:INFO:Calculating mean and std
2025-05-28 00:04:40,577:INFO:Creating metrics dataframe
2025-05-28 00:04:40,579:INFO:Uploading results into container
2025-05-28 00:04:40,579:INFO:Uploading model into container now
2025-05-28 00:04:40,580:INFO:_master_model_container: 2
2025-05-28 00:04:40,580:INFO:_display_container: 2
2025-05-28 00:04:40,580:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-05-28 00:04:40,580:INFO:create_model() successfully completed......................................
2025-05-28 00:04:40,696:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:40,696:INFO:Creating metrics dataframe
2025-05-28 00:04:40,701:INFO:Initializing Naive Bayes
2025-05-28 00:04:40,701:INFO:Total runtime is 0.14393898248672485 minutes
2025-05-28 00:04:40,701:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:40,701:INFO:Initializing create_model()
2025-05-28 00:04:40,702:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:40,702:INFO:Checking exceptions
2025-05-28 00:04:40,702:INFO:Importing libraries
2025-05-28 00:04:40,702:INFO:Copying training dataset
2025-05-28 00:04:40,709:INFO:Defining folds
2025-05-28 00:04:40,709:INFO:Declaring metric variables
2025-05-28 00:04:40,710:INFO:Importing untrained model
2025-05-28 00:04:40,710:INFO:Naive Bayes Imported successfully
2025-05-28 00:04:40,710:INFO:Starting cross validation
2025-05-28 00:04:40,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:40,886:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,889:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:40,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,061:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,064:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,234:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,238:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,241:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,408:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,411:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,414:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,583:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,586:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,590:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,759:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,763:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,764:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:41,766:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,933:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,937:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:41,940:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,112:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,285:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,289:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,292:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,459:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,463:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,472:INFO:Calculating mean and std
2025-05-28 00:04:42,473:INFO:Creating metrics dataframe
2025-05-28 00:04:42,475:INFO:Uploading results into container
2025-05-28 00:04:42,476:INFO:Uploading model into container now
2025-05-28 00:04:42,476:INFO:_master_model_container: 3
2025-05-28 00:04:42,476:INFO:_display_container: 2
2025-05-28 00:04:42,476:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-05-28 00:04:42,476:INFO:create_model() successfully completed......................................
2025-05-28 00:04:42,589:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:42,589:INFO:Creating metrics dataframe
2025-05-28 00:04:42,594:INFO:Initializing Decision Tree Classifier
2025-05-28 00:04:42,594:INFO:Total runtime is 0.17549262444178262 minutes
2025-05-28 00:04:42,594:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:42,595:INFO:Initializing create_model()
2025-05-28 00:04:42,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:42,595:INFO:Checking exceptions
2025-05-28 00:04:42,595:INFO:Importing libraries
2025-05-28 00:04:42,595:INFO:Copying training dataset
2025-05-28 00:04:42,602:INFO:Defining folds
2025-05-28 00:04:42,602:INFO:Declaring metric variables
2025-05-28 00:04:42,602:INFO:Importing untrained model
2025-05-28 00:04:42,603:INFO:Decision Tree Classifier Imported successfully
2025-05-28 00:04:42,603:INFO:Starting cross validation
2025-05-28 00:04:42,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:42,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,786:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,790:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,961:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,965:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:42,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,140:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,143:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,147:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,341:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,349:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,524:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,528:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,531:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,703:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,707:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,710:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,883:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,886:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:43,889:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,061:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,065:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,241:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,244:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,248:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,420:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,423:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,427:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,433:INFO:Calculating mean and std
2025-05-28 00:04:44,433:INFO:Creating metrics dataframe
2025-05-28 00:04:44,435:INFO:Uploading results into container
2025-05-28 00:04:44,436:INFO:Uploading model into container now
2025-05-28 00:04:44,436:INFO:_master_model_container: 4
2025-05-28 00:04:44,436:INFO:_display_container: 2
2025-05-28 00:04:44,436:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=210, splitter='best')
2025-05-28 00:04:44,436:INFO:create_model() successfully completed......................................
2025-05-28 00:04:44,548:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:44,549:INFO:Creating metrics dataframe
2025-05-28 00:04:44,554:INFO:Initializing SVM - Linear Kernel
2025-05-28 00:04:44,554:INFO:Total runtime is 0.20815458297729492 minutes
2025-05-28 00:04:44,554:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:44,554:INFO:Initializing create_model()
2025-05-28 00:04:44,554:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:44,555:INFO:Checking exceptions
2025-05-28 00:04:44,555:INFO:Importing libraries
2025-05-28 00:04:44,555:INFO:Copying training dataset
2025-05-28 00:04:44,562:INFO:Defining folds
2025-05-28 00:04:44,562:INFO:Declaring metric variables
2025-05-28 00:04:44,562:INFO:Importing untrained model
2025-05-28 00:04:44,563:INFO:SVM - Linear Kernel Imported successfully
2025-05-28 00:04:44,564:INFO:Starting cross validation
2025-05-28 00:04:44,567:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:44,767:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:44,769:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,772:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,775:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:44,778:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,968:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:44,970:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:44,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:44,977:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,172:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:45,174:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,177:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,179:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:45,181:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,387:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:45,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:45,395:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,605:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:45,607:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,610:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,612:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:45,614:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,810:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:45,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:45,817:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:45,818:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:46,015:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,018:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,020:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:46,022:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,217:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:46,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,222:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,224:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:46,226:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,427:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:46,429:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,432:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,434:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:46,436:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:46,624:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,629:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:46,631:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,636:INFO:Calculating mean and std
2025-05-28 00:04:46,637:INFO:Creating metrics dataframe
2025-05-28 00:04:46,639:INFO:Uploading results into container
2025-05-28 00:04:46,639:INFO:Uploading model into container now
2025-05-28 00:04:46,640:INFO:_master_model_container: 5
2025-05-28 00:04:46,640:INFO:_display_container: 2
2025-05-28 00:04:46,640:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=210, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-05-28 00:04:46,640:INFO:create_model() successfully completed......................................
2025-05-28 00:04:46,751:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:46,751:INFO:Creating metrics dataframe
2025-05-28 00:04:46,756:INFO:Initializing Ridge Classifier
2025-05-28 00:04:46,756:INFO:Total runtime is 0.24485752979914346 minutes
2025-05-28 00:04:46,756:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:46,757:INFO:Initializing create_model()
2025-05-28 00:04:46,757:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:46,757:INFO:Checking exceptions
2025-05-28 00:04:46,757:INFO:Importing libraries
2025-05-28 00:04:46,757:INFO:Copying training dataset
2025-05-28 00:04:46,764:INFO:Defining folds
2025-05-28 00:04:46,764:INFO:Declaring metric variables
2025-05-28 00:04:46,764:INFO:Importing untrained model
2025-05-28 00:04:46,765:INFO:Ridge Classifier Imported successfully
2025-05-28 00:04:46,765:INFO:Starting cross validation
2025-05-28 00:04:46,768:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:46,935:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:46,937:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,940:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:46,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:46,944:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,104:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,106:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,109:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,113:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,280:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,281:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,443:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,445:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,448:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,450:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,452:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,613:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,615:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,618:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,620:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,783:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,784:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,788:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,789:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,791:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,952:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:47,953:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,957:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:47,958:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:47,960:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,120:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:48,122:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,125:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,127:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:48,129:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,289:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:48,291:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,295:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,296:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:48,298:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,460:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:48,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,465:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,466:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:48,468:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:48,474:INFO:Calculating mean and std
2025-05-28 00:04:48,474:INFO:Creating metrics dataframe
2025-05-28 00:04:48,476:INFO:Uploading results into container
2025-05-28 00:04:48,477:INFO:Uploading model into container now
2025-05-28 00:04:48,477:INFO:_master_model_container: 6
2025-05-28 00:04:48,477:INFO:_display_container: 2
2025-05-28 00:04:48,477:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=210, solver='auto',
                tol=0.0001)
2025-05-28 00:04:48,478:INFO:create_model() successfully completed......................................
2025-05-28 00:04:48,589:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:48,590:INFO:Creating metrics dataframe
2025-05-28 00:04:48,594:INFO:Initializing Random Forest Classifier
2025-05-28 00:04:48,594:INFO:Total runtime is 0.275494118531545 minutes
2025-05-28 00:04:48,594:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:48,595:INFO:Initializing create_model()
2025-05-28 00:04:48,595:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:48,595:INFO:Checking exceptions
2025-05-28 00:04:48,595:INFO:Importing libraries
2025-05-28 00:04:48,595:INFO:Copying training dataset
2025-05-28 00:04:48,602:INFO:Defining folds
2025-05-28 00:04:48,602:INFO:Declaring metric variables
2025-05-28 00:04:48,602:INFO:Importing untrained model
2025-05-28 00:04:48,602:INFO:Random Forest Classifier Imported successfully
2025-05-28 00:04:48,603:INFO:Starting cross validation
2025-05-28 00:04:48,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:49,086:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:49,090:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:49,091:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:49,093:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:49,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:49,594:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:49,598:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,158:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,162:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,737:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:50,751:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,337:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,343:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,346:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:51,348:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,848:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:51,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,338:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,342:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,345:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,828:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,832:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:52,836:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,322:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,329:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,334:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,846:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,850:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,854:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:53,860:INFO:Calculating mean and std
2025-05-28 00:04:53,861:INFO:Creating metrics dataframe
2025-05-28 00:04:53,862:INFO:Uploading results into container
2025-05-28 00:04:53,863:INFO:Uploading model into container now
2025-05-28 00:04:53,863:INFO:_master_model_container: 7
2025-05-28 00:04:53,863:INFO:_display_container: 2
2025-05-28 00:04:53,864:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=210, verbose=0,
                       warm_start=False)
2025-05-28 00:04:53,864:INFO:create_model() successfully completed......................................
2025-05-28 00:04:53,978:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:53,978:INFO:Creating metrics dataframe
2025-05-28 00:04:53,982:INFO:Initializing Quadratic Discriminant Analysis
2025-05-28 00:04:53,982:INFO:Total runtime is 0.3652888774871826 minutes
2025-05-28 00:04:53,982:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:53,982:INFO:Initializing create_model()
2025-05-28 00:04:53,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:53,982:INFO:Checking exceptions
2025-05-28 00:04:53,983:INFO:Importing libraries
2025-05-28 00:04:53,983:INFO:Copying training dataset
2025-05-28 00:04:53,988:INFO:Defining folds
2025-05-28 00:04:53,988:INFO:Declaring metric variables
2025-05-28 00:04:53,989:INFO:Importing untrained model
2025-05-28 00:04:53,989:INFO:Quadratic Discriminant Analysis Imported successfully
2025-05-28 00:04:53,989:INFO:Starting cross validation
2025-05-28 00:04:53,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:54,176:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:54,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:54,278:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,285:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:54,493:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:54,497:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,502:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,506:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,622:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:54,715:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:54,719:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,724:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,725:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:04:54,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,844:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:54,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:54,940:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,945:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:54,948:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:55,159:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:55,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,167:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:55,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:55,383:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,507:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:55,601:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:55,606:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,609:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,613:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,728:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:55,822:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:55,825:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,830:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:55,950:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:56,043:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:56,047:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,051:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,055:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,171:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-05-28 00:04:56,264:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:56,268:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,272:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,276:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,281:INFO:Calculating mean and std
2025-05-28 00:04:56,282:INFO:Creating metrics dataframe
2025-05-28 00:04:56,284:INFO:Uploading results into container
2025-05-28 00:04:56,284:INFO:Uploading model into container now
2025-05-28 00:04:56,285:INFO:_master_model_container: 8
2025-05-28 00:04:56,285:INFO:_display_container: 2
2025-05-28 00:04:56,285:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-05-28 00:04:56,285:INFO:create_model() successfully completed......................................
2025-05-28 00:04:56,402:INFO:SubProcess create_model() end ==================================
2025-05-28 00:04:56,402:INFO:Creating metrics dataframe
2025-05-28 00:04:56,406:INFO:Initializing Ada Boost Classifier
2025-05-28 00:04:56,406:INFO:Total runtime is 0.4056987961133321 minutes
2025-05-28 00:04:56,407:INFO:SubProcess create_model() called ==================================
2025-05-28 00:04:56,407:INFO:Initializing create_model()
2025-05-28 00:04:56,407:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:04:56,407:INFO:Checking exceptions
2025-05-28 00:04:56,407:INFO:Importing libraries
2025-05-28 00:04:56,408:INFO:Copying training dataset
2025-05-28 00:04:56,415:INFO:Defining folds
2025-05-28 00:04:56,415:INFO:Declaring metric variables
2025-05-28 00:04:56,415:INFO:Importing untrained model
2025-05-28 00:04:56,415:INFO:Ada Boost Classifier Imported successfully
2025-05-28 00:04:56,416:INFO:Starting cross validation
2025-05-28 00:04:56,418:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:04:56,541:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:56,727:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:56,729:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,733:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:56,857:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:57,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:57,055:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,059:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,062:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,178:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:57,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:57,368:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,372:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,375:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,512:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:57,732:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:57,735:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,739:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,742:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:57,884:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:58,111:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:58,115:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,119:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,123:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,258:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:58,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:58,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,503:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,644:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:58,831:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:58,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,840:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:58,971:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:59,247:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:59,251:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,255:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,259:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,412:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:59,647:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:59,650:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,654:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,657:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,796:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-05-28 00:04:59,992:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:04:59,994:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:04:59,997:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:00,000:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:00,007:INFO:Calculating mean and std
2025-05-28 00:05:00,007:INFO:Creating metrics dataframe
2025-05-28 00:05:00,009:INFO:Uploading results into container
2025-05-28 00:05:00,010:INFO:Uploading model into container now
2025-05-28 00:05:00,010:INFO:_master_model_container: 9
2025-05-28 00:05:00,010:INFO:_display_container: 2
2025-05-28 00:05:00,011:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=210)
2025-05-28 00:05:00,011:INFO:create_model() successfully completed......................................
2025-05-28 00:05:00,151:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:00,152:INFO:Creating metrics dataframe
2025-05-28 00:05:00,156:INFO:Initializing Gradient Boosting Classifier
2025-05-28 00:05:00,156:INFO:Total runtime is 0.46819485028584795 minutes
2025-05-28 00:05:00,156:INFO:SubProcess create_model() called ==================================
2025-05-28 00:05:00,157:INFO:Initializing create_model()
2025-05-28 00:05:00,157:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:00,157:INFO:Checking exceptions
2025-05-28 00:05:00,157:INFO:Importing libraries
2025-05-28 00:05:00,157:INFO:Copying training dataset
2025-05-28 00:05:00,164:INFO:Defining folds
2025-05-28 00:05:00,164:INFO:Declaring metric variables
2025-05-28 00:05:00,164:INFO:Importing untrained model
2025-05-28 00:05:00,165:INFO:Gradient Boosting Classifier Imported successfully
2025-05-28 00:05:00,165:INFO:Starting cross validation
2025-05-28 00:05:00,169:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:05:01,779:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:01,780:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:01,784:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:01,787:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:03,379:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:03,381:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:03,385:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:03,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:04,973:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:04,975:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:04,978:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:04,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:06,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:06,566:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:06,569:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:06,572:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:08,273:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:08,275:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:08,282:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:08,287:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:09,903:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:09,905:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:09,908:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:09,911:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:11,627:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:11,630:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:11,635:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:11,638:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:13,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:13,380:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:13,383:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:13,387:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:14,916:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:14,918:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:14,921:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:14,923:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:14,925:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,456:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:16,458:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,461:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,465:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,471:INFO:Calculating mean and std
2025-05-28 00:05:16,471:INFO:Creating metrics dataframe
2025-05-28 00:05:16,473:INFO:Uploading results into container
2025-05-28 00:05:16,474:INFO:Uploading model into container now
2025-05-28 00:05:16,474:INFO:_master_model_container: 10
2025-05-28 00:05:16,474:INFO:_display_container: 2
2025-05-28 00:05:16,475:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=210, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-05-28 00:05:16,475:INFO:create_model() successfully completed......................................
2025-05-28 00:05:16,591:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:16,591:INFO:Creating metrics dataframe
2025-05-28 00:05:16,596:INFO:Initializing Linear Discriminant Analysis
2025-05-28 00:05:16,596:INFO:Total runtime is 0.7421860019365947 minutes
2025-05-28 00:05:16,596:INFO:SubProcess create_model() called ==================================
2025-05-28 00:05:16,596:INFO:Initializing create_model()
2025-05-28 00:05:16,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:16,597:INFO:Checking exceptions
2025-05-28 00:05:16,597:INFO:Importing libraries
2025-05-28 00:05:16,597:INFO:Copying training dataset
2025-05-28 00:05:16,603:INFO:Defining folds
2025-05-28 00:05:16,604:INFO:Declaring metric variables
2025-05-28 00:05:16,604:INFO:Importing untrained model
2025-05-28 00:05:16,604:INFO:Linear Discriminant Analysis Imported successfully
2025-05-28 00:05:16,604:INFO:Starting cross validation
2025-05-28 00:05:16,607:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:05:16,823:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:16,827:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,833:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:16,837:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,043:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:17,047:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,053:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,057:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,263:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:17,267:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,274:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,277:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,485:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:17,489:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,498:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,707:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:17,711:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,717:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,720:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,927:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:17,931:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,937:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:17,941:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,148:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:18,151:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,158:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,161:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,368:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:18,371:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,381:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,589:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:18,593:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,600:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,603:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,811:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-05-28 00:05:18,815:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,821:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,825:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:18,831:INFO:Calculating mean and std
2025-05-28 00:05:18,831:INFO:Creating metrics dataframe
2025-05-28 00:05:18,833:INFO:Uploading results into container
2025-05-28 00:05:18,834:INFO:Uploading model into container now
2025-05-28 00:05:18,834:INFO:_master_model_container: 11
2025-05-28 00:05:18,834:INFO:_display_container: 2
2025-05-28 00:05:18,834:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-05-28 00:05:18,834:INFO:create_model() successfully completed......................................
2025-05-28 00:05:18,947:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:18,947:INFO:Creating metrics dataframe
2025-05-28 00:05:18,951:INFO:Initializing Extra Trees Classifier
2025-05-28 00:05:18,952:INFO:Total runtime is 0.781452480951945 minutes
2025-05-28 00:05:18,952:INFO:SubProcess create_model() called ==================================
2025-05-28 00:05:18,952:INFO:Initializing create_model()
2025-05-28 00:05:18,952:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:18,952:INFO:Checking exceptions
2025-05-28 00:05:18,952:INFO:Importing libraries
2025-05-28 00:05:18,952:INFO:Copying training dataset
2025-05-28 00:05:18,959:INFO:Defining folds
2025-05-28 00:05:18,959:INFO:Declaring metric variables
2025-05-28 00:05:18,959:INFO:Importing untrained model
2025-05-28 00:05:18,960:INFO:Extra Trees Classifier Imported successfully
2025-05-28 00:05:18,960:INFO:Starting cross validation
2025-05-28 00:05:18,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:05:19,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:19,385:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:19,392:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:19,798:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:19,806:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:19,812:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,299:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,305:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,310:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,726:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,732:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:20,736:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,153:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,157:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,163:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:21,564:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,054:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,062:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,471:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,475:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,480:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,936:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,942:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:22,947:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:23,365:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:23,373:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:23,378:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:23,386:INFO:Calculating mean and std
2025-05-28 00:05:23,387:INFO:Creating metrics dataframe
2025-05-28 00:05:23,389:INFO:Uploading results into container
2025-05-28 00:05:23,389:INFO:Uploading model into container now
2025-05-28 00:05:23,389:INFO:_master_model_container: 12
2025-05-28 00:05:23,390:INFO:_display_container: 2
2025-05-28 00:05:23,390:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=210, verbose=0,
                     warm_start=False)
2025-05-28 00:05:23,390:INFO:create_model() successfully completed......................................
2025-05-28 00:05:23,509:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:23,509:INFO:Creating metrics dataframe
2025-05-28 00:05:23,514:INFO:Initializing Light Gradient Boosting Machine
2025-05-28 00:05:23,514:INFO:Total runtime is 0.8574977914492289 minutes
2025-05-28 00:05:23,515:INFO:SubProcess create_model() called ==================================
2025-05-28 00:05:23,515:INFO:Initializing create_model()
2025-05-28 00:05:23,515:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:23,515:INFO:Checking exceptions
2025-05-28 00:05:23,516:INFO:Importing libraries
2025-05-28 00:05:23,516:INFO:Copying training dataset
2025-05-28 00:05:23,525:INFO:Defining folds
2025-05-28 00:05:23,525:INFO:Declaring metric variables
2025-05-28 00:05:23,525:INFO:Importing untrained model
2025-05-28 00:05:23,526:INFO:Light Gradient Boosting Machine Imported successfully
2025-05-28 00:05:23,526:INFO:Starting cross validation
2025-05-28 00:05:23,529:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:05:23,657:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:23,658:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:23,658:INFO:[LightGBM] [Info] Number of data points in the train set: 1506, number of used features: 23
2025-05-28 00:05:23,709:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:23,709:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:23,716:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:23,718:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:23,719:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000322 secs. 1 sparse feature groups
2025-05-28 00:05:23,719:INFO:[LightGBM] [Info] Start training from score -0.681266
2025-05-28 00:05:23,719:INFO:[LightGBM] [Info] Start training from score -3.097705
2025-05-28 00:05:23,719:INFO:[LightGBM] [Info] Start training from score -1.811881
2025-05-28 00:05:23,720:INFO:[LightGBM] [Info] Start training from score -2.187314
2025-05-28 00:05:23,720:INFO:[LightGBM] [Info] Start training from score -1.752692
2025-05-28 00:05:25,013:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:25,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:25,021:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:25,140:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:25,141:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:25,141:INFO:[LightGBM] [Info] Number of data points in the train set: 1506, number of used features: 23
2025-05-28 00:05:25,182:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:25,182:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:25,189:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:25,191:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:25,191:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000308 secs. 1 sparse feature groups
2025-05-28 00:05:25,191:INFO:[LightGBM] [Info] Start training from score -0.679954
2025-05-28 00:05:25,191:INFO:[LightGBM] [Info] Start training from score -3.112520
2025-05-28 00:05:25,192:INFO:[LightGBM] [Info] Start training from score -1.811881
2025-05-28 00:05:25,192:INFO:[LightGBM] [Info] Start training from score -2.187314
2025-05-28 00:05:25,192:INFO:[LightGBM] [Info] Start training from score -1.752692
2025-05-28 00:05:26,484:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:26,488:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:26,492:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:26,611:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:26,612:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:26,612:INFO:[LightGBM] [Info] Number of data points in the train set: 1506, number of used features: 23
2025-05-28 00:05:26,653:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:26,653:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:26,660:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:26,661:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:26,662:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000303 secs. 1 sparse feature groups
2025-05-28 00:05:26,662:INFO:[LightGBM] [Info] Start training from score -0.679954
2025-05-28 00:05:26,663:INFO:[LightGBM] [Info] Start training from score -3.112520
2025-05-28 00:05:26,663:INFO:[LightGBM] [Info] Start training from score -1.811881
2025-05-28 00:05:26,663:INFO:[LightGBM] [Info] Start training from score -2.187314
2025-05-28 00:05:26,663:INFO:[LightGBM] [Info] Start training from score -1.752692
2025-05-28 00:05:28,017:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:28,021:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:28,025:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:28,144:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:28,145:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:28,145:INFO:[LightGBM] [Info] Number of data points in the train set: 1506, number of used features: 23
2025-05-28 00:05:28,186:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:28,186:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:28,193:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:28,194:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:28,195:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000309 secs. 1 sparse feature groups
2025-05-28 00:05:28,195:INFO:[LightGBM] [Info] Start training from score -0.679954
2025-05-28 00:05:28,196:INFO:[LightGBM] [Info] Start training from score -3.112520
2025-05-28 00:05:28,196:INFO:[LightGBM] [Info] Start training from score -1.811881
2025-05-28 00:05:28,196:INFO:[LightGBM] [Info] Start training from score -2.187314
2025-05-28 00:05:28,196:INFO:[LightGBM] [Info] Start training from score -1.752692
2025-05-28 00:05:29,491:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:29,495:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:29,499:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:29,617:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:29,618:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:29,618:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:29,660:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:29,660:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:29,667:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:29,669:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:29,669:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000296 secs. 1 sparse feature groups
2025-05-28 00:05:29,670:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:29,670:INFO:[LightGBM] [Info] Start training from score -3.113184
2025-05-28 00:05:29,670:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:29,670:INFO:[LightGBM] [Info] Start training from score -2.182078
2025-05-28 00:05:29,670:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:30,981:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:30,986:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:30,990:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:31,108:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:31,108:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:31,109:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:31,151:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:31,152:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:31,159:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:31,161:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:31,161:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000300 secs. 1 sparse feature groups
2025-05-28 00:05:31,161:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:31,162:INFO:[LightGBM] [Info] Start training from score -3.113184
2025-05-28 00:05:31,162:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:31,162:INFO:[LightGBM] [Info] Start training from score -2.182078
2025-05-28 00:05:31,162:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:32,591:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:32,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:32,599:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:32,718:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:32,718:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:32,719:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:32,761:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:32,761:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:32,777:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:32,779:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:32,780:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000596 secs. 1 sparse feature groups
2025-05-28 00:05:32,781:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:32,781:INFO:[LightGBM] [Info] Start training from score -3.098368
2025-05-28 00:05:32,781:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:32,781:INFO:[LightGBM] [Info] Start training from score -2.187977
2025-05-28 00:05:32,781:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:34,089:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:34,093:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:34,097:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:34,216:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:34,217:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:34,217:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:34,260:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:34,261:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:34,268:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:34,269:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:34,270:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000303 secs. 1 sparse feature groups
2025-05-28 00:05:34,270:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:34,270:INFO:[LightGBM] [Info] Start training from score -3.098368
2025-05-28 00:05:34,271:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:34,271:INFO:[LightGBM] [Info] Start training from score -2.187977
2025-05-28 00:05:34,271:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:35,587:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:35,591:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:35,595:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:35,715:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:35,715:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:35,715:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:35,756:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:35,756:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:35,764:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:35,765:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:35,766:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000296 secs. 1 sparse feature groups
2025-05-28 00:05:35,766:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:35,766:INFO:[LightGBM] [Info] Start training from score -3.098368
2025-05-28 00:05:35,766:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:35,766:INFO:[LightGBM] [Info] Start training from score -2.187977
2025-05-28 00:05:35,767:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:37,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:37,393:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:37,397:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:37,516:INFO:[LightGBM] [Info] This is the GPU trainer!!
2025-05-28 00:05:37,516:INFO:[LightGBM] [Info] Total Bins 330
2025-05-28 00:05:37,517:INFO:[LightGBM] [Info] Number of data points in the train set: 1507, number of used features: 23
2025-05-28 00:05:37,558:INFO:[LightGBM] [Info] Using GPU Device: Quadro M3000M, Vendor: NVIDIA Corporation
2025-05-28 00:05:37,558:INFO:[LightGBM] [Info] Compiling OpenCL Kernel with 256 bins...
2025-05-28 00:05:37,565:INFO:[LightGBM] [Info] GPU programs have been built
2025-05-28 00:05:37,567:INFO:[LightGBM] [Info] Size of histogram bin entry: 8
2025-05-28 00:05:37,567:INFO:[LightGBM] [Info] 7 dense feature groups (0.01 MB) transferred to GPU in 0.000298 secs. 1 sparse feature groups
2025-05-28 00:05:37,568:INFO:[LightGBM] [Info] Start training from score -0.681930
2025-05-28 00:05:37,568:INFO:[LightGBM] [Info] Start training from score -3.098368
2025-05-28 00:05:37,568:INFO:[LightGBM] [Info] Start training from score -1.808488
2025-05-28 00:05:37,568:INFO:[LightGBM] [Info] Start training from score -2.187977
2025-05-28 00:05:37,568:INFO:[LightGBM] [Info] Start training from score -1.753356
2025-05-28 00:05:38,889:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:38,893:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:38,897:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:38,903:INFO:Calculating mean and std
2025-05-28 00:05:38,904:INFO:Creating metrics dataframe
2025-05-28 00:05:38,906:INFO:Uploading results into container
2025-05-28 00:05:38,907:INFO:Uploading model into container now
2025-05-28 00:05:38,907:INFO:_master_model_container: 13
2025-05-28 00:05:38,907:INFO:_display_container: 2
2025-05-28 00:05:38,908:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               device='gpu', importance_type='split', learning_rate=0.1,
               max_depth=-1, min_child_samples=20, min_child_weight=0.001,
               min_split_gain=0.0, n_estimators=100, n_jobs=-1, num_leaves=31,
               objective=None, random_state=210, reg_alpha=0.0, reg_lambda=0.0,
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2025-05-28 00:05:38,908:INFO:create_model() successfully completed......................................
2025-05-28 00:05:39,027:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:39,027:INFO:Creating metrics dataframe
2025-05-28 00:05:39,031:INFO:Initializing Dummy Classifier
2025-05-28 00:05:39,032:INFO:Total runtime is 1.1161181489626566 minutes
2025-05-28 00:05:39,032:INFO:SubProcess create_model() called ==================================
2025-05-28 00:05:39,032:INFO:Initializing create_model()
2025-05-28 00:05:39,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7fb82a5c74f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:39,032:INFO:Checking exceptions
2025-05-28 00:05:39,032:INFO:Importing libraries
2025-05-28 00:05:39,032:INFO:Copying training dataset
2025-05-28 00:05:39,039:INFO:Defining folds
2025-05-28 00:05:39,039:INFO:Declaring metric variables
2025-05-28 00:05:39,040:INFO:Importing untrained model
2025-05-28 00:05:39,040:INFO:Dummy Classifier Imported successfully
2025-05-28 00:05:39,040:INFO:Starting cross validation
2025-05-28 00:05:39,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-05-28 00:05:39,215:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,219:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,221:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:39,222:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,384:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,388:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,389:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:39,391:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,553:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,557:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,558:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:39,560:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,723:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,726:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,728:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:39,730:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,892:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,896:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:39,897:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:39,899:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,063:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,066:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,068:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:40,069:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,232:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,236:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,237:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:40,239:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,401:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,405:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,406:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:40,408:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,570:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,573:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,575:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:40,577:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,740:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,743:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,745:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-05-28 00:05:40,746:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1561: UserWarning: Note that pos_label (set to 'very_good') is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2025-05-28 00:05:40,752:INFO:Calculating mean and std
2025-05-28 00:05:40,753:INFO:Creating metrics dataframe
2025-05-28 00:05:40,755:INFO:Uploading results into container
2025-05-28 00:05:40,755:INFO:Uploading model into container now
2025-05-28 00:05:40,755:INFO:_master_model_container: 14
2025-05-28 00:05:40,755:INFO:_display_container: 2
2025-05-28 00:05:40,756:INFO:DummyClassifier(constant=None, random_state=210, strategy='prior')
2025-05-28 00:05:40,756:INFO:create_model() successfully completed......................................
2025-05-28 00:05:40,873:INFO:SubProcess create_model() end ==================================
2025-05-28 00:05:40,873:INFO:Creating metrics dataframe
2025-05-28 00:05:40,879:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-05-28 00:05:40,882:INFO:Initializing create_model()
2025-05-28 00:05:40,882:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb932cf3eb0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-05-28 00:05:40,882:INFO:Checking exceptions
2025-05-28 00:05:40,883:INFO:Importing libraries
2025-05-28 00:05:40,883:INFO:Copying training dataset
2025-05-28 00:05:40,891:INFO:Defining folds
2025-05-28 00:05:40,891:INFO:Declaring metric variables
2025-05-28 00:05:40,892:INFO:Importing untrained model
2025-05-28 00:05:40,892:INFO:Declaring custom model
2025-05-28 00:05:40,893:INFO:Logistic Regression Imported successfully
2025-05-28 00:05:40,895:INFO:Cross validation set to False
2025-05-28 00:05:40,895:INFO:Fitting Model
2025-05-28 00:05:41,535:WARNING:/home/hosam/Desktop/projects/software-school/pycaret-env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-05-28 00:05:41,535:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-28 00:05:41,536:INFO:create_model() successfully completed......................................
2025-05-28 00:05:41,662:INFO:_master_model_container: 14
2025-05-28 00:05:41,662:INFO:_display_container: 2
2025-05-28 00:05:41,663:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-05-28 00:05:41,663:INFO:compare_models() successfully completed......................................
2025-05-28 00:05:41,754:INFO:Initializing save_model()
2025-05-28 00:05:41,754:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=210, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=student_performance_model, prep_pipe_=Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=F...
                                                               return_df=True,
                                                               verbose=0))),
                ('onehot_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-05-28 00:05:41,754:INFO:Adding model into prep_pipe
2025-05-28 00:05:41,767:INFO:student_performance_model.pkl saved in current working directory
2025-05-28 00:05:41,855:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missin...
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=210,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-05-28 00:05:41,855:INFO:save_model() successfully completed......................................
2025-05-28 00:05:51,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:51,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:51,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:51,813:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:52,426:INFO:Initializing load_model()
2025-05-28 00:05:52,426:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:05:57,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:57,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:57,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:57,383:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:05:57,980:INFO:Initializing load_model()
2025-05-28 00:05:57,980:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:06:16,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:16,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:16,332:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:16,333:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:16,926:INFO:Initializing load_model()
2025-05-28 00:06:16,926:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:06:27,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:27,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:27,078:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:27,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:27,674:INFO:Initializing load_model()
2025-05-28 00:06:27,674:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:06:35,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:35,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:35,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:35,657:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:36,405:INFO:Initializing load_model()
2025-05-28 00:06:36,405:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:06:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:47,220:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:47,221:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:06:47,846:INFO:Initializing load_model()
2025-05-28 00:06:47,846:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:07:15,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:15,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:15,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:15,245:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:15,849:INFO:Initializing load_model()
2025-05-28 00:07:15,850:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:07:27,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:27,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:27,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:27,583:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:28,177:INFO:Initializing load_model()
2025-05-28 00:07:28,177:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:07:36,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:36,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:36,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:36,322:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:36,916:INFO:Initializing load_model()
2025-05-28 00:07:36,916:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:07:49,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:49,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:49,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:49,894:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:07:50,489:INFO:Initializing load_model()
2025-05-28 00:07:50,489:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:07:50,644:INFO:Initializing predict_model()
2025-05-28 00:07:50,644:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fd15baabbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fd122ca00d0>)
2025-05-28 00:07:50,645:INFO:Checking exceptions
2025-05-28 00:07:50,645:INFO:Preloading libraries
2025-05-28 00:07:50,645:INFO:Set up data.
2025-05-28 00:07:50,651:INFO:Set up index.
2025-05-28 00:10:44,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:10:44,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:10:44,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:10:44,037:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:10:44,631:INFO:Initializing load_model()
2025-05-28 00:10:44,631:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:10:44,786:INFO:Initializing predict_model()
2025-05-28 00:10:44,786:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f1722af7bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f16e9cc40d0>)
2025-05-28 00:10:44,786:INFO:Checking exceptions
2025-05-28 00:10:44,786:INFO:Preloading libraries
2025-05-28 00:10:44,786:INFO:Set up data.
2025-05-28 00:10:44,793:INFO:Set up index.
2025-05-28 00:13:39,572:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:13:39,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:13:39,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:13:39,573:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:13:40,220:INFO:Initializing load_model()
2025-05-28 00:13:40,220:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:14:19,260:INFO:Initializing predict_model()
2025-05-28 00:14:19,260:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fe10f0ece50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fe10f0bdfc0>)
2025-05-28 00:14:19,261:INFO:Checking exceptions
2025-05-28 00:14:19,261:INFO:Preloading libraries
2025-05-28 00:14:19,261:INFO:Set up data.
2025-05-28 00:14:19,268:INFO:Set up index.
2025-05-28 00:16:13,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:16:13,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:16:13,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:16:13,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:16:14,480:INFO:Initializing load_model()
2025-05-28 00:16:14,480:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:16:45,210:INFO:Initializing predict_model()
2025-05-28 00:16:45,211:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79afe8e50>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7ff79afb9fc0>)
2025-05-28 00:16:45,211:INFO:Checking exceptions
2025-05-28 00:16:45,211:INFO:Preloading libraries
2025-05-28 00:16:45,211:INFO:Set up data.
2025-05-28 00:16:45,220:INFO:Set up index.
2025-05-28 00:16:49,922:INFO:Initializing predict_model()
2025-05-28 00:16:49,922:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff79afa7820>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7ff79afb9fc0>)
2025-05-28 00:16:49,922:INFO:Checking exceptions
2025-05-28 00:16:49,922:INFO:Preloading libraries
2025-05-28 00:16:49,923:INFO:Set up data.
2025-05-28 00:16:49,931:INFO:Set up index.
2025-05-28 00:19:53,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:19:53,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:19:53,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:19:53,340:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:19:54,269:INFO:Initializing load_model()
2025-05-28 00:19:54,269:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:20:03,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:03,948:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:03,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:03,949:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:04,600:INFO:Initializing load_model()
2025-05-28 00:20:04,600:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:20:23,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:23,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:23,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:23,410:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:20:24,090:INFO:Initializing load_model()
2025-05-28 00:20:24,091:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:21:02,379:INFO:Initializing predict_model()
2025-05-28 00:21:02,379:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eae88fa0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59f30>)
2025-05-28 00:21:02,380:INFO:Checking exceptions
2025-05-28 00:21:02,380:INFO:Preloading libraries
2025-05-28 00:21:02,380:INFO:Set up data.
2025-05-28 00:21:02,388:INFO:Set up index.
2025-05-28 00:22:40,497:INFO:Initializing predict_model()
2025-05-28 00:22:40,497:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eafc47c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59ea0>)
2025-05-28 00:22:40,497:INFO:Checking exceptions
2025-05-28 00:22:40,498:INFO:Preloading libraries
2025-05-28 00:22:40,498:INFO:Set up data.
2025-05-28 00:22:40,504:INFO:Set up index.
2025-05-28 00:23:29,442:INFO:Initializing predict_model()
2025-05-28 00:23:29,442:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eaf9fd00>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59ea0>)
2025-05-28 00:23:29,442:INFO:Checking exceptions
2025-05-28 00:23:29,442:INFO:Preloading libraries
2025-05-28 00:23:29,442:INFO:Set up data.
2025-05-28 00:23:29,449:INFO:Set up index.
2025-05-28 00:23:34,426:INFO:Initializing predict_model()
2025-05-28 00:23:34,426:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eaf9fc40>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59ea0>)
2025-05-28 00:23:34,426:INFO:Checking exceptions
2025-05-28 00:23:34,426:INFO:Preloading libraries
2025-05-28 00:23:34,426:INFO:Set up data.
2025-05-28 00:23:34,434:INFO:Set up index.
2025-05-28 00:23:47,270:INFO:Initializing predict_model()
2025-05-28 00:23:47,270:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eae89ea0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae5a0e0>)
2025-05-28 00:23:47,270:INFO:Checking exceptions
2025-05-28 00:23:47,270:INFO:Preloading libraries
2025-05-28 00:23:47,271:INFO:Set up data.
2025-05-28 00:23:47,277:INFO:Set up index.
2025-05-28 00:24:07,241:INFO:Initializing predict_model()
2025-05-28 00:24:07,241:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eae4ba90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59ea0>)
2025-05-28 00:24:07,241:INFO:Checking exceptions
2025-05-28 00:24:07,241:INFO:Preloading libraries
2025-05-28 00:24:07,242:INFO:Set up data.
2025-05-28 00:24:07,248:INFO:Set up index.
2025-05-28 00:25:15,178:INFO:Initializing predict_model()
2025-05-28 00:25:15,178:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f95eae4ba90>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f95eae59ea0>)
2025-05-28 00:25:15,180:INFO:Checking exceptions
2025-05-28 00:25:15,180:INFO:Preloading libraries
2025-05-28 00:25:15,180:INFO:Set up data.
2025-05-28 00:25:15,187:INFO:Set up index.
2025-05-28 00:27:20,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:27:20,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:27:20,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:27:20,345:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:27:21,072:INFO:Initializing load_model()
2025-05-28 00:27:21,072:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:27:52,477:INFO:Initializing predict_model()
2025-05-28 00:27:52,477:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f7060ee8850>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f7060eb5ea0>)
2025-05-28 00:27:52,477:INFO:Checking exceptions
2025-05-28 00:27:52,478:INFO:Preloading libraries
2025-05-28 00:27:52,478:INFO:Set up data.
2025-05-28 00:27:52,485:INFO:Set up index.
2025-05-28 00:28:29,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:28:29,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:28:29,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:28:29,051:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-05-28 00:28:29,654:INFO:Initializing load_model()
2025-05-28 00:28:29,654:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-05-28 00:28:29,809:INFO:Initializing predict_model()
2025-05-28 00:28:29,809:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f5757dcbbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f571ef980d0>)
2025-05-28 00:28:29,809:INFO:Checking exceptions
2025-05-28 00:28:29,809:INFO:Preloading libraries
2025-05-28 00:28:29,809:INFO:Set up data.
2025-05-28 00:28:29,816:INFO:Set up index.
2025-06-06 01:45:16,677:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 01:45:16,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 01:45:16,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 01:45:16,678:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 01:45:17,515:INFO:Initializing load_model()
2025-06-06 01:45:17,515:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-06 01:45:17,684:INFO:Initializing predict_model()
2025-06-06 01:45:17,684:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8837007bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f87fe21c0d0>)
2025-06-06 01:45:17,684:INFO:Checking exceptions
2025-06-06 01:45:17,684:INFO:Preloading libraries
2025-06-06 01:45:17,685:INFO:Set up data.
2025-06-06 01:45:17,694:INFO:Set up index.
2025-06-06 03:07:30,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:07:30,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:07:30,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:07:30,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:07:31,502:INFO:Initializing load_model()
2025-06-06 03:07:31,502:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-06 03:07:31,651:INFO:Initializing predict_model()
2025-06-06 03:07:31,651:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f219be4bbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f219c0bbd90>)
2025-06-06 03:07:31,651:INFO:Checking exceptions
2025-06-06 03:07:31,651:INFO:Preloading libraries
2025-06-06 03:07:31,652:INFO:Set up data.
2025-06-06 03:07:31,658:INFO:Set up index.
2025-06-06 03:08:09,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:08:09,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:08:09,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:08:09,765:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-06 03:08:10,359:INFO:Initializing load_model()
2025-06-06 03:08:10,359:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-06 03:08:10,515:INFO:Initializing predict_model()
2025-06-06 03:08:10,516:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f57cb3f7bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f57cb667d90>)
2025-06-06 03:08:10,516:INFO:Checking exceptions
2025-06-06 03:08:10,516:INFO:Preloading libraries
2025-06-06 03:08:10,516:INFO:Set up data.
2025-06-06 03:08:10,522:INFO:Set up index.
2025-06-07 16:39:04,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 16:39:04,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 16:39:04,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 16:39:04,683:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 16:39:05,511:INFO:Initializing load_model()
2025-06-07 16:39:05,512:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 16:39:05,685:INFO:Initializing predict_model()
2025-06-07 16:39:05,685:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fa1ed4abbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fa1ed713d90>)
2025-06-07 16:39:05,685:INFO:Checking exceptions
2025-06-07 16:39:05,685:INFO:Preloading libraries
2025-06-07 16:39:05,688:INFO:Set up data.
2025-06-07 16:39:05,699:INFO:Set up index.
2025-06-07 17:29:04,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:29:04,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:29:04,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:29:04,795:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:29:05,506:INFO:Initializing load_model()
2025-06-07 17:29:05,506:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:29:05,668:INFO:Initializing predict_model()
2025-06-07 17:29:05,669:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f8f0d22fbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f8f0d497d90>)
2025-06-07 17:29:05,669:INFO:Checking exceptions
2025-06-07 17:29:05,669:INFO:Preloading libraries
2025-06-07 17:29:05,669:INFO:Set up data.
2025-06-07 17:29:05,677:INFO:Set up index.
2025-06-07 17:30:01,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:30:01,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:30:01,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:30:01,010:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:30:01,599:INFO:Initializing load_model()
2025-06-07 17:30:01,599:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:30:01,750:INFO:Initializing predict_model()
2025-06-07 17:30:01,750:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fb937963bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fb937bcbd90>)
2025-06-07 17:30:01,750:INFO:Checking exceptions
2025-06-07 17:30:01,750:INFO:Preloading libraries
2025-06-07 17:30:01,750:INFO:Set up data.
2025-06-07 17:30:01,757:INFO:Set up index.
2025-06-07 17:36:22,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:36:22,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:36:22,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:36:22,336:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:36:22,989:INFO:Initializing load_model()
2025-06-07 17:36:22,989:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:37:31,506:INFO:Initializing predict_model()
2025-06-07 17:37:31,506:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff3f6c53190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7ff3f6c88550>)
2025-06-07 17:37:31,506:INFO:Checking exceptions
2025-06-07 17:37:31,506:INFO:Preloading libraries
2025-06-07 17:37:31,506:INFO:Set up data.
2025-06-07 17:37:31,515:INFO:Set up index.
2025-06-07 17:39:58,048:INFO:Initializing predict_model()
2025-06-07 17:39:58,048:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff3f6c52fe0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7ff3f6c88550>)
2025-06-07 17:39:58,048:INFO:Checking exceptions
2025-06-07 17:39:58,048:INFO:Preloading libraries
2025-06-07 17:39:58,048:INFO:Set up data.
2025-06-07 17:39:58,055:INFO:Set up index.
2025-06-07 17:41:18,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:41:18,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:41:18,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:41:18,721:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:41:19,499:INFO:Initializing load_model()
2025-06-07 17:41:19,499:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:41:21,254:INFO:Initializing predict_model()
2025-06-07 17:41:21,254:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7fbca59b43a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7fbca5986050>)
2025-06-07 17:41:21,255:INFO:Checking exceptions
2025-06-07 17:41:21,255:INFO:Preloading libraries
2025-06-07 17:41:21,255:INFO:Set up data.
2025-06-07 17:41:21,263:INFO:Set up index.
2025-06-07 17:42:34,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:34,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:34,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:34,007:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:34,672:INFO:Initializing load_model()
2025-06-07 17:42:34,672:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:42:37,194:INFO:Initializing predict_model()
2025-06-07 17:42:37,194:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f61b27203a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f61b26f2050>)
2025-06-07 17:42:37,194:INFO:Checking exceptions
2025-06-07 17:42:37,194:INFO:Preloading libraries
2025-06-07 17:42:37,195:INFO:Set up data.
2025-06-07 17:42:37,202:INFO:Set up index.
2025-06-07 17:42:44,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:44,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:44,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:44,545:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-07 17:42:45,298:INFO:Initializing load_model()
2025-06-07 17:42:45,298:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-07 17:42:45,506:INFO:Initializing predict_model()
2025-06-07 17:42:45,506:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fc8b83a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88a050>)
2025-06-07 17:42:45,506:INFO:Checking exceptions
2025-06-07 17:42:45,506:INFO:Preloading libraries
2025-06-07 17:42:45,507:INFO:Set up data.
2025-06-07 17:42:45,514:INFO:Set up index.
2025-06-07 17:43:11,391:INFO:Initializing predict_model()
2025-06-07 17:43:11,391:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fc8b8070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:43:11,391:INFO:Checking exceptions
2025-06-07 17:43:11,391:INFO:Preloading libraries
2025-06-07 17:43:11,391:INFO:Set up data.
2025-06-07 17:43:11,399:INFO:Set up index.
2025-06-07 17:43:26,281:INFO:Initializing predict_model()
2025-06-07 17:43:26,281:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fd267be0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:43:26,281:INFO:Checking exceptions
2025-06-07 17:43:26,281:INFO:Preloading libraries
2025-06-07 17:43:26,282:INFO:Set up data.
2025-06-07 17:43:26,289:INFO:Set up index.
2025-06-07 17:43:45,088:INFO:Initializing predict_model()
2025-06-07 17:43:45,088:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fd2671f0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:43:45,088:INFO:Checking exceptions
2025-06-07 17:43:45,088:INFO:Preloading libraries
2025-06-07 17:43:45,089:INFO:Set up data.
2025-06-07 17:43:45,097:INFO:Set up index.
2025-06-07 17:43:56,977:INFO:Initializing predict_model()
2025-06-07 17:43:56,977:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fd267dc0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:43:56,977:INFO:Checking exceptions
2025-06-07 17:43:56,977:INFO:Preloading libraries
2025-06-07 17:43:56,978:INFO:Set up data.
2025-06-07 17:43:56,984:INFO:Set up index.
2025-06-07 17:44:30,132:INFO:Initializing predict_model()
2025-06-07 17:44:30,132:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fc8778e0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:44:30,132:INFO:Checking exceptions
2025-06-07 17:44:30,132:INFO:Preloading libraries
2025-06-07 17:44:30,132:INFO:Set up data.
2025-06-07 17:44:30,141:INFO:Set up index.
2025-06-07 17:44:53,759:INFO:Initializing predict_model()
2025-06-07 17:44:53,759:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f23fc877bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f23fc88aef0>)
2025-06-07 17:44:53,759:INFO:Checking exceptions
2025-06-07 17:44:53,760:INFO:Preloading libraries
2025-06-07 17:44:53,760:INFO:Set up data.
2025-06-07 17:44:53,767:INFO:Set up index.
2025-06-09 21:15:42,238:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:15:42,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:15:42,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:15:42,239:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:15:42,980:INFO:Initializing load_model()
2025-06-09 21:15:42,980:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:15:43,131:INFO:Initializing predict_model()
2025-06-09 21:15:43,131:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f17acc47bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f17aceafd90>)
2025-06-09 21:15:43,131:INFO:Checking exceptions
2025-06-09 21:15:43,131:INFO:Preloading libraries
2025-06-09 21:15:43,131:INFO:Set up data.
2025-06-09 21:15:43,138:INFO:Set up index.
2025-06-09 21:16:46,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:16:46,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:16:46,079:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:16:46,080:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:16:46,870:INFO:Initializing load_model()
2025-06-09 21:16:46,870:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:17:46,485:INFO:Initializing predict_model()
2025-06-09 21:17:46,485:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542bb4400>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b86050>)
2025-06-09 21:17:46,485:INFO:Checking exceptions
2025-06-09 21:17:46,485:INFO:Preloading libraries
2025-06-09 21:17:46,486:INFO:Set up data.
2025-06-09 21:17:46,494:INFO:Set up index.
2025-06-09 21:17:54,343:INFO:Initializing predict_model()
2025-06-09 21:17:54,343:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542bb40d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b85fc0>)
2025-06-09 21:17:54,343:INFO:Checking exceptions
2025-06-09 21:17:54,344:INFO:Preloading libraries
2025-06-09 21:17:54,344:INFO:Set up data.
2025-06-09 21:17:54,351:INFO:Set up index.
2025-06-09 21:18:48,843:INFO:Initializing predict_model()
2025-06-09 21:18:48,844:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542bb43a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b85fc0>)
2025-06-09 21:18:48,844:INFO:Checking exceptions
2025-06-09 21:18:48,844:INFO:Preloading libraries
2025-06-09 21:18:48,844:INFO:Set up data.
2025-06-09 21:18:48,851:INFO:Set up index.
2025-06-09 21:19:15,697:INFO:Initializing predict_model()
2025-06-09 21:19:15,697:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542bb55d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b85fc0>)
2025-06-09 21:19:15,698:INFO:Checking exceptions
2025-06-09 21:19:15,698:INFO:Preloading libraries
2025-06-09 21:19:15,698:INFO:Set up data.
2025-06-09 21:19:15,708:INFO:Set up index.
2025-06-09 21:19:20,107:INFO:Initializing predict_model()
2025-06-09 21:19:20,108:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542b73b20>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b87c70>)
2025-06-09 21:19:20,108:INFO:Checking exceptions
2025-06-09 21:19:20,108:INFO:Preloading libraries
2025-06-09 21:19:20,108:INFO:Set up data.
2025-06-09 21:19:20,117:INFO:Set up index.
2025-06-09 21:19:30,213:INFO:Initializing predict_model()
2025-06-09 21:19:30,213:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f3542bb64a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f3542b87c70>)
2025-06-09 21:19:30,213:INFO:Checking exceptions
2025-06-09 21:19:30,213:INFO:Preloading libraries
2025-06-09 21:19:30,214:INFO:Set up data.
2025-06-09 21:19:30,222:INFO:Set up index.
2025-06-09 21:24:37,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:37,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:37,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:37,356:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:38,159:INFO:Initializing load_model()
2025-06-09 21:24:38,159:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:24:38,374:INFO:Initializing predict_model()
2025-06-09 21:24:38,374:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f16498dfbb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f1649b4bd90>)
2025-06-09 21:24:38,374:INFO:Checking exceptions
2025-06-09 21:24:38,374:INFO:Preloading libraries
2025-06-09 21:24:38,375:INFO:Set up data.
2025-06-09 21:24:38,381:INFO:Set up index.
2025-06-09 21:24:38,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:38,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:38,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:38,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:24:39,516:INFO:Initializing load_model()
2025-06-09 21:24:39,517:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:24:57,340:INFO:Initializing predict_model()
2025-06-09 21:24:57,340:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f868eec83a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f868ee96050>)
2025-06-09 21:24:57,340:INFO:Checking exceptions
2025-06-09 21:24:57,340:INFO:Preloading libraries
2025-06-09 21:24:57,340:INFO:Set up data.
2025-06-09 21:24:57,347:INFO:Set up index.
2025-06-09 21:25:05,676:INFO:Initializing predict_model()
2025-06-09 21:25:05,676:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f868eec8070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f868ee95fc0>)
2025-06-09 21:25:05,676:INFO:Checking exceptions
2025-06-09 21:25:05,676:INFO:Preloading libraries
2025-06-09 21:25:05,676:INFO:Set up data.
2025-06-09 21:25:05,685:INFO:Set up index.
2025-06-09 21:27:18,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:18,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:18,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:18,544:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:19,195:INFO:Initializing load_model()
2025-06-09 21:27:19,195:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:27:46,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:46,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:46,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:46,446:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:27:47,139:INFO:Initializing load_model()
2025-06-09 21:27:47,139:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:30:59,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:30:59,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:30:59,435:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:30:59,436:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:31:00,118:INFO:Initializing load_model()
2025-06-09 21:31:00,118:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:31:21,131:INFO:Initializing predict_model()
2025-06-09 21:31:21,131:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f723ca6c5e0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f723ca3e050>)
2025-06-09 21:31:21,131:INFO:Checking exceptions
2025-06-09 21:31:21,131:INFO:Preloading libraries
2025-06-09 21:31:21,132:INFO:Set up data.
2025-06-09 21:31:21,140:INFO:Set up index.
2025-06-09 21:32:45,820:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:45,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:45,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:45,821:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:46,614:INFO:Initializing load_model()
2025-06-09 21:32:46,614:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:32:54,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:54,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:54,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:54,953:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:55,607:INFO:Initializing load_model()
2025-06-09 21:32:55,607:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:32:55,762:INFO:Initializing predict_model()
2025-06-09 21:32:55,762:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7ff46d4e3bb0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7ff46d753d90>)
2025-06-09 21:32:55,762:INFO:Checking exceptions
2025-06-09 21:32:55,762:INFO:Preloading libraries
2025-06-09 21:32:55,763:INFO:Set up data.
2025-06-09 21:32:55,769:INFO:Set up index.
2025-06-09 21:32:56,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:56,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:56,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:56,210:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:32:56,873:INFO:Initializing load_model()
2025-06-09 21:32:56,873:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:33:41,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:33:41,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:33:41,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:33:41,193:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:33:41,854:INFO:Initializing load_model()
2025-06-09 21:33:41,854:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:34:08,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:08,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:08,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:08,538:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:09,300:INFO:Initializing load_model()
2025-06-09 21:34:09,300:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:34:28,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:28,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:28,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:28,086:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-09 21:34:28,796:INFO:Initializing load_model()
2025-06-09 21:34:28,796:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-09 21:34:50,850:INFO:Initializing predict_model()
2025-06-09 21:34:50,851:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f284b0cc610>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f284b09dfc0>)
2025-06-09 21:34:50,851:INFO:Checking exceptions
2025-06-09 21:34:50,851:INFO:Preloading libraries
2025-06-09 21:34:50,851:INFO:Set up data.
2025-06-09 21:34:50,859:INFO:Set up index.
2025-06-09 21:34:56,999:INFO:Initializing predict_model()
2025-06-09 21:34:56,999:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f284b0cc6d0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f284b09df30>)
2025-06-09 21:34:56,999:INFO:Checking exceptions
2025-06-09 21:34:56,999:INFO:Preloading libraries
2025-06-09 21:34:56,999:INFO:Set up data.
2025-06-09 21:34:57,007:INFO:Set up index.
2025-06-10 01:03:52,277:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:03:52,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:03:52,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:03:52,278:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:03:53,439:INFO:Initializing load_model()
2025-06-10 01:03:53,439:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-10 01:05:40,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:05:40,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:05:40,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:05:40,321:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-06-10 01:05:41,026:INFO:Initializing load_model()
2025-06-10 01:05:41,026:INFO:load_model(model_name=student_performance_model, platform=None, authentication=None, verbose=True)
2025-06-10 01:07:45,934:INFO:Initializing predict_model()
2025-06-10 01:07:45,934:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x7f70642408e0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['Age', 'StudyTimeWeekly',
                                             'Absences'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Gender', 'Ethnicity',
                                             'ParentalEducation', 'Tutoring',
                                             'ParentalS...
moderate       2
strong         3
very_strong    4
NaN           -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Ethnicity', 'ParentalEducation',
                                             'ParentalSupport'],
                                    transformer=OneHotEncoder(cols=['Ethnicity',
                                                                    'ParentalEducation',
                                                                    'ParentalSupport'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=210))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7f70644464d0>)
2025-06-10 01:07:45,934:INFO:Checking exceptions
2025-06-10 01:07:45,935:INFO:Preloading libraries
2025-06-10 01:07:45,938:INFO:Set up data.
2025-06-10 01:07:45,947:INFO:Set up index.
